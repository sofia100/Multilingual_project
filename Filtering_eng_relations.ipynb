{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir =\"trainset_filtered/\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "allowed_suffixes =['s', \"'s\", \"s'\", ''] # if chars after end\n",
    "\n",
    "def check_word_condition(text, eng_word):\n",
    "    for word in text.split(\" \"):\n",
    "        if word.startswith(eng_word):\n",
    "            remaining_word = word[len(eng_word):]\n",
    "            # print(remaining_word)\n",
    "            alpha_chars = ''.join([char for char in remaining_word if char.isalpha()])\n",
    "            # print(alpha_chars)\n",
    "            if alpha_chars in allowed_suffixes:\n",
    "                return True\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "print(check_word_condition(\"The uncle!! were good\", 'uncle'))\n",
    "print(check_word_condition(\"The unclear were good\", 'uncle'))\n",
    "print(check_word_condition(\"The unclesar were good\", 'uncle'))\n",
    "print(check_word_condition(\"The uncle's were good\", 'uncle'))\n",
    "print(check_word_condition(\"The uncle were good\", 'uncle'))\n",
    "print(check_word_condition(\"The uncles' were good\", 'uncle'))\n",
    "print(check_word_condition(\"The uncles' were good\", 'uncles'))\n",
    "print(check_word_condition(\"The uncles'!! were good\", 'uncle'))\n",
    "print(check_word_condition(\"The cluncle!! were good\", 'uncle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the list of uique words that match the englsih words\n",
    "# unique_words = set()\n",
    "# for file in os.listdir(root_dir):\n",
    "#     lang_dir = root_dir + file\n",
    "#     if os.path.isdir(lang_dir):\n",
    "#         print(lang_dir)\n",
    "#         for file in os.listdir(lang_dir):\n",
    "#             eng_word =  file.split(\"_\")[2]\n",
    "#             print(\"\\nFile\", file, os.path.getsize(lang_dir + \"/\" + file))\n",
    "#             #check filesize and continue\n",
    "#             if os.path.getsize(lang_dir + \"/\" + file) == 1:\n",
    "#                 continue\n",
    "#               # read the csv file\n",
    "#             df = pd.read_csv(lang_dir + \"/\" + file, header=0)\n",
    "#             # in each row of CSV file, get the word that matches the english word \"uncle\"\n",
    "#             # for index, row in df.iterrows():\n",
    "#             #     # print(\"row::\", row['eng_Latn'])\n",
    "#             #     flag_found = False\n",
    "#             #     for word in row['eng_Latn'].split(\" \"):\n",
    "#             #         # # print(\"word: \", word)\n",
    "                    \n",
    "#             #         if  word.startswith(eng_word):\n",
    "#             #             flag_found = True\n",
    "#             #             remaining_word = word[len(eng_word):]\n",
    "#             #             chars_list = list(remaining_word)\n",
    "#             #             # check if chars_list is symbols or characters\n",
    "#             #             # if all characters are not  symbols and not allowed suffix, then drop the row\n",
    "#             #             alpha_chars = [char for char in chars_list if char.isalpha()]\n",
    "#             #             for suffix in allowed_suffixes:\n",
    "#             #                 if ''.join(alpha_chars)==(suffix):\n",
    "#             #                     flag_found = False\n",
    "#             #                     break\n",
    "                        \n",
    "#             #         # if eng_word in word:\n",
    "#             #         #     unique_words.add(word)\n",
    "#             #     if not flag_found:\n",
    "#             #         # drop the row\n",
    "#             #         df.drop(index, inplace=True)\n",
    "#             # df = df[df['eng_Latn'].apply(lambda x: any(word.startswith(eng_word) for word in x.split()))]\n",
    "#             print(\"Before filtering::\", df.shape)\n",
    "#             df = df[df['eng_Latn'].apply(check_word_condition, args=(eng_word,))]\n",
    "#             print(\"After filtering::\", df.shape)\n",
    "\n",
    "            \n",
    "                    \n",
    "#                 # if index >3:\n",
    "#                 #     break\n",
    "\n",
    "#             # print(\"For word \", eng_word, \"got results:: \", unique_words)      \n",
    "#             # replace the df in same file          \n",
    "#             df.to_csv(lang_dir + \"/\" + file, index=False)       \n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taunting\n",
    "haunting\n",
    "Haunting unclear\n",
    "haunt\n",
    "haunted\n",
    "Du-Shaunt undaunted\n",
    "unclean\n",
    "flaunted\n",
    "gauntlet\n",
    "haunts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguos_dict = {\n",
    "    'brother-in-law': 'brother-in-law',\n",
    "    'brother in law': 'brother-in-law',\n",
    "    'sister-in-law': 'sister-in-law',\n",
    "    'sister in law': 'sister-in-law',\n",
    "    'uncle': 'uncle',\n",
    "    'aunt': 'aunt',\n",
    "    'grandfather': 'grandfather',\n",
    "    'grandmother': 'grandmother',\n",
    "    'cousin': 'cousin',\n",
    "    'nephew': 'nephew',\n",
    "    'niece': 'niece',\n",
    "    'child': 'child'\n",
    ",\n",
    "    'brothers-in-law': 'brother-in-law',\n",
    "    'brothers in law': 'brother-in-law',\n",
    "    'sisters-in-law': 'sister-in-law',\n",
    "    'sisters in law': 'sister-in-law',\n",
    "    # 'uncles': 'uncle',\n",
    "    # 'aunts': 'aunt',\n",
    "    # 'grandfathers': 'grandfather',\n",
    "    # 'grandmothers': 'grandmother',\n",
    "    # 'cousins': 'cousin',\n",
    "    # 'nephews': 'nephew',\n",
    "    # 'nieces': 'niece',\n",
    "    'children': 'child'\n",
    "    ,\n",
    "    # 'brothers in law\\'s': 'brother-in-law',\n",
    "    # 'brother-in-law\\'s': 'brother-in-law',\n",
    "    # 'sisters in law\\'s': 'sister-in-law',\n",
    "    # 'sister-in-law\\'s': 'sister-in-law',\n",
    "    # 'uncle\\'s': 'uncle',\n",
    "    # 'aunt\\'s': 'aunt',\n",
    "    # 'grandfather\\'s': 'grandfather',\n",
    "    # 'grandmother\\'s': 'grandmother',\n",
    "    # 'cousin\\'s': 'cousin',\n",
    "    # 'nephew\\'s': 'nephew',\n",
    "    # 'niece\\'s': 'niece',\n",
    "    # 'child\\'s': 'child',\n",
    "    # 'children\\'s': 'child',\n",
    "\n",
    "    # 'brothers in laws\\'': 'brother-in-law',\n",
    "    # 'sisters in laws\\'': 'sister-in-law',\n",
    "    # 'uncles\\'': 'uncle',\n",
    "    # 'aunts\\'': 'aunt',\n",
    "    # 'grandfathers\\'': 'grandfather',\n",
    "    # 'grandmothers\\'': 'grandmother',\n",
    "    # 'cousins\\'': 'cousin',\n",
    "    # 'nephews\\'': 'nephew',\n",
    "    # 'nieces\\'': 'niece',\n",
    "    # 'brother in law\\'s': 'brother-in-law',\n",
    "    # 'sister in law\\'s': 'sister-in-law',\n",
    "    # 'brothers-in-law\\'s': 'brother-in-law',\n",
    "    # 'sisters-in-law\\'s': 'sister-in-law',\n",
    "\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "# get set of values of ambiguous_dict\n",
    "unique_words = set(ambiguos_dict.values())\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering from main source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_tam_Taml.csv\n",
      "Before filtering:: (9690253, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:42<42:21, 282.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_kan_Knda.csv\n",
      "Before filtering:: (12500959, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [11:48<48:55, 366.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_ory_Orya.csv\n",
      "Before filtering:: (2863078, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [13:06<27:24, 235.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_hin_Deva.csv\n",
      "Before filtering:: (27187805, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [28:48<51:24, 514.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_guj_Gujr.csv\n",
      "Before filtering:: (11630301, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [35:44<39:53, 478.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_tel_Telu.csv\n",
      "Before filtering:: (11100046, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [41:56<29:30, 442.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_ben_Beng.csv\n",
      "Before filtering:: (16055075, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [49:16<22:04, 441.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_mar_Deva.csv\n",
      "Before filtering:: (10806011, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [54:14<13:11, 395.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_mal_Mlym.csv\n",
      "Before filtering:: (12378602, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:00:22<06:27, 387.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File BPCC_pan_Guru.csv\n",
      "Before filtering:: (6275797, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:03:48<00:00, 382.90s/it]\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'BPCC__/extracted/'\n",
    "# root_dir=\"translated_csv/\"\n",
    "for file in tqdm.tqdm(os.listdir(root_dir)):\n",
    "            print(\"\\nFile\", file)\n",
    "            df = pd.read_csv(root_dir+'/'+file, header=0)\n",
    "            print(\"Before filtering::\", df.shape)\n",
    "            lang = file[len(\"BPCC_\"):-4]\n",
    "            # print(lang)\n",
    "            for eng_word in ambiguos_dict.keys():\n",
    "                # read the csv file\n",
    "                df2 = df[df['eng_Latn'].apply(check_word_condition, args=(eng_word,))]\n",
    "                new_file_name = \"trainset_filtered/\"+lang + \"/\" + lang+\"_\"+ ambiguos_dict[eng_word]+\"_bpcc.csv\"\n",
    "                # check if already file existis. if yes then append wlse create ne wfile and write df2\n",
    "                if os.path.exists(new_file_name):\n",
    "                    df2.to_csv(new_file_name, mode='a', header=False, index=False)\n",
    "                else:\n",
    "                     \n",
    "                     df2.to_csv(new_file_name, index=False)\n",
    "                # print(\"After filtering::\", df2.shape)\n",
    "\n",
    "            # save df2 in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File tam_Taml_uncle_bpcc.csv\n",
      "Before filtering:: (1713, 2)\n",
      "\n",
      "File tam_Taml_aunt_bpcc.csv\n",
      "Before filtering:: (514, 2)\n",
      "\n",
      "File tam_Taml_grandfather_bpcc.csv\n",
      "Before filtering:: (1702, 2)\n",
      "\n",
      "File tam_Taml_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:09,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (112480, 2)\n",
      "\n",
      "File tam_Taml_grandmother_bpcc.csv\n",
      "Before filtering:: (890, 2)\n",
      "\n",
      "File tam_Taml_brother-in-law_bpcc.csv\n",
      "Before filtering:: (134, 2)\n",
      "\n",
      "File tam_Taml_nephew_bpcc.csv\n",
      "Before filtering:: (317, 2)\n",
      "\n",
      "File tam_Taml_niece_bpcc.csv\n",
      "Before filtering:: (186, 2)\n",
      "\n",
      "File tam_Taml_sister-in-law_bpcc.csv\n",
      "Before filtering:: (122, 2)\n",
      "\n",
      "File tam_Taml_cousin_bpcc.csv\n",
      "Before filtering:: (773, 2)\n",
      "\n",
      "File mar_Deva_niece_bpcc.csv\n",
      "Before filtering:: (219, 2)\n",
      "\n",
      "File mar_Deva_grandmother_bpcc.csv\n",
      "Before filtering:: (1023, 2)\n",
      "\n",
      "File mar_Deva_uncle_bpcc.csv\n",
      "Before filtering:: (1080, 2)\n",
      "\n",
      "File mar_Deva_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:01<00:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (106417, 2)\n",
      "\n",
      "File mar_Deva_brother-in-law_bpcc.csv\n",
      "Before filtering:: (265, 2)\n",
      "\n",
      "File mar_Deva_cousin_bpcc.csv\n",
      "Before filtering:: (793, 2)\n",
      "\n",
      "File mar_Deva_aunt_bpcc.csv\n",
      "Before filtering:: (385, 2)\n",
      "\n",
      "File mar_Deva_nephew_bpcc.csv\n",
      "Before filtering:: (587, 2)\n",
      "\n",
      "File mar_Deva_grandfather_bpcc.csv\n",
      "Before filtering:: (1665, 2)\n",
      "\n",
      "File mar_Deva_sister-in-law_bpcc.csv\n",
      "Before filtering:: (170, 2)\n",
      "\n",
      "File ory_Orya_child_bpcc.csv\n",
      "Before filtering:: (33346, 2)\n",
      "\n",
      "File ory_Orya_grandmother_bpcc.csv\n",
      "Before filtering:: (326, 2)\n",
      "\n",
      "File ory_Orya_grandfather_bpcc.csv\n",
      "Before filtering:: (403, 2)\n",
      "\n",
      "File ory_Orya_cousin_bpcc.csv\n",
      "Before filtering:: (156, 2)\n",
      "\n",
      "File ory_Orya_aunt_bpcc.csv\n",
      "Before filtering:: (72, 2)\n",
      "\n",
      "File ory_Orya_uncle_bpcc.csv\n",
      "Before filtering:: (223, 2)\n",
      "\n",
      "File ory_Orya_niece_bpcc.csv\n",
      "Before filtering:: (48, 2)\n",
      "\n",
      "File ory_Orya_sister-in-law_bpcc.csv\n",
      "Before filtering:: (44, 2)\n",
      "\n",
      "File ory_Orya_nephew_bpcc.csv\n",
      "Before filtering:: (81, 2)\n",
      "\n",
      "File ory_Orya_brother-in-law_bpcc.csv\n",
      "Before filtering:: (58, 2)\n",
      "\n",
      "File hin_Deva_grandmother_bpcc.csv\n",
      "Before filtering:: (2438, 2)\n",
      "\n",
      "File hin_Deva_brother-in-law_bpcc.csv\n",
      "Before filtering:: (2053, 2)\n",
      "\n",
      "File hin_Deva_grandfather_bpcc.csv\n",
      "Before filtering:: (2978, 2)\n",
      "\n",
      "File hin_Deva_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:02<00:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (241526, 2)\n",
      "\n",
      "File hin_Deva_niece_bpcc.csv\n",
      "Before filtering:: (1403, 2)\n",
      "\n",
      "File hin_Deva_uncle_bpcc.csv\n",
      "Before filtering:: (4961, 2)\n",
      "\n",
      "File hin_Deva_sister-in-law_bpcc.csv\n",
      "Before filtering:: (1158, 2)\n",
      "\n",
      "File hin_Deva_aunt_bpcc.csv\n",
      "Before filtering:: (1277, 2)\n",
      "\n",
      "File hin_Deva_cousin_bpcc.csv\n",
      "Before filtering:: (4027, 2)\n",
      "\n",
      "File hin_Deva_nephew_bpcc.csv\n",
      "Before filtering:: (4260, 2)\n",
      "\n",
      "File kan_Knda_grandfather_bpcc.csv\n",
      "Before filtering:: (1699, 2)\n",
      "\n",
      "File kan_Knda_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:03<00:03,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (154934, 2)\n",
      "\n",
      "File kan_Knda_aunt_bpcc.csv\n",
      "Before filtering:: (578, 2)\n",
      "\n",
      "File kan_Knda_grandmother_bpcc.csv\n",
      "Before filtering:: (1981, 2)\n",
      "\n",
      "File kan_Knda_niece_bpcc.csv\n",
      "Before filtering:: (378, 2)\n",
      "\n",
      "File kan_Knda_nephew_bpcc.csv\n",
      "Before filtering:: (743, 2)\n",
      "\n",
      "File kan_Knda_sister-in-law_bpcc.csv\n",
      "Before filtering:: (172, 2)\n",
      "\n",
      "File kan_Knda_uncle_bpcc.csv\n",
      "Before filtering:: (1251, 2)\n",
      "\n",
      "File kan_Knda_cousin_bpcc.csv\n",
      "Before filtering:: (1651, 2)\n",
      "\n",
      "File kan_Knda_brother-in-law_bpcc.csv\n",
      "Before filtering:: (361, 2)\n",
      "\n",
      "File pan_Guru_brother-in-law_bpcc.csv\n",
      "Before filtering:: (214, 2)\n",
      "\n",
      "File pan_Guru_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:03<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (72845, 2)\n",
      "\n",
      "File pan_Guru_sister-in-law_bpcc.csv\n",
      "Before filtering:: (125, 2)\n",
      "\n",
      "File pan_Guru_niece_bpcc.csv\n",
      "Before filtering:: (200, 2)\n",
      "\n",
      "File pan_Guru_uncle_bpcc.csv\n",
      "Before filtering:: (645, 2)\n",
      "\n",
      "File pan_Guru_cousin_bpcc.csv\n",
      "Before filtering:: (596, 2)\n",
      "\n",
      "File pan_Guru_grandfather_bpcc.csv\n",
      "Before filtering:: (694, 2)\n",
      "\n",
      "File pan_Guru_aunt_bpcc.csv\n",
      "Before filtering:: (213, 2)\n",
      "\n",
      "File pan_Guru_nephew_bpcc.csv\n",
      "Before filtering:: (445, 2)\n",
      "\n",
      "File pan_Guru_grandmother_bpcc.csv\n",
      "Before filtering:: (562, 2)\n",
      "\n",
      "File tel_Telu_cousin_bpcc.csv\n",
      "Before filtering:: (1351, 2)\n",
      "\n",
      "File tel_Telu_sister-in-law_bpcc.csv\n",
      "Before filtering:: (121, 2)\n",
      "\n",
      "File tel_Telu_brother-in-law_bpcc.csv\n",
      "Before filtering:: (241, 2)\n",
      "\n",
      "File tel_Telu_grandmother_bpcc.csv\n",
      "Before filtering:: (933, 2)\n",
      "\n",
      "File tel_Telu_grandfather_bpcc.csv\n",
      "Before filtering:: (1159, 2)\n",
      "\n",
      "File tel_Telu_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:03<00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (126866, 2)\n",
      "\n",
      "File tel_Telu_niece_bpcc.csv\n",
      "Before filtering:: (228, 2)\n",
      "\n",
      "File tel_Telu_nephew_bpcc.csv\n",
      "Before filtering:: (471, 2)\n",
      "\n",
      "File tel_Telu_uncle_bpcc.csv\n",
      "Before filtering:: (1145, 2)\n",
      "\n",
      "File tel_Telu_aunt_bpcc.csv\n",
      "Before filtering:: (472, 2)\n",
      "\n",
      "File mal_Mlym_sister-in-law_bpcc.csv\n",
      "Before filtering:: (161, 2)\n",
      "\n",
      "File mal_Mlym_aunt_bpcc.csv\n",
      "Before filtering:: (898, 2)\n",
      "\n",
      "File mal_Mlym_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:04<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (145501, 2)\n",
      "\n",
      "File mal_Mlym_cousin_bpcc.csv\n",
      "Before filtering:: (1127, 2)\n",
      "\n",
      "File mal_Mlym_brother-in-law_bpcc.csv\n",
      "Before filtering:: (267, 2)\n",
      "\n",
      "File mal_Mlym_grandfather_bpcc.csv\n",
      "Before filtering:: (1986, 2)\n",
      "\n",
      "File mal_Mlym_nephew_bpcc.csv\n",
      "Before filtering:: (602, 2)\n",
      "\n",
      "File mal_Mlym_grandmother_bpcc.csv\n",
      "Before filtering:: (2243, 2)\n",
      "\n",
      "File mal_Mlym_niece_bpcc.csv\n",
      "Before filtering:: (290, 2)\n",
      "\n",
      "File mal_Mlym_uncle_bpcc.csv\n",
      "Before filtering:: (2228, 2)\n",
      "\n",
      "File guj_Gujr_cousin_bpcc.csv\n",
      "Before filtering:: (1656, 2)\n",
      "\n",
      "File guj_Gujr_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:04<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (144561, 2)\n",
      "\n",
      "File guj_Gujr_nephew_bpcc.csv\n",
      "Before filtering:: (767, 2)\n",
      "\n",
      "File guj_Gujr_niece_bpcc.csv\n",
      "Before filtering:: (400, 2)\n",
      "\n",
      "File guj_Gujr_aunt_bpcc.csv\n",
      "Before filtering:: (518, 2)\n",
      "\n",
      "File guj_Gujr_sister-in-law_bpcc.csv\n",
      "Before filtering:: (274, 2)\n",
      "\n",
      "File guj_Gujr_uncle_bpcc.csv\n",
      "Before filtering:: (1335, 2)\n",
      "\n",
      "File guj_Gujr_brother-in-law_bpcc.csv\n",
      "Before filtering:: (402, 2)\n",
      "\n",
      "File guj_Gujr_grandmother_bpcc.csv\n",
      "Before filtering:: (1310, 2)\n",
      "\n",
      "File guj_Gujr_grandfather_bpcc.csv\n",
      "Before filtering:: (1587, 2)\n",
      "\n",
      "File ben_Beng_brother-in-law_bpcc.csv\n",
      "Before filtering:: (199, 2)\n",
      "\n",
      "File ben_Beng_uncle_bpcc.csv\n",
      "Before filtering:: (1877, 2)\n",
      "\n",
      "File ben_Beng_child_bpcc.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering:: (137820, 2)\n",
      "\n",
      "File ben_Beng_cousin_bpcc.csv\n",
      "Before filtering:: (853, 2)\n",
      "\n",
      "File ben_Beng_niece_bpcc.csv\n",
      "Before filtering:: (278, 2)\n",
      "\n",
      "File ben_Beng_aunt_bpcc.csv\n",
      "Before filtering:: (488, 2)\n",
      "\n",
      "File ben_Beng_grandfather_bpcc.csv\n",
      "Before filtering:: (2239, 2)\n",
      "\n",
      "File ben_Beng_sister-in-law_bpcc.csv\n",
      "Before filtering:: (190, 2)\n",
      "\n",
      "File ben_Beng_nephew_bpcc.csv\n",
      "Before filtering:: (406, 2)\n",
      "\n",
      "File ben_Beng_grandmother_bpcc.csv\n",
      "Before filtering:: (1643, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'trainset_filtered'\n",
    "# root_dir=\"translated_csv/\"\n",
    "for lang_fol in tqdm.tqdm(os.listdir(root_dir)):\n",
    "        for file in os.listdir(root_dir+'/'+lang_fol):\n",
    "            print(\"\\nFile\", file)\n",
    "            df = pd.read_csv(root_dir+'/'+lang_fol+'/'+file, header=0)\n",
    "            print(\"Before filtering::\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
