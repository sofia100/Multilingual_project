{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of notebook:\n",
    "To generate the relations or kinships data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMERS_CACHE='/pool.ssd/assets/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_format = '%Y-%m-%d_%H:%M:%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import tqdm\n",
    "import ast\n",
    "\n",
    "# pip install accelerate\n",
    "\n",
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "# import requests\n",
    "import datetime as dt\n",
    "import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /assets/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/huggingface/transformers@v4.49.0-Gemma-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"google/gemma-3-27b-it\"\n",
    "# model_ids_gemma = [\"google/gemma-3-4b-it\", \"google/gemma-3-12b-it\", \"google/gemma-3-27b-it\"]\n",
    "# model_paths_gemma = ['/assets/models/google-gemma-3-it-4b', '/assets/models/google-gemma-3-it-12b', '/assets/models/google-gemma-3-it-27b']\n",
    "# model_path = \"/assets/models/google-gemma-3-it-27b\"\n",
    "\n",
    "\n",
    "# for model_path in model_ids_gemma:\n",
    "#     tokenizer, model, processor = model_init(model_path)\n",
    "#     print(\"model loaded\")\n",
    "#     print(\"model_path\", model_path)\n",
    "\n",
    "\n",
    "# model_ids_gemma=[  'google/gemma-3-12b-it' ]\n",
    "# PROMPT_TYPE = 'all_gender' # 'all_gender' or 'female' are so far two options\n",
    "# TGT_LANG = 'Hindi' #'Hindi' # for prompt to generate data\n",
    "\n",
    "# TGT_LANG_CODE = 'hin' #'hin' # to store filenames\n",
    "model_ids_gemma=['/assets/models/google-gemma-3-it-4b']\n",
    "MAX_NEW_TOKENS = 500 #480 #200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import possible_indic_relations as poss_indic_rel\n",
    "import span_encodings as sp_enc\n",
    "# Reload the module to reflect changes\n",
    "importlib.reload(poss_indic_rel)\n",
    "importlib.reload(sp_enc)\n",
    "import pandas as pd\n",
    "pir= poss_indic_rel.possible_relations\n",
    "pir\n",
    "\n",
    "ambiguos_words = list(pir.keys())\n",
    "span_encodings = sp_enc.span_encodings\n",
    "\n",
    "# drop \"child\" item from ambiguos_words\n",
    "index_child = ambiguos_words.index(\"child\")\n",
    "ambiguos_words.pop(index_child)\n",
    "print(\"ambiguos_words\", ambiguos_words)\n",
    "\n",
    "lang_script_list = [\n",
    "    'hin_Deva', \n",
    "    'guj_Gujr',\n",
    "    'mar_Deva', \n",
    "    'ory_Orya',\n",
    "     'ben_Beng', \n",
    "    'tam_Taml', \n",
    "    'pan_Guru',\n",
    "     'tel_Telu',\n",
    "      'mal_Mlym', 'kan_Knda', \n",
    "                           ]\n",
    "\n",
    "lang_code_map = {\n",
    "    'eng_Latn': 'Eng',\n",
    "    'hin_Deva': 'Hin',\n",
    "    'guj_Gujr': 'Guj',\n",
    "    'kan_Knda': 'Kan',\n",
    "    'mal_Mlym': 'Mal',\n",
    "    'mar_Deva': 'Mar',\n",
    "    'tam_Taml': 'Tam',\n",
    "    'tel_Telu': 'Tel',\n",
    "    'pan_Guru': 'Pun',\n",
    "    'ben_Beng': 'Ben',\n",
    "    'ory_Orya': 'Odi'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_examples = {\n",
    "#                         0: [  \n",
    "#                             \"ग्राहक दुकानदार से कीमत कम करने के लिए मोलभाव कर रहा है।\",\n",
    "#                             \"खरीदार उत्पाद की कीमत पर चर्चा कर रहा है।\",\n",
    "#                             \"अभिनेता फिल्म की शूटिंग कर रहा है।\",\n",
    "#                             \"गायक नया गीत गा रहा है।\",\n",
    "#                             \"खिलाड़ी फुटबॉल खेल रहा है।\"\n",
    "#                         ],\n",
    "#                         1: [  \n",
    "#                             \"ग्राहिका दुकानदार से कीमत कम करने के लिए मोलभाव कर रही है।\",\n",
    "#                             \"खरीदारी करने वाली महिला उत्पाद की कीमत पर चर्चा कर रही है।\",\n",
    "#                             \"अभिनेत्री फिल्म की शूटिंग कर रही है।\",\n",
    "#                             \"गायिका नया गीत गा रही है।\",\n",
    "#                             \"खिलाड़ी फुटबॉल खेल रही है।\"\n",
    "#                         ],\n",
    "#                         2: [  \n",
    "#                             \"ग्राहक दुकानदार से कीमत कम करने के लिए बातचीत कर रहे हैं।\",\n",
    "#                             \"खरीदार उत्पाद की कीमत पर चर्चा कर रहे हैं।\",\n",
    "#                             \"कलाकार फिल्म की शूटिंग कर रहे हैं।\",\n",
    "#                             \"गायन समूह नया गीत गा रहा है।\",\n",
    "#                             \"टीम ने शानदार फुटबॉल खेला।\"\n",
    "#                         ]\n",
    "#                     }\n",
    "# fem_examples = {\n",
    "#     1: [\"माँ का प्रेम और करुणा संपूर्ण सृष्टि को ऊर्जा देती है।\",\n",
    "#     \"देवी सरस्वती ज्ञान और विद्या की अधिष्ठात्री हैं।\",\n",
    "#     \"नारी शक्ति का स्वरूप सृजन और पालन में निहित है।\",\n",
    "#     \"योगिनी ध्यान और साधना से आत्मज्ञान प्राप्त करती है।\",\n",
    "#     \"गृहलक्ष्मी अपने परिवार के सुख और समृद्धि का आधार होती है।\",\n",
    "#     \"कला की साधिका अपनी कल्पनाओं को साकार करती है।\",\n",
    "#     \"संगीतकारा अपनी सुरों से वातावरण को मधुर बना देती है।\",\n",
    "#     \"रचनात्मक महिला अपने विचारों से समाज को प्रेरित करती है।\",\n",
    "#     \"ऋषिका वेदों के गूढ़ ज्ञान को समझने में सक्षम होती है।\",\n",
    "#     \"प्रकृति स्वयं मातृशक्ति का प्रतीक है, जो पोषण करती है।\",\n",
    "#     \"समुद्र की लहरें देवी की तरह रहस्यमयी और शक्तिशाली होती हैं।\",\n",
    "#     \"शक्ति स्वरूपा स्त्री विपरीत परिस्थितियों में भी धैर्य रखती है।\",\n",
    "#     \"कवयित्री अपने शब्दों से लोगों की भावनाओं को छू लेती है।\",\n",
    "#     \"संवेदनशील नारी दूसरों की पीड़ा को समझने में सक्षम होती है।\",\n",
    "#     \"युद्ध में वीरांगना अपने पराक्रम से शत्रुओं का सामना करती है।\",\n",
    "#     \"योग साधिका आत्मा और शरीर के संतुलन को बनाए रखती है।\",\n",
    "#     \"नृत्यांगना अपने नृत्य से भावनाओं को अभिव्यक्त करती है।\",\n",
    "#     \"चिकित्सिका अपने ज्ञान से रोगियों को स्वस्थ करती है।\",\n",
    "#     \"शिक्षिका अपने विद्यार्थियों को ज्ञान की रोशनी से आलोकित करती है।\",\n",
    "#     \"धार्मिक महिला अपने भक्ति और श्रद्धा से जीवन को संवारती है।\"]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_topics=[\"occupation\", \" religion\", \" sport\", \" politics\", \"  health\", \" finance\", \" education\", \" farming\", \" entertainment\", \"  news\", \"  daily conversation\", \"  weather\", \" technology\", \" conflicts\", \" controversials\", \n",
    "        \" international\", \"  UN\", \" travel\", \" tourism\", \" shopping\", \" baby care\", \" valentines\", \"  soldiers\", \" prisioners\", \" soul actions\", \" nature\", \" pollution\", \" bio hazards\", \" elders\", \" family\", \n",
    "        \"  social studies\", \" maths\", \" literature\", \"  physics\", \" chemistry\", \"  biology\", \" Indian history \", \" civics\", \" geography\", \"  computer\", \" physical education\", \"  arts and craft\", \"  food\", \n",
    "        \" clothes\", \" water shortage\", \" road blockage\", \" traffic\", \" arriving late\", \" bargaining\", \" toys\", \" games\", \" deep talks\", \"declarative\", \"interrogative\", \"imperative\",  \"exclamatory\", \"safe work space\", \n",
    "        \"medical checkups\", \"self-reliant\", \"future India\",   \"legal\", \"governance\",  \n",
    "  \"STEM\" ,   \"business\", \"sports\",  \"culture\", \"Alarm\",\"Audio\",\"Calendar / Events\", \"Communication\",\"DateTime\",\"Email\",\"Finance\",  \"General\",\"Home Automation\", \"Location\",\"Music\",\"News\",\"Reminders\",\"Social Media\",  \n",
    "  \"Travel\",\"Weather\",\"BookRestaurant\",\"BookFlight\",\"BookHotel\",\"GetDirections\",\"GetPlaceDetails\",\"GetWeather\",\"SearchForInformation\",\"GetNews\",\"PlayMusic\",\"ControlVolume\",\"SetAlarm\",\"CancelAlarm\",\"SetReminder\",\"MakeCall\",\n",
    "  \"SendMessage\",\"SendEmail\",\"CheckEmail\",\"GetTime\",\"GetDate\",\"Greeting\",\"Farewell\",\"AskHowAreYou\",\"ThankYou\",\"TellAJoke\",\"TurnOnLights\", \"Social media interactions\",  \"Financial transactions\"  ]\n",
    "\n",
    "fem_topics =  ['menstruation', 'pregnancy', 'childbirth', 'breastfeeding', 'menopause', 'ovulation', 'hormones', 'gynecologist', 'obstetrician', 'midwife', 'doula', 'contraception', 'abortion', 'fertility', 'infertility', 'endometriosis', 'polycystic ovary syndrome', 'uterus', 'ovaries', 'marriage', 'divorce', 'single mother', \n",
    "               'surrogacy','domestic violence', 'sexual assault', 'rape', 'sexual harassment', 'goddess', 'beauty pageant', 'feminism',]\n",
    "\n",
    "additional_topics = [ \"Housewife\", \"Policewoman\", \"CEO\", \"Nurse\", \"Teacher\", \"Chef\", \"Politician\", \"Engineer\", \"Laborer\", \"Bollywood\",  \n",
    "    \"Karwa Chauth\", \"Raksha Bandhan\", \"Teej\", \"Kanyadaan\", \"Mehendi\", \"Navratri\", \"Eid\", \"Holi\", \"Diwali\", \"Chhath Puja\",  \n",
    "    \"Cricket\", \"Kabaddi\", \"Wrestling\", \"Badminton\", \"Olympics\", \"IPL\", \"Marathon\", \"Yoga\", \"Coaching\", \"School Sports\",  \n",
    "    \"Voting\", \"Protests\", \"Gender Crime\", \"Quotas\", \"News Reporting\", \"Women’s Rights\", \"Men’s Rights\", \"Dowry Law\", \"Parliament\", \"Governance\",  \n",
    "   \"Maternity\", \"Paternity\", \"Skin Care\", \"Hairfall\", \"Dieting\", \"Medical Checkups\", \"Parlor\", \"Gym\", \"Pregnancy\", \"Breastfeeding\",  \n",
    "    \"Budget\", \"Loans\", \"Savings\", \"Shopping\", \"Investments\", \"Gold\", \"Startups\", \"Stock Market\", \"Banking\", \"Credit Cards\",  \n",
    "    \"STEM\", \"IIT\", \"Nursing\", \"Fashion\", \"Leadership\", \"Arts\", \"Research\", \"Admissions\", \"Govt Jobs\", \"Engineering\",  \n",
    "    \"Agriculture\", \"Water Shortage\", \"Pollution\", \"Bio Hazards\", \"Organic Farming\", \"Green Energy\", \"Monsoon\", \"Drought\", \"Farmers’ Protests\", \"Pesticides\",  \n",
    "    \"Serials\", \"Reality Shows\", \"Action Films\", \"Singers\", \"Web Series\", \"Pay Gap\", \"Directors\", \"Influencers\", \"Romance\", \"Bollywood\",  \n",
    "    \"Social Media\", \"Financial Transactions\", \"Fake News\", \"News Anchors\", \"Political Debates\", \"Public Speaking\", \"Cyber Safety\", \"E-Governance\", \"WhatsApp Forwards\", \"YouTube Trends\",  \n",
    "    \"Solo Travel\", \"Taxi Safety\", \"Bike Riders\", \"Public Transport\", \"Driving\", \"Holiday\", \"Blogging\", \"Late-Night Travel\", \"Destinations\", \"Work-from-Home\",  \n",
    "    \"Marriage\", \"Dowry\", \"Motherhood\", \"Fatherhood\", \"Widowhood\", \"Siblings\", \"Bride\", \"Groom\", \"Joint Family\", \"Daughter-Son\",  \n",
    "    \"New Year\", \"Makar Sankranti\", \"Baisakhi\", \"Ganesh Chaturthi\", \"Pongal\", \"Onam\", \"Eid-ul-Fitr\", \"Christmas\", \"Buddha Purnima\", \"Muharram\",  \n",
    "    \"Cooking\", \"Shopping\", \"Cleaning\", \"Driving\", \"Bills\", \"Decor\", \"Childcare\", \"Grocery\", \"Hobbies\", \"Festivals\",  \n",
    "    \"Citizenship\", \"Elections\", \"Protests\", \"RTI\", \"Lawsuits\", \"Corruption\", \"Taxation\", \"Parliament Sessions\", \"Women’s Rights\", \"Legal Awareness\"\n",
    "]\n",
    "# additional_topics = additional_topics - fem_topics - general_topics\n",
    "additional_topics = list(set(additional_topics) - set(fem_topics) - set(general_topics))\n",
    "print(len(additional_topics), len(fem_topics), len(general_topics))\n",
    "\n",
    "topics=general_topics #[-3:]\n",
    "# topics=additional_topics\n",
    "# topics = None # set below\n",
    "print(\"topics\", len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if PROMPT_TYPE == 'female':\n",
    "#     examples = fem_examples\n",
    "#     topics = fem_topics\n",
    "# else:\n",
    "#     # topics = general_topics\n",
    "#     topics = additional_topics\n",
    "#     examples = general_examples\n",
    "\n",
    "# print(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = '''[\n",
    "#     ..   \"पूछती हूँ\", \"बनाती हूँ\", \"बचाती हूँ\", \"डरती हूँ\", \"हँसती हूँ\", \"रोती हूँ\", \"लड़ती हूँ\",...\n",
    "#     \"गिरती हूँ\", \"उठाती हूँ\", \"सुलाती हूँ\", \"दिखाती हूँ\", \"सुनाती हूँ\"...\n",
    "# ]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_coll ={\n",
    "    'hin_Deva': {\n",
    "    \"चाची\": [\n",
    "        \"चाची ने संपत्ति विवाद को अदालत में उठाया।\",\n",
    "        \"मेरी चाची ने वकील से सलाह ली।\",\n",
    "        # \"चाची ने ज़मीन के काग़ज़ात की जाँच करवाई।\",\n",
    "        # \"मेरी चाची ने कानूनी अधिकारों के लिए याचिका दायर की।\",\n",
    "        # \"चाची अदालत में अपने पक्ष को मजबूती से रख रही थीं।\",\n",
    "        # \"मेरी चाची ने विरासत से जुड़ा केस जीता।\",\n",
    "        # \"चाची ने कानून के तहत अपने हिस्से की माँग की।\"\n",
    "    ],\n",
    "    \"बुआ\": [\n",
    "        \"बुआ ने तलाक़ की प्रक्रिया शुरू कर दी है।\",\n",
    "        \"मेरी बुआ ने धोखाधड़ी के खिलाफ एफआईआर दर्ज करवाई।\",\n",
    "        # \"बुआ कोर्ट में अपने बच्चों की कस्टडी के लिए लड़ रही हैं।\",\n",
    "        # \"बुआ ने अपने वकील के साथ कानूनी रणनीति बनाई।\",\n",
    "        # \"मेरी बुआ ने कोर्ट में बयान दर्ज कराया।\",\n",
    "        # \"बुआ ने न्यायालय से सुरक्षा की माँग की।\",\n",
    "        # \"बुआ को संपत्ति विवाद में न्याय मिला।\"\n",
    "    ],\n",
    "    \"ताई\": [\n",
    "        \"ताई ने अदालत में दस्तावेज़ पेश किए।\",\n",
    "        \"मेरी ताई ने सरकारी वकील से बात की।\",\n",
    "        # \"ताई ने अदालत में गवाही दी।\",\n",
    "        # \"ताई ने ज़मीन के बंटवारे को लेकर केस दर्ज करवाया।\",\n",
    "        # \"मेरी ताई ने अपनी विरासत के अधिकार की कानूनी लड़ाई जीती।\",\n",
    "        # \"ताई ने समाजिक कल्याण योजनाओं में धोखाधड़ी की शिकायत की।\",\n",
    "        # \"ताई कोर्ट में अपने पक्ष को स्पष्ट कर रही थीं।\"\n",
    "    ],\n",
    "    \"मामी\": [\n",
    "        \"मामी ने धोखाधड़ी के मामले में शिकायत दर्ज की।\",\n",
    "        \"मेरी मामी ने कानून के तहत गुज़र-बसर भत्ता माँगा।\",\n",
    "        # \"मामी ने महिला आयोग में मामला दर्ज कराया।\",\n",
    "        # \"मामी अदालत से न्याय की उम्मीद कर रही हैं।\",\n",
    "        # \"मामी ने दस्तावेज़ों की वैधता को चुनौती दी।\",\n",
    "        # \"मेरी मामी ने कानून सलाहकार से परामर्श लिया।\",\n",
    "        # \"मामी ने पुलिस में विधिवत बयान दर्ज करवाया।\"\n",
    "    ],\n",
    "    \"मासी\": [\n",
    "        \"मासी ने कानूनी सहायता के लिए अर्जी दी।\",\n",
    "        \"मेरी मासी ने अदालत में अपने हक़ की लड़ाई लड़ी।\",\n",
    "        # \"मासी ने कोर्ट में संपत्ति पर दावा किया।\",\n",
    "        # \"मासी ने गवाहों की सूची वकील को सौंपी।\",\n",
    "        # \"मेरी मासी को वकील ने कड़ी दलील देने की सलाह दी।\",\n",
    "        # \"मासी ने पुलिस थाने में रिपोर्ट दर्ज करवाई।\",\n",
    "        # \"मासी ने पारिवारिक विवाद में अदालत का रुख किया।\"\n",
    "    ]\n",
    "},\n",
    "  'guj_Gujr':  {\n",
    "    \"કાકી\": [\n",
    "        \"કાકીએ મિલકતના વિવાદ માટે કોર્ટમાં કેસ દાખલ કર્યો.\",\n",
    "        \"મારી કાકીએ વકીલની સલાહ લીધી અને કાયદેસર પગલાં લીધા.\"\n",
    "    ],\n",
    "    \"ફોઈ\": [\n",
    "        \"ફોઈએ કૌટુંબિક હિંસાના કેસમાં ફરિયાદ નોંધાવી.\",\n",
    "        \"મારી ફોઈએ કોર્ટમાં પોતાના હક્ક માટે સાક્ષ આપ્યો.\"\n",
    "    ],\n",
    "    \"મોટી મા\": [\n",
    "        \"મોટી માએ વારસાની હક્ક માટે કાયદેસર કાર્યવાહી કરી.\",\n",
    "        \"મોટી માંએ કોર્ટમાં કાગળો રજૂ કર્યા.\"\n",
    "    ],\n",
    "    \"મામી\": [\n",
    "        \"મામીએ સ્ત્રી અધિકાર માટે ફરિયાદ નોંધાવી.\",\n",
    "        \"મારી મામીએ પોલીસ સ્ટેશનમાં લેખિત ફરિયાદ આપી.\"\n",
    "    ],\n",
    "    \"મોશી\": [\n",
    "        \"મોશીએ કાયદેસર હક્ક માટે અરજદારી કરી.\",\n",
    "        \"મોશી કોર્ટના દરવાજા સુધી પહોંચ્યા ન્યાય માટે.\"\n",
    "    ]\n",
    "}, 'ory_Orya': {\n",
    "\n",
    "    \"ଖୁଡି\": [\n",
    "        \"ଖୁଡି ଜମି ସମ୍ପର୍କିତ ମାମଲା ପାଇଁ ଆଇନଜୀବୀ ସହ ସମ୍ପର୍କ କଲେ।\",\n",
    "        \"ମୋ ଖୁଡି ନିଜର ଅଧିକାର ପାଇଁ ଆଇନ ମାର୍ଗରେ ଯିବାକୁ ଚାହାଁଛନ୍ତି।\"\n",
    "    ],\n",
    "    \"ପିସି\": [\n",
    "        \"ପିସି ନ୍ୟାୟାଳୟ ରେ ଗवाही ଦେଲେ।\",\n",
    "        \"ମୋ ପିସି ଏକ ଆଇନ ମାମଲା ରେ ଜିତିଲେ।\"\n",
    "    ],\n",
    "    \"ବଡ ମା\": [\n",
    "        \"ବଡ ମା ଏକ ଥାନାରେ ରିପୋର୍ଟ ଦାଖଲ କରିଥିଲେ।\",\n",
    "        \"ମୋ ବଡ ମା ଜମି ବିବାଦ ପାଇଁ ଅଦାଲତ କୁ ଗଲେ।\"\n",
    "    ],\n",
    "    \"ମାଏନ\": [\n",
    "        \"ମାଏନ ନିଜ ଆଇନିକ ଅଧିକାର ନିମନ୍ତେ ଆବେଦନ କଲେ।\",\n",
    "        \"ମୋ ମାଏନ ନ୍ୟାୟ ଲାଗି ମହିଳା କମିଶନ୍ ରେ ଅଭିଯୋଗ କଲେ।\"\n",
    "    ],\n",
    "    \"ମାଉସି\": [\n",
    "        \"ମାଉସି ଜନ୍ମସ୍ଥଳୀର ଥାନାରେ ଏକ ଅଭିଯୋଗ ଦାଖଲ କଲେ।\",\n",
    "        \"ମୋ ମାଉସି ଆଇନ ଅନୁଯାୟୀ ନ୍ୟାୟ ପାଇଁ ଚେଷ୍ଟା କରୁଛନ୍ତି।\"\n",
    "    ]\n",
    "}\n",
    ",\n",
    "\n",
    "  'mal_Mlym': {\n",
    "    \"അമ്മായിയമ്മ\": [\n",
    "        \"അമ്മായിയമ്മ ഭൂമി തർക്കത്തിൽ കോടതിയെ സമീപിച്ചു.\",\n",
    "        \"എന്റെ അമ്മായിയമ്മ നിയമോപദേശം തേടി രംഗത്തെത്തി.\"\n",
    "    ],\n",
    "    \"പിഷി\": [\n",
    "        \"പിഷി കുടുംബപരമായ പ്രശ്നങ്ങൾക്കായി കേസ് കൊടുത്തു.\",\n",
    "        \"എന്റെ പിഷി കോടതിയിൽ സാക്ഷ്യം പറഞ്ഞു.\"\n",
    "    ],\n",
    "    \"വലിയമ്മ\": [\n",
    "        \"വലിയമ്മ അവകാശങ്ങൾക്കായി നിയമപരമായി നടപടി ആരംഭിച്ചു.\",\n",
    "        \"എന്റെ വലിയമ്മ വക്കീലുമായി നിയമപ്രവർത്തനങ്ങൾ തുടങ്ങി.\"\n",
    "    ],\n",
    "    \"മാമി\": [\n",
    "        \"മാമി സ്ത്രീകളും കുട്ടികളും സംരക്ഷണത്തിനായി പരാതിപ്പെട്ടു.\",\n",
    "        \"എന്റെ മാമി പൊലീസ് സ്റ്റേഷനിൽ പരാതി നൽകി.\"\n",
    "    ],\n",
    "    \"മാമ്മ\": [\n",
    "        \"മാമ്മ കോടതിയിൽ തർക്കം പരിഹരിക്കാൻ ശ്രമിച്ചു.\",\n",
    "        \"എന്റെ മാമ്മ നിയമം അനുസരിച്ച് അധികാരങ്ങൾ ആവശ്യപ്പെട്ടു.\"\n",
    "    ]\n",
    "  },\n",
    "  'kan_Knda': {\n",
    "    \"ಅತ್ತೆ\": [\n",
    "        \"ಅತ್ತೆ ಜಮೀನು ವಿವಾದದ ಕುರಿತು ನ್ಯಾಯಾಲಯದಲ್ಲಿ ಅರ್ಜಿ ಸಲ್ಲಿಸಿದರು.\",\n",
    "        \"ನನ್ನ ಅತ್ತೆ ಕಾನೂನು ಸಲಹೆಗಾಗಿ ವಕೀಲರನ್ನು ಭೇಟಿಯಾದರು.\"\n",
    "    ],\n",
    "    \"ಪಿಸಿಯವರು\": [\n",
    "        \"ಪಿಸಿಯವರು ಕೌಟುಂಬಿಕ ಸಮಸ್ಯೆಗೆ ಸಂಬಂಧಿಸಿದಂತೆ ತಾಕೀತು ಪತ್ರ ನೀಡಿದರು.\",\n",
    "        \"ನನ್ನ ಪಿಸಿಯವರು ನ್ಯಾಯಾಲಯದಲ್ಲಿ ತಮ್ಮ ಹಕ್ಕುಗಳನ್ನು ಬೇಡಿಕೆ ಹಾಕಿದರು.\"\n",
    "    ],\n",
    "    \"ದೊಡ್ಡ ಅಮ್ಮ\": [\n",
    "        \"ದೊಡ್ಡ ಅಮ್ಮ ಕಾನೂನು ಪ್ರಕ್ರಿಯೆ ಬಗ್ಗೆ ಸೂಕ್ತ ದಾಖಲೆಗಳನ್ನು ಸಂಗ್ರಹಿಸಿದರು.\",\n",
    "        \"ನನ್ನ ದೊಡ್ಡ ಅಮ್ಮ ನ್ಯಾಯಾಲಯದಲ್ಲಿ ಸಾಕ್ಷ್ಯಾಧಾರ ನೀಡಿದರು.\"\n",
    "    ],\n",
    "    \"ಮಾಮಿ\": [\n",
    "        \"ಮಾಮಿ ಮಹಿಳಾ ಕಮಿಷನ್‌ಗೆ ದೂರು ನೀಡಿದರು.\",\n",
    "        \"ನನ್ನ ಮಾಮಿ ಕಾನೂನು ಮೂಲಕ ನ್ಯಾಯವನ್ನು ಪಡೆಯಲು ಯತ್ನಿಸುತ್ತಿದ್ದಾರೆ.\"\n",
    "    ],\n",
    "    \"ಚಿಕ್ಕಮ್ಮ\": [\n",
    "        \"ಚಿಕ್ಕಮ್ಮನು ಹಕ್ಕಿಗಾಗಿ ನ್ಯಾಯಾಲಯದಲ್ಲಿ ಅರ್ಜಿ ಸಲ್ಲಿಸಿದರು.\",\n",
    "        \"ನನ್ನ ಚಿಕ್ಕಮ್ಮ ಕಾನೂನು ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ ಸಕ್ರಿಯವಾಗಿ ಭಾಗವಹಿಸುತ್ತಿದ್ದಾರೆ.\"\n",
    "    ]\n",
    "  },\n",
    "  'mar_Deva': {\n",
    "    \"काकू\": [\n",
    "        \"काकूंनी मालमत्तेच्या वादासाठी वकिलांची मदत घेतली.\",\n",
    "        \"माझ्या काकूंनी न्यायालयात आपला हक्क सिद्ध केला.\"\n",
    "    ],\n",
    "    \"पिसी\": [\n",
    "        \"पिसीने कौटुंबिक हिंसाचारविरोधात तक्रार दाखल केली.\",\n",
    "        \"माझ्या पिसीने कोर्टात साक्ष दिली.\"\n",
    "    ],\n",
    "    \"मोठी आई\": [\n",
    "        \"मोठ्या आईने जमिनीच्या हक्कासाठी केस दाखल केला.\",\n",
    "        \"माझ्या मोठ्या आईने वकिलांच्या मार्गदर्शनाने कायदेशीर कारवाई केली.\"\n",
    "    ],\n",
    "    \"मावस\": [\n",
    "        \"मावसने पोलिसांत वारसाहक्काची तक्रार नोंदवली.\",\n",
    "        \"माझ्या मावसने कोर्टात अर्ज दाखल केला.\"\n",
    "    ],\n",
    "    \"मावशी\": [\n",
    "        \"मावशीने कायदेशीर सल्ला घेऊन निर्णय घेतला.\",\n",
    "        \"माझ्या मावशीने महिला आयोगाकडे आपली तक्रार मांडली.\"\n",
    "    ]\n",
    "  },\n",
    "  'tam_Taml': {\n",
    "    \"அத்தை\": [\n",
    "        \"அத்தை நீதிமன்றத்தில் சொத்து உரிமைக்காக வழக்கு தொடர்ந்தார்.\",\n",
    "        \"என் அத்தை சட்ட ஆலோசனை பெற்ற பிறகு நடவடிக்கை எடுத்தார்.\"\n",
    "    ],\n",
    "    \"பாட்டி அத்தை\": [\n",
    "        \"பாட்டி அத்தை வீட்டுவசதி உரிமை குறித்து புகார் செய்தார்.\",\n",
    "        \"என் பாட்டி அத்தை நீதிமன்றத்தில் சாட்சியாக வெளியேறினார்.\"\n",
    "    ],\n",
    "    \"பெரியம்மா\": [\n",
    "        \"பெரியம்மா வக்கீலின் உதவியுடன் வழக்கு தாக்கல் செய்தார்.\",\n",
    "        \"என் பெரியம்மா சட்டப்படி தனது உரிமையை கோரினார்.\"\n",
    "    ],\n",
    "    \"மாமி\": [\n",
    "        \"மாமி குடும்ப வன்முறையுக்கு எதிராக போலீசில் புகார் செய்தார்.\",\n",
    "        \"என் மாமி சட்ட மையத்தில் மனு தாக்கல் செய்தார்.\"\n",
    "    ],\n",
    "    \"மாமி (2)\": [\n",
    "        \"மாமி நீதிமன்றத்தில் தனது நில உரிமையை நிரூபித்தார்.\",\n",
    "        \"என் மாமி சட்ட ஆலோசகரை சந்தித்தார்.\"\n",
    "    ]\n",
    "  },\n",
    "  'tel_Telu': {\n",
    "    \"అత్త\": [\n",
    "        \"అత్త గారు ఆస్తి హక్కుల కోసం కోర్టులో కేసు వేశారు.\",\n",
    "        \"నా అత్త గారు న్యాయ సహాయానికి న్యాయవాదిని సంప్రదించారు.\"\n",
    "    ],\n",
    "    \"పిన్నమ్మ\": [\n",
    "        \"పిన్నమ్మ గారు పోలీసులకు ఫిర్యాదు చేశారు.\",\n",
    "        \"పిన్నమ్మ కోర్టులో తగిన ఆధారాలతో హాజరయ్యారు.\"\n",
    "    ],\n",
    "    \"పెద్దమ్మ\": [\n",
    "        \"పెద్దమ్మ తన హక్కుల కోసం న్యాయపరమైన చర్యలు చేపట్టారు.\",\n",
    "        \"నా పెద్దమ్మ ఆస్తి సంబంధిత పత్రాలు కోర్టులో సమర్పించారు.\"\n",
    "    ],\n",
    "    \"మామి\": [\n",
    "        \"మామి మహిళా హక్కుల కోసం లీగల్ నోటీసు ఇచ్చారు.\",\n",
    "        \"మా మామి న్యాయంగా తమ హక్కును పొందేందుకు కోర్టును ఆశ్రయించారు.\"\n",
    "    ],\n",
    "    \"మావెము\": [\n",
    "        \"మావెము న్యాయ సలహా తీసుకొని ఫిర్యాదు చేశారు.\",\n",
    "        \"మావెము పోలీసు స్టేషన్‌లో పిర్యాదు చేశారు.\"\n",
    "    ]\n",
    "  },\n",
    "  'pan_Guru': {\n",
    "    \"ਚਾਚੀ\": [\n",
    "        \"ਚਾਚੀ ਨੇ ਜਾਇਦਾਦ ਦੇ ਮੁੱਦੇ 'ਤੇ ਅਦਾਲਤ 'ਚ ਮਾਮਲਾ ਚਲਾਇਆ।\",\n",
    "        \"ਚਾਚੀ ਨੇ ਆਪਣੇ ਕਾਨੂੰਨੀ ਹੱਕ ਲਈ ਵਕੀਲ ਨਾਲ ਸਲਾਹ ਲਈ।\"\n",
    "    ],\n",
    "    \"ਬੁਆ\": [\n",
    "        \"ਬੁਆ ਨੇ ਘਰੇਲੂ ਹਿੰਸਾ ਖਿਲਾਫ ਕੇਸ ਦਰਜ ਕਰਵਾਇਆ।\",\n",
    "        \"ਬੁਆ ਅਦਾਲਤ ਵਿੱਚ ਆਪਣੇ ਹੱਕ ਦੀ ਗਵਾਹੀ ਦੇ ਰਹੀ ਸੀ।\"\n",
    "    ],\n",
    "    \"ਵੱਡੀ ਮਾਂ\": [\n",
    "        \"ਵੱਡੀ ਮਾਂ ਨੇ ਵਾਰਸਾਨਾ ਹੱਕ ਲਈ ਕਾਨੂੰਨੀ ਕਾਰਵਾਈ ਸ਼ੁਰੂ ਕੀਤੀ।\",\n",
    "        \"ਵੱਡੀ ਮਾਂ ਨੇ ਜਾਇਦਾਦ ਸੰਬੰਧੀ ਦਸਤਾਵੇਜ਼ ਅਦਾਲਤ ਵਿਚ ਪੇਸ਼ ਕੀਤੇ।\"\n",
    "    ],\n",
    "    \"ਮਾਮੀ\": [\n",
    "        \"ਮਾਮੀ ਨੇ ਔਰਤਾਂ ਦੇ ਹੱਕ ਲਈ ਸ਼ਿਕਾਇਤ ਕੀਤੀ।\",\n",
    "        \"ਮਾਮੀ ਨੇ ਪੁਲਿਸ ਨੂੰ ਲਿਖਤੀ ਸ਼ਿਕਾਇਤ ਦਿੱਤੀ।\"\n",
    "    ],\n",
    "    \"ਮੌਸੀ\": [\n",
    "        \"ਮੌਸੀ ਨੇ ਆਪਣੇ ਕਾਨੂੰਨੀ ਹੱਕ ਲਈ ਅਰਜ਼ੀ ਦਿੱਤੀ।\",\n",
    "        \"ਮੌਸੀ ਨੇ ਅਦਾਲਤ ਤੋਂ ਇਨਸਾਫ਼ ਦੀ ਮੰਗ ਕੀਤੀ।\"\n",
    "    ]\n",
    "  },\n",
    "  'ben_Beng': {\n",
    "    \"কাকী\": [\n",
    "        \"কাকী সম্পত্তি সংক্রান্ত বিষয়ে মামলা দায়ের করেছেন।\",\n",
    "        \"আমার কাকী আইনজীবীর সঙ্গে পরামর্শ করেছেন।\"\n",
    "    ],\n",
    "    \"পিসি\": [\n",
    "        \"পিসি আদালতে নিজের অধিকারের জন্য দাঁড়িয়েছিলেন।\",\n",
    "        \"আমার পিসি একটি পারিবারিক মামলায় জয়লাভ করেছেন।\"\n",
    "    ],\n",
    "    \"বড় মা\": [\n",
    "        \"বড় মা উত্তরাধিকার সংক্রান্ত মামলা আদালতে তুলেছেন।\",\n",
    "        \"আমার বড় মা কোর্টে প্রয়োজনীয় কাগজ জমা দিয়েছেন।\"\n",
    "    ],\n",
    "    \"মামি\": [\n",
    "        \"মামি নারী হিংসার বিরুদ্ধে অভিযোগ দায়ের করেছেন।\",\n",
    "        \"আমার মামি আইনের সাহায্যে ন্যায় বিচারের জন্য লড়ছেন।\"\n",
    "    ],\n",
    "    \"মাসি\": [\n",
    "        \"মাসি সম্পত্তির ভাগ নিয়ে আদালতে গিয়েছেন।\",\n",
    "        \"আমার মাসি পুলিশ স্টেশনে লিখিত অভিযোগ দাখিল করেছেন।\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "for lang in examples_coll.keys():\n",
    "    val = examples_coll[lang]\n",
    "    for k in val.keys():\n",
    "        v = val[k]\n",
    "        examples_coll[lang][k] = str(v)+'...'\n",
    "\n",
    "\n",
    "\n",
    "print(len(examples_coll))\n",
    "print(examples_coll['ory_Orya'].keys())\n",
    "print(examples_coll['ory_Orya'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_init(model_path):\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n",
    "    print(\"tokenizer loaded\")\n",
    "\n",
    "    model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "        # model_id, device_map=\"auto\"\n",
    "        model_path, device_map='auto'\n",
    "    ).eval()\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "    return tokenizer, model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_now_str():\n",
    "    now_str = dt.datetime.now().strftime(datetime_format)\n",
    "    # print(now_str)\n",
    "    return now_str\n",
    "\n",
    "def save_logs(now_str, messages=None, inputs=None, decoded=None, time_diff=None, tgt_lang_code=None):\n",
    "    with open('response_logs.txt', 'a+') as f:\n",
    "        # write decoded to file with timestamp now_str\n",
    "        f.write(\"=========================================\\n\")\n",
    "        f.write(f\"\\nTime Stamp: {now_str} :: Time Diff: {time_diff}  :: TGT_LANG:: {tgt_lang_code}\\n Messages: {messages} \\nInputs: {inputs} \\nOutput: {decoded}\\n\")\n",
    "        f.write(\"=========================================\\n\")\n",
    "        f.close()\n",
    "    # print(\"Response saved to file\")\n",
    "\n",
    "def sav_outputs(now_str, outputs, tgt_lang_code):\n",
    "    with open(tgt_lang_code + '_outputs_logs.txt', 'a+') as f:\n",
    "        # write decoded to file with timestamp now_str\n",
    "        f.write(\"=========================================\\n\")\n",
    "        f.write(f\"\\nTime Stamp: {now_str} :: TGT_LANG:: {tgt_lang_code} \\nOutput: **<<{str(outputs)}>>**\\n\")\n",
    "        f.write(\"=========================================\\n\")\n",
    "        f.close()\n",
    "    # print(\"Outputs saved to file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "def get_message(tgt_lang = 'Hindi', examples=None, num=7, topic='law', prompt=None, mapping=None):\n",
    "        \n",
    "        prompt = '''Generate total ''' +str((len(mapping)*num)) +\" \"+ tgt_lang+''' sentences and return a python dictionary where  keys are ''' + str(mapping) + '''\n",
    "and each of the corresponding values are the list of ''' +str((num)) +\" \"+ tgt_lang+''' sentences corresponding to using each relation and using the topic: '''+ topic +'''. Generate gramatically correct sentences where each given relation is used respectively.\n",
    "Do not associate with any bias or stereotypes associated with subject, relation and gender. No need of comments or explanations or English texts. Make the sentences as varied as possible. While generating relations in ''' +tgt_lang+''' sentences, do not use neutral terms.\n",
    "Generate the sentences for the above mentioned relations and not exactly same as the given examples.'''\n",
    "              \n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant that understands \"+tgt_lang+\" and can generate sentences in \"+tgt_lang+\".\"}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt+'''\n",
    "                    Sample Output:\n",
    "                    sentences = ''' +str(examples)\n",
    "        }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        return messages\n",
    "\n",
    "\n",
    "def get_prompt_inputs(processor, messages, model, add_gen_prompt=True, tokenize=True, return_dict=True, return_tensors=\"pt\"):\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages, add_generation_prompt=add_gen_prompt, tokenize=tokenize,\n",
    "        return_dict=return_dict, return_tensors=return_tensors,\n",
    "    ).to(model.device, dtype=torch.bfloat16)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def get_decoded_response(model, processor, inputs, max_new_tokens=MAX_NEW_TOKENS, do_sample=False, temperature=1.5, num_return_sequences=1):\n",
    "    input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=do_sample, \n",
    "                                    temperature=temperature, num_return_sequences=num_return_sequences, \n",
    "                                    max_length=input_len + max_new_tokens)\n",
    "        generation = generation[0][input_len:]\n",
    "\n",
    "    decoded = processor.decode(generation, skip_special_tokens=True)\n",
    "    # print(decoded)\n",
    "    return decoded\n",
    "\n",
    "# **Overall Impression:** The image is a close-up shot of a vibrant garden scene, \n",
    "# focusing on a cluster of pink cosmos flowers and a busy bumblebee. \n",
    "# It has a slightly soft, natural feel, likely captured in daylight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extracted_text(text):\n",
    "    start_ind = text.find('```python')\n",
    "    end_ind = text.find('```', start_ind+1)\n",
    "    # if end_idx not found then last index of text\n",
    "    if end_ind == -1:\n",
    "        end_ind = len(text)\n",
    "    extracted_text = text[start_ind:end_ind]\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pir['grandfather']['ory_Orya'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate as per topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in model_ids_gemma:\n",
    "    tokenizer, model, processor = model_init(model_path)\n",
    "    for word in tqdm.tqdm(ambiguos_words):\n",
    "        for topic in tqdm.tqdm(topics):\n",
    "            for tgt_lang in tqdm.tqdm(lang_script_list):\n",
    "                print(\"Word: \", word, \"Topic: \", topic, \"TGT_LANG: \", tgt_lang)\n",
    "                now_str = get_now_str()\n",
    "                start_time = dt.datetime.strptime(now_str, datetime_format)\n",
    "                save_logs(now_str, 'Model: '+model_path + '\\nword: '+ word+ '\\nTopic: '+topic + '\\nTGT_LANG: '+tgt_lang + '\\nTASK : Generating data for relations', tgt_lang_code=tgt_lang)\n",
    "                # messages = get_message(examples= examples, topic=topic)\n",
    "                messages = get_message(tgt_lang=tgt_lang, examples= examples_coll[tgt_lang], topic=topic, num =3,   mapping= list(pir[word][tgt_lang].keys()) )\n",
    "                inputs = get_prompt_inputs(processor, messages, model)\n",
    "                now_str2 = get_now_str()\n",
    "                end_time = dt.datetime.strptime(now_str2, datetime_format)\n",
    "                save_logs(now_str2, messages, inputs=inputs['input_ids'], time_diff=  end_time-start_time, tgt_lang_code=tgt_lang)\n",
    "                start_time = end_time\n",
    "                decoded = get_decoded_response(model, processor, inputs)\n",
    "                now_str3 = get_now_str()\n",
    "                end_time = dt.datetime.strptime(now_str3, datetime_format)\n",
    "                save_logs(now_str3, decoded=decoded, time_diff= end_time-start_time, tgt_lang_code=tgt_lang)\n",
    "                extracted_txt = get_extracted_text(decoded)\n",
    "                now_str = get_now_str()\n",
    "                sav_outputs(now_str, extracted_txt, tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# indic_sent_dict Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_sent_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sample dictionary structure\n",
    "# Convert the dictionary to a list of rows (one row per sentence)\n",
    "rows = []\n",
    "for word, lang_dict in indic_sent_dict.items():\n",
    "    for lang, term_dict in lang_dict.items():\n",
    "        for indic_term, sentences in term_dict.items():\n",
    "            for sentence in sentences:\n",
    "                rows.append({\n",
    "                    'word': word,\n",
    "                    'lang': lang,\n",
    "                    'indic_term': indic_term,\n",
    "                    'sentence': sentence\n",
    "                })\n",
    "\n",
    "# Write to CSV\n",
    "with open('output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['word', 'lang', 'indic_term', 'sentence']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"CSV file 'output.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_eng(sents=None, rootword=None, tgt_lang = 'Hindi', examples=None):\n",
    "        prompt = '''Return the python list of English sentences using the word \"'''+rootword+'''\" as the translation of following sentences in ''' +tgt_lang+ '\\n'+ \"\\n- \".join(sents)+'''\n",
    "No need to write explaination and do not specify maternal or paternal. Simply provide Python list containing '''+ str(len(sents)) +'''  English sentences as shown below. '''\n",
    "\n",
    "                  \n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant that correctly translates from \"+tgt_lang+\" to English.\"}]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt+'''\n",
    "                    Sample Python Code Output:\\sentences = ''' +(str(examples[:len(sents)]) if examples else str(examples))\n",
    "        }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translations = pd.DataFrame(columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in model_ids_gemma:\n",
    "    tokenizer, model, processor = model_init(model_path)\n",
    "\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_str = get_now_str()\n",
    "now_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(code):\n",
    "    # print(\"code:\", code)\n",
    "    # Remove any unwanted characters or formatting\n",
    "    arr = []\n",
    "    # deep copy code to a temp variable\n",
    "    code_temp = code\n",
    "    code = code.strip()\n",
    "    code = code.replace(\"...\", \"\")\n",
    "    search_str = '```python\\nsentences = '\n",
    "    start_idx = code.find(search_str)\n",
    "    end_idx = code.find(']', start_idx+1)\n",
    "    code = code[start_idx+len(search_str):]\n",
    "    # print(\"end_idx of ]:\", end_idx)\n",
    "    if end_idx == -1 :\n",
    "        # print(\"code this:\", code)\n",
    "        code = code.strip()\n",
    "        if not code.endswith(']'):\n",
    "            code = code.strip()\n",
    "            if code.endswith(\".'\") or code.endswith('.\"'):\n",
    "                code = code + \"]\"\n",
    "            elif code.endswith(\" '\") or code.endswith(' \"'):\n",
    "                code = code[:-1] + \"]\"\n",
    "            else: \n",
    "                # Try to find the last incomplete string\n",
    "                match = re.findall(r'([\\'\"])[^\\'\"]*$' , code)\n",
    "                quote_type = match[-1] if match else '\"'  # fallback\n",
    "                # print(\"quote_type:\", quote_type, \"code:\", code)\n",
    "                # Step 1: Add missing closing quote if needed\n",
    "                if code.count(quote_type) % 2 != 0:\n",
    "                    code += quote_type\n",
    "                # Step 2: Add missing closing bracket if needed\n",
    "                if not code.endswith(\"]\"):\n",
    "                    code = code  + \"]\"\n",
    "    else:\n",
    "        code = code[: end_idx+1]\n",
    "            \n",
    "    try:\n",
    "        #  dict_code = eval(code\n",
    "        arr = ast.literal_eval(code)\n",
    "    except Exception as e:\n",
    "        print(\"\\n\\n! ! ! eval error code:\", code, \"\\n with error : \", e, '\\n code_temp', code_temp)\n",
    "\n",
    "    return arr\n",
    "\n",
    "stri= '''```python\n",
    "sentences = [\n",
    "    \"My grandmother told me stories.\",\n",
    "    \"My grandmother is a skilled weaver.\",\n",
    "    \"My grandmother told me stories about life.\",\n",
    "    \"My grandmother taught me how to make traditional dishes.\",\n",
    "    \"My grandmother told me stories about life.\",\n",
    "    \"My grandmother told me stories, which included struggles in life.\",\n",
    "    \"My grandm '''\n",
    "\n",
    "preprocess_text(stri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "indic_sent_dict['grandfather']['hin_Deva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for word in indic_sent_dict:\n",
    "        print(\">> Word: \", word)   \n",
    "        for lang_code in indic_sent_dict[word]:\n",
    "            print(\">>>> TGT_LANG: \", lang_code)\n",
    "            df_lang_word=None\n",
    "            df_lang_word = pd.DataFrame(columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])\n",
    "            transl_arr =[]\n",
    "            for key in indic_sent_dict[word][lang_code]:\n",
    "                print(\">>>>>> Key: \", key)\n",
    "                indic_sents = indic_sent_dict[word][lang_code][key]\n",
    "                # indic_sents = indic_sents[:45]\n",
    "                l = len(indic_sents)\n",
    "                l = l if l < 5 else 5\n",
    "                indic_sents = indic_sents[:l]\n",
    "                for i in tqdm.tqdm(range(0, len(indic_sents), batch_size)):\n",
    "                    batch = indic_sents[i:i+batch_size]\n",
    "\n",
    "                    sents = batch\n",
    "                    now_str1 = get_now_str()        \n",
    "                    start_time = dt.datetime.strptime(now_str1, datetime_format)\n",
    "                    save_logs(now_str1, messages= 'Model: '+model_path + '\\n Task: English equivalents; i: '+ str(i )+ '\\nBatch Size: '+  str(batch_size))\n",
    "                    # messages = get_message(examples= examples, topic=topic)\n",
    "                    messages = get_message_eng(tgt_lang=lang_code_map[lang_code], rootword=word, sents=sents)\n",
    "                    inputs = get_prompt_inputs(processor, messages, model)\n",
    "                    now_str2 = get_now_str()\n",
    "                    end_time = dt.datetime.strptime(now_str2, datetime_format)\n",
    "                    save_logs(now_str2, messages, inputs, time_diff=  end_time-start_time)\n",
    "                    start_time = end_time\n",
    "                    decoded = get_decoded_response(model, processor, inputs, max_new_tokens=100)\n",
    "                    now_str3 = get_now_str()\n",
    "                    end_time = dt.datetime.strptime(now_str3, datetime_format)\n",
    "                    save_logs(now_str3, decoded=decoded, time_diff= end_time-start_time, tgt_lang_code=lang_code)\n",
    "                    extracted_txt = get_extracted_text(decoded)\n",
    "                    # print(\"Extracted Text: \", extracted_txt, type(extracted_txt))\n",
    "                    now_str4 = get_now_str()\n",
    "                    sav_outputs(now_str4, extracted_txt, lang_code)\n",
    "                    eng_sents = preprocess_text(extracted_txt)\n",
    "                    print(\"English Sentences length: \", len(eng_sents), \"sents length: \", len(sents))\n",
    "                    temp_arr = []\n",
    "                    for _ in range(len(eng_sents)):\n",
    "                        temp_arr.append([word, eng_sents[_], sents[_], lang_code, key])\n",
    "                    # break\n",
    "                    # if i > 1* batch_size:\n",
    "                    #     break\n",
    "                print(\"Batch processed: \", i, \"size : \", len(temp_arr), \"size of transl_arr: \", len(transl_arr))\n",
    "                transl_arr.extend(temp_arr)\n",
    "                print(\"Total translations so far: \", len(transl_arr), transl_arr)   \n",
    "                temp_arr=[]\n",
    "                # df_translations = pd.concat([df_translations, pd.DataFrame(transl_arr, columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])], ignore_index=True\n",
    "                # )\n",
    "                # df_translations.to_csv('translations'+now_str4+'.csv', index=False)\n",
    "            print(len(transl_arr), df_lang_word.shape)\n",
    "            df_lang_word = pd.concat([df_lang_word, pd.DataFrame(transl_arr, columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])], ignore_index=True\n",
    "            )\n",
    "            df_lang_word.to_csv('translations_'+word+'_'+lang_code+now_str4+'.csv', index=False)\n",
    "            # break\n",
    "except Exception as e:\n",
    "    print(\"!!! Error: \", e)\n",
    "    print(\"Word: \", word, \"TGT_LANG: \", lang_code, \"i: \", i)\n",
    "    print(\"Batch Size: \", batch_size, '\\n sents: ', sents)\n",
    "    print(\"Decoded: \", decoded)\n",
    "    print(\"Extracted Text: \", extracted_txt)\n",
    "    # print(\"Inputs: \", inputs['input_ids'])\n",
    "    print(\"Messages: \", messages)\n",
    "    print(\"Error in processing the word and language\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_arr = []\n",
    "for _ in range(len(eng_sents)):\n",
    "    temp_arr.append([word, eng_sents[_], sents[_], lang_code, key])\n",
    "    # break\n",
    "    # if i > 1* batch_size:\n",
    "    #     break\n",
    "transl_arr.extend(temp_arr)\n",
    "                # temp_arr=[]\n",
    "                # df_translations = pd.concat([df_translations, pd.DataFrame(transl_arr, columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])], ignore_index=True\n",
    "                # )\n",
    "                # df_translations.to_csv('translations'+now_str4+'.csv', index=False)\n",
    "print(len(transl_arr), df_lang_word.shape)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_lang_word = pd.concat([df_lang_word, pd.DataFrame(transl_arr, columns=['word', 'eng_text','tgt_lang_text', 'tgt_lang', 'indic_text'])], ignore_index=True\n",
    "            )\n",
    "            df_lang_word.to_csv('translations_'+word+'_'+lang_code+now_str4+'.csv', index=False)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lang_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break runn all:)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To generate from prompt list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effective_text(text, combo):\n",
    "    msg ={}\n",
    "    try:\n",
    "        search_str = '```python\\nsentences = '\n",
    "        start_ind = text.find(search_str)\n",
    "        end_ind = text.find('```', start_ind+1)\n",
    "        # if end_idx not found then last index of text\n",
    "        if end_ind == -1:\n",
    "            end_ind = len(text)\n",
    "        extracted_text = text[start_ind+len(search_str):end_ind]\n",
    "        extracted_text = extracted_text.replace('\\n', '')\n",
    "\n",
    "        # if extracted text ends with ] then take whole text else, take till last occurence '\",'\n",
    "        if not extracted_text.endswith(']'):\n",
    "            last_ind = extracted_text.rfind('\",')\n",
    "            if last_ind != -1:\n",
    "                extracted_text = extracted_text[:last_ind+1] + ']'\n",
    "            else:\n",
    "                print(\"Invalid list:: for text\", text, \" ; extracted_txt: \", extracted_text)\n",
    "                extracted_text = extracted_text + ']'\n",
    "\n",
    "        if 'male' in combo:\n",
    "            msg[0] =    ast.literal_eval(extracted_text)\n",
    "        elif 'female' in combo:\n",
    "            msg[1] = ast.literal_eval(extracted_text)   \n",
    "        else:\n",
    "            msg[2] = ast.literal_eval(extracted_text)\n",
    "    except Exception as e:\n",
    "        print(\"Error in extracting text: \", e)\n",
    "        save_logs(\"Error in extracting text: \", e, text) \n",
    "    return str(msg)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import random\n",
    "\n",
    "# Define the dimensions\n",
    "politeness_forms = ['polite', 'non-polite']\n",
    "genders = ['male', 'female', 'they']\n",
    "persons = ['first', 'second', 'third']\n",
    "tenses = [\n",
    "    'present simple', 'present continuous', 'present perfect', 'present perfect continuous',\n",
    "    'past simple', 'past continuous', 'past perfect', 'past perfect continuous',\n",
    "    'future'\n",
    "]\n",
    "\n",
    "# Generate all 162 combinations\n",
    "# combinations = list(product(politeness_forms, genders, persons, tenses))\n",
    "tenses = [\n",
    "    'present simple', 'present continuous', 'present perfect', 'present perfect continuous',\n",
    "    'past simple', 'past continuous', 'past perfect', 'past perfect continuous',\n",
    "    'future'\n",
    "]\n",
    "\n",
    "# First person: polite doesn't matter; gender matters only in past tenses\n",
    "first_person_combinations = []\n",
    "for tense in tenses:\n",
    "    if 'past' in tense:\n",
    "        for gender in ['male', 'female']:\n",
    "            first_person_combinations.append(('first', gender, 'neutral', tense))\n",
    "    else:\n",
    "        first_person_combinations.append(('first', 'neutral', 'neutral', tense))\n",
    "\n",
    "# Second person: tu, tum, aap = different politeness forms\n",
    "# Gender matters in past tenses\n",
    "second_person_combinations = []\n",
    "for politeness in ['tu', 'tum', 'aap']:\n",
    "    for tense in tenses:\n",
    "        if 'past' in tense:\n",
    "            for gender in ['male', 'female']:\n",
    "                second_person_combinations.append(('second', gender, politeness, tense))\n",
    "        else:\n",
    "            second_person_combinations.append(('second', 'neutral', politeness, tense))\n",
    "\n",
    "# Third person:\n",
    "# Singular (male/female): gender matters\n",
    "# Plural (they): gender-neutral\n",
    "third_person_combinations = []\n",
    "for tense in tenses:\n",
    "    for gender in ['male', 'female']:\n",
    "        third_person_combinations.append(('third', gender, 'neutral', tense))\n",
    "    third_person_combinations.append(('third', 'they', 'neutral', tense))\n",
    "\n",
    "# Merge all\n",
    "valid_combinations = (\n",
    "    first_person_combinations +\n",
    "    second_person_combinations +\n",
    "    third_person_combinations\n",
    ")\n",
    "\n",
    "# Example function to generate a prompt for a given combination\n",
    "def generate_prompt(target_language, politeness, gender, person, tense, num_verbs=80):\n",
    "    # return (\n",
    "    #     f\"Generate a python list of {num_verbs} distinct, unique and various verbs in {target_language} that are in the form of:\\n\"\n",
    "    #     f\"- Tense: {tense}\\n\"\n",
    "    #     f\"- Person: {person} person\\n\"\n",
    "    #     f\"- Gender: {gender}\\n\"\n",
    "    #     f\"- Politeness: {politeness} form\\n\"\n",
    "    #     f\"Provide only the python list of conjugated verbs in {target_language} only without translations or explanations.\"\n",
    "    # )\n",
    "    polite_note = f\" using the '{politeness}' form\" if person == 'second' else \"\"\n",
    "    gender_note = \"\" if gender in ['neutral', 'they'] else f\" for {gender} subject\"\n",
    "    return (\n",
    "        f\"Generate a list of {num_verbs} unique verbs in {target_language} that are in the form of:\\n\"\n",
    "        f\"- Tense: {tense}\\n\"\n",
    "        f\"- Person: {person} person{polite_note}{gender_note}.\\n\"\n",
    "        f\"Provide only the python list of conjugated verbs in {target_language} only without translations or explanations. Give gramatically correct phrases for the mentioned gender and tense.\\n\"\n",
    "    )\n",
    "\n",
    "# Example of generating prompts for all combinations\n",
    "target_language = \"Hindi\"  # or any language of your choice\n",
    "prompts = [\n",
    "    {\n",
    "        \"combination\": combo,\n",
    "        \"prompt\": generate_prompt(target_language, *combo)\n",
    "    }\n",
    "    # for combo in combinations\n",
    "    for combo in valid_combinations\n",
    "]\n",
    "print(\"Total prompts generated: \", len(prompts))\n",
    "# Example: print a few prompts\n",
    "for i in range(3, 6):\n",
    "    print(f\"Prompt for combination {prompts[i]['combination']}:\\n{prompts[i]['prompt']}\\n{'-'*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of prompts: \", len(prompts))\n",
    "prompts[6:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_path in model_ids_gemma:\n",
    "    tokenizer, model, processor = model_init(model_path)\n",
    "    for prompt in tqdm.tqdm(prompts):\n",
    "        topic = prompt['combination']\n",
    "        now_str = get_now_str()\n",
    "        start_time = dt.datetime.strptime(now_str, datetime_format)\n",
    "        save_logs(now_str, 'Model: '+model_path + '\\nTopic: '+ str(topic))\n",
    "        # messages = get_message(examples= examples, topic=topic)\n",
    "        messages = get_message(tgt_lang=TGT_LANG,  topic=topic,   prompt=prompt['prompt'], examples= examples , prompt_type=None)\n",
    "        inputs = get_prompt_inputs(processor, messages, model)\n",
    "        now_str2 = get_now_str()\n",
    "        end_time = dt.datetime.strptime(now_str2, datetime_format)\n",
    "        save_logs(now_str2, messages, inputs, time_diff=  end_time-start_time)\n",
    "        start_time = end_time\n",
    "        decoded = get_decoded_response(model, processor, inputs)\n",
    "        now_str3 = get_now_str()\n",
    "        end_time = dt.datetime.strptime(now_str3, datetime_format)\n",
    "        save_logs(now_str3, decoded=decoded, time_diff= end_time-start_time)\n",
    "        # extracted_txt = get_extracted_text(decoded)\n",
    "        effective_txt = get_effective_text(decoded, combo=topic)\n",
    "        now_str = get_now_str()\n",
    "        sav_outputs(now_str, effective_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break all the code into functions and run the code in a loop for all the models and topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the model you need to use. Use the above to see the list of models.\n",
    "model_name_or_path = \"/assets/models/mistralai-mistral-instruct-7b-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install protobuf\n",
    "# %pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "print(\"tokenizer loaded\")\n",
    "\n",
    "# LLaMa's tokenizer does not have a valid PAD token, so we need to initialize this as so\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# For decoder-only models, just to be safe, also do:\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    # By default, map different parts of the model to available GPU(s).\n",
    "    device_map=\"auto\",\n",
    "    # Loading the model in full precision can use a lot of\n",
    "    # of memory, so we quantize it using reduced precision types.\n",
    "    torch_dtype='bfloat16'\n",
    ")\n",
    "\n",
    "# Best practices\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on using the transformers library and its components can be found here: https://huggingface.co/docs/transformers/llm_tutorial\n",
    "\n",
    "Specifically, for text generation, the following can be useful:\n",
    "- https://huggingface.co/docs/transformers/main/en/main_classes/text_generation\n",
    "- https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PROMPT = '''Generate 10 English sentences each for the relations: \n",
    "grandmother, grandfather, uncle, aunt, brother-in-law, sister-in-law, cousin, nephew, niece. \n",
    "For each relation, generate 10 sentences using the following topics: games, deep talks, questions, exclamations, and other forms of speeches. \n",
    "Ensure the sentences include different forms of possessive pronouns (e.g., my, their, his, her) for each of the 9 relations. Avoid using short/colloquial terms for the relations.\n",
    "Only provide the response as a Python list of strings for all categories. No need to segregate them in any manner.\n",
    "Sample output: \n",
    "<<<[\n",
    "\"My grandmother and I play chess together.\", \n",
    "...\n",
    "\"Their grandfather and I have deep talks.\", \n",
    "...\n",
    "\"Due to the heartache, my brother-in-law was not present in the function.\",\n",
    "...\n",
    "\"For the party, my uncle will pick and drop you.\",\n",
    "...\n",
    "\"I have the best sister-in-law in the world!\",\n",
    "...\n",
    "\"I am very grateful to my aunt to take care of my mother when I was not available\",\n",
    "...\n",
    "... \n",
    "] (total 90 sentences: for each relation -> 10 sentences)>>>'''\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(\n",
    "            **inputs.to(model.device),\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=2,\n",
    "            num_beams=5,\n",
    "            max_new_tokens=1000\n",
    "        )\n",
    "\n",
    "        outputs = tokenizer.batch_decode(\n",
    "            outputs, skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for output in outputs:\n",
    "#     print(\"o/p::\", output)\n",
    "    # print('-' * 50)\n",
    "    # print()\n",
    "# save the outputs to a file named : generated_outputs.txt\n",
    "# open in append mode\n",
    "\n",
    "def save_outputs(outputs):\n",
    "    with open('generated_outputs_hin_mf.txt', 'a') as f:\n",
    "        for output in outputs:\n",
    "            f.write(output + '\\n')\n",
    "            # print(output)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(outputs, prompt):\n",
    "    response = outputs[0]\n",
    "    sentences = response[response.find(prompt) + len(prompt):]\n",
    "    sentences = sentences[sentences.find('{') :sentences.find('}')]  \n",
    "    print(sentences)\n",
    "    # sentences = sentences.split(',\\n')\n",
    "    # sentences = [sentence.strip() for sentence in sentences]\n",
    "    # sentences = [sentence[1:-1] for sentence in sentences]\n",
    "    # print(sentences, type(sentences))\n",
    "    return sentences\n",
    "\n",
    "# extract_sentences(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sentences to a file named : generated_sentences.txt\n",
    "def save_sentences(sentences):\n",
    "    with open('generated_sentences_hin_mf.txt', 'a+') as f:\n",
    "        # for sentence in sentences:\n",
    "            f.write(sentences + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts=[]\n",
    "# techniques = examples.keys()\n",
    "topics=[\"occupation\", \" religion\", \" sport\", \" politics\", \"  health\", \" finance\", \" education\", \" farming\", \" entertainment\", \"  news\", \"  daily conversation\", \"  weather\", \" technology\", \" conflicts\", \" controversials\", \n",
    "        \" international\", \"  UN\", \" travel\", \" tourism\", \" shopping\", \" baby care\", \" valentines\", \"  soldiers\", \" prisioners\", \" soul actions\", \" nature\", \" pollution\", \" bio hazards\", \" elders\", \" family\", \n",
    "        \"  social studies\", \" maths\", \" literature\", \"  physics\", \" chemistry\", \"  biology\", \" Indian history \", \" civics\", \" geography\", \"  computer\", \" physical education\", \"  arts and craft\", \"  food\", \n",
    "        \" clothes\", \" water shortage\", \" road blockage\", \" traffic\", \" arriving late\", \" bargaining\", \" toys\", \" games\", \" deep talks\", \"declarative\", \"interrogative\", \"imperative\",  \"exclamatory\", \"safe work space\", \n",
    "        \"medical checkups\", \"self-reliant\", \"future India\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [ \"legal\", \"governance\",  \n",
    "  \"STEM\" ,   \"business\", \"sports\",  \"culture\", \"Alarm\",\n",
    "    \"Audio\",\n",
    "    \"Calendar / Events\",  # Added space for better readability\n",
    "    \"Communication\",\n",
    "    \"DateTime\",\n",
    "    \"Email\",\n",
    "    \"Finance\",  # Likely, but limited information available\n",
    "    \"General\",\n",
    "    \"Home Automation\",  # Likely, but limited information available\n",
    "    \"Location\",\n",
    "    \"Music\",\n",
    "    \"News\",\n",
    "    \"Reminders\",\n",
    "    \"Social Media\",  # Likely, but limited information available\n",
    "    \"Travel\",\n",
    "    \"Weather\",\n",
    "    \"BookRestaurant\",\n",
    "    \"BookFlight\",\n",
    "    \"BookHotel\",\n",
    "    \"GetDirections\",\n",
    "    \"GetPlaceDetails\",\n",
    "    \"GetWeather\",\n",
    "    \"SearchForInformation\",\n",
    "    \"GetNews\",\n",
    "    \"PlayMusic\",\n",
    "    \"ControlVolume\",\n",
    "    \"SetAlarm\",\n",
    "    \"CancelAlarm\",\n",
    "    \"SetReminder\",\n",
    "    \"MakeCall\",\n",
    "    \"SendMessage\",\n",
    "    \"SendEmail\",\n",
    "    \"CheckEmail\",\n",
    "    \"GetTime\",\n",
    "    \"GetDate\",\n",
    "    \"Greeting\",\n",
    "    \"Farewell\",\n",
    "    \"AskHowAreYou\",\n",
    "    \"ThankYou\",\n",
    "    \"TellAJoke\",\n",
    "    \"TurnOnLights\",  # and other home automation actions\n",
    "    \"Social media interactions\",  # posting, liking, etc.\n",
    "    \"Financial transactions\"  ]\n",
    "\n",
    "topics=topics[:3]\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for technique in techniques:\n",
    "    # pick every 10 topics from topics in a loop\n",
    "for i in tqdm.tqdm(range(0, len(topics))):\n",
    "    # print(topics[i:i+10])\n",
    "    # print(\"Generate 100 sentences in \"+ lang +\" with action doer as Male or Female. Differentiate between male and female sentences using the \"+ technique +\" technique. You can use the topics like \"+ \", \".join(topics[i:i+10]) +\".Return as a python dictionary.\")\n",
    "    # prompts.append(\"Generate 10 sentences in \"+ lang +\" with action doer as Male or Female. Differentiate between male and female sentences using the \"+ technique +\" technique. You can use the topics like \"+ \", \".join(topics[i:i+10]) +\".Return as a python dictionary.\")\n",
    "#     prompt = '''Generate 10 English sentences each for the relations: \n",
    "# grandmother, grandfather, uncle, aunt, brother-in-law, sister-in-law, cousin, nephew, niece. \n",
    "# For each relation, generate 10 sentences using the following topic: ''' + topics[i]+''' \n",
    "# Ensure the sentences include different forms of possessive pronouns (e.g., my, their, his, her) for each of the 9 relations. Avoid using short/colloquial terms for the relations.\n",
    "# Only provide the response as a Python list of strings for all categories. No need to segregate them in any manner.\n",
    "# Sample output: \n",
    "# <<<[\n",
    "# \"My grandmother and I play chess together.\", \n",
    "# ...\n",
    "# \"Their grandfather and I have deep talks.\", \n",
    "# ...\n",
    "# \"Due to the heartache, my brother-in-law was not present in the function.\",\n",
    "# ...\n",
    "# \"For the party, my uncle will pick and drop you.\",\n",
    "# ...\n",
    "# \"I have the best sister-in-law in the world!\",\n",
    "# ...\n",
    "# \"I am very grateful to my aunt to take care of my mother when I was not available\",\n",
    "# ...\n",
    "# ... \n",
    "# ] (total 90 sentences: for each relation -> 10 sentences)>>>'''  \n",
    "    prompt = '''Generate 10 Hindi sentences such that subject is male and female individually. Give the gender as key: 0 for Male and 1 for female.\n",
    "      For each gender, generate 5 sentences each for following topic: ''' + topics[i]+''' \n",
    "Only provide the response as a Python list of strings for all categories. No need to segregate them in any manner.\n",
    "Sample output: \n",
    "<<<{\n",
    " 0: [  \n",
    "            \"लेखक नई पुस्तक लिख रहा है।\",  \n",
    "            ...\n",
    "        ],  \n",
    "        1: [  \n",
    "            \"लेखिका नई पुस्तक लिख रही है।\",  \n",
    "            ... \n",
    "        ]  \n",
    "} (total 90 sentences: for each relation -> 10 sentences)>>>''' \n",
    "    prompts.append(prompt)\n",
    "\n",
    "    outputs= generate_response(prompt=prompt)\n",
    "    print(\"outputs done for topic: \", topics[i], i)\n",
    "    save_outputs(outputs)\n",
    "    sentences= extract_sentences(outputs, prompt)\n",
    "    print(\"sentences extracted for topic:\", topics[i], i)\n",
    "    save_sentences(sentences)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For RLHF'd models (LLaMa-3.1 Instruct, etc.), an additional prompt formatting step is needed to ensure that the model is able to generate the desired output. The template is applied using `tokenizer.apply_chat_template` function, and basically adds formatting tokens to your prompt. Use it only with instruction-fine-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install jinja2>=3.1.0\n",
    "\n",
    "# TASK_PROMPT = \"Please answer my question. What is the capital of India?\"\n",
    "# TASK_CONVERSATION = [\n",
    "#     # System Prompt: This is optional, and not all models support this.\n",
    "#     # But use it if you need explicit instructions to be followed.\n",
    "#     dict(role='system', content='You are a helpful assistant.'),\n",
    "#     # Your message (as if on the web interface) goes here.\n",
    "#     # Past history can be added to this conversation too.\n",
    "#     dict(role='user', content=TASK_PROMPT)\n",
    "# ]\n",
    "\n",
    "# # Format the conversation to a text prompt, using apply chat template.\n",
    "# conversation_prompt = tokenizer.apply_chat_template(\n",
    "#     TASK_CONVERSATION,\n",
    "#     tokenize=False,\n",
    "#     # Needed to allow the model to start its reply instead of completing yours.\n",
    "#     add_generation_prompt=True\n",
    "# )\n",
    "# # We skip special tokens because the template already adds them. This is an overlooked thing, so be careful.\n",
    "# inputs = tokenizer(conversation_prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "\n",
    "# # Generation process is the same as before.\n",
    "# with torch.inference_mode():\n",
    "#     outputs = model.generate(\n",
    "#         **inputs.to(model.device),\n",
    "#         temperature=0.2,\n",
    "#         do_sample=True,\n",
    "#         num_return_sequences=2,\n",
    "#         num_beams=2,\n",
    "#         max_new_tokens=10\n",
    "#     )\n",
    "\n",
    "#     outputs = tokenizer.batch_decode(\n",
    "#         outputs, skip_special_tokens=True,\n",
    "#         clean_up_tokenization_spaces=True\n",
    "#     )\n",
    "\n",
    "#     for output in outputs:\n",
    "#         print(output)\n",
    "#         print('-' * 50)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
