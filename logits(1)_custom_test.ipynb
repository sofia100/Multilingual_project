{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1, 3,5,7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES= 1, 3,5,7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/home/sofia/cache_custom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicTrans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import softmax\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4 # edited from 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization = None\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import possible_indic_relations as poss_indic_rel\n",
    "import span_encodings as sp_enc\n",
    "# Reload the module to reflect changes\n",
    "importlib.reload(poss_indic_rel)\n",
    "importlib.reload(sp_enc)\n",
    "\n",
    "pir= poss_indic_rel.possible_relations\n",
    "pir\n",
    "\n",
    "ambiguos_words = list(pir.keys())\n",
    "span_encodings = sp_enc.span_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span_encodings['ory_Orya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer(ckpt_dir, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir,  quantization)\n",
    "\n",
    "ip_en_ind = IndicProcessor(inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resolve_logits_for_best_beam(outputs, num_beams):\n",
    "    \"\"\" Resolve the logits from the best beam, using model output from a generate call.\n",
    "        For a shape [tokens?, batch_size*num_beams, vocab], returns [tokens?, batch_size, vocab]\n",
    "\n",
    "        Assumes num_return_sequences=1.\"\"\"\n",
    "\n",
    "    print(\"length of output beam\", len(outputs.beam_indices))\n",
    "    print(\"shape of beam_indices\", outputs.beam_indices.shape)\n",
    "    print(\"shape of logits\", (outputs.logits[0].shape))\n",
    "    print(\"length of logits\", len(outputs.logits))\n",
    "    print(\"length od outputs\", len(outputs))\n",
    "    best_logits  = []\n",
    "    beam_indices = [outputs.beam_indices[:, i].tolist() for i in range(len(outputs.logits)) if i < outputs.beam_indices.shape[1]]  \n",
    "    print(\"length of beam_indices\", len(beam_indices))\n",
    "\n",
    "    for beam_index, logits in zip(beam_indices, outputs.logits):\n",
    "        beam_index = [ idx if idx != -1 else ((num_beams*(i+1))-1) for i, idx in enumerate(beam_index) ]\n",
    "        best_logits.append(logits[beam_index,:])\n",
    "\n",
    "    return best_logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_logits_for_span(logits, translations, tokenizer, search_spans, span_encodings, lang):\n",
    "    \"\"\" Given search spans, returns the logits before the span was generated.\n",
    "\n",
    "    Args:\n",
    "        logits (tuple[Tensor]): Tuple of tensors, of shape [tokens?, batch_size, vocab]\n",
    "        sequences (tuple[list[int]]): Tokenized output sequences.\n",
    "        tokenizer (PreTrainedTokenizerBase): Tokenizer for the model.\n",
    "        search_spans (list[str]): batch_size spans to search for. Must be present in the generated sequences.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Tensor of shape [batch_size, vocab] indicating the logits before the span for each batch element.\n",
    "    \"\"\"\n",
    "    if isinstance(search_spans, str):\n",
    "        search_spans = [ search_spans ] * len(translations)\n",
    "\n",
    "    # with tokenizer.as_target_tokenizer():   \n",
    "    #     detok_outputs = tokenizer.batch_decode(translations, skip_special_tokens=True)\n",
    "\n",
    "    # positions = [ output.index(span) for output, span in zip(translations, search_spans) ]\n",
    "    logit_pos = [  ]\n",
    "\n",
    "    for seq,  span,  in zip(translations,  search_spans): \n",
    "        # print(\"Span to search for:\", span, span_encodings[lang])\n",
    "        key = next((k for k in span_encodings[lang].keys() if span in k), \"None\")\n",
    "        subtokens = span_encodings[lang][key]\n",
    "        print(\"subtokens\", subtokens)\n",
    "        print(\"for span:\", span, \"subtokens\", subtokens)\n",
    "        print(\"seq\", seq)\n",
    "        idx = 0\n",
    "        while idx < len(seq)-1:\n",
    "            if any( idx+i < len(seq) and seq[idx+i] == tok for i, tok in enumerate(subtokens)): \n",
    "                # print( \"found\", idx)\n",
    "                break\n",
    "            idx += 1\n",
    "        logit_pos.append(idx-1)\n",
    "    \n",
    "    print(\"logit_pos\", logit_pos)\n",
    "    print(\"Dimensions of logits\", logits[0].shape, len(logits))\n",
    "\n",
    "    selected_logits = []\n",
    "    # Iterate over each batch and corresponding token position\n",
    "    for batch, token in enumerate(logit_pos):\n",
    "        print(\"batch, token\", batch, token)\n",
    "        print(\"len(logits)\", len(logits))\n",
    "        print(\"Shape of logits\", logits[0].shape)\n",
    "        # print(\"logits token\", logits[token])\n",
    "        print(\"logits 1st item 1st row\",logits[0][0])\n",
    "        # Extract logits for the specific token position in the current batch\n",
    "        current_logit = logits[token][batch, :]\n",
    "        # current_logit = logits[token][0]\n",
    "        \n",
    "        # Append the selected logit to the list\n",
    "        selected_logits.append(current_logit)\n",
    "\n",
    "    # Stack the list of selected logits into a tensor\n",
    "    selected_logits = torch.stack(selected_logits)\n",
    "\n",
    "    return selected_logits\n",
    "        \n",
    "    # return selected_logits\n",
    "    # return torch.stack([ logits[token][batch,:] for batch, token in enumerate(logit_pos) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_spans(inp_sents, tgt_lang, translations):\n",
    "    search_spans= []\n",
    "    root_amb_words=[]\n",
    "    # print(\"inp_sents\", inp_sents)\n",
    "    for idx, inp in enumerate(inp_sents):\n",
    "        # check which word from ambiguos_Wwords in present in the input sentence\n",
    "        for word in ambiguos_words:\n",
    "            if word in inp:\n",
    "                curr_amb_word= word\n",
    "        root_amb_words.append(curr_amb_word)\n",
    "\n",
    "        # get the possible relations for the current ambiguous word\n",
    "        possible_relations= pir[curr_amb_word][tgt_lang].keys()\n",
    "        # print(\"Possible relations for the word\", curr_amb_word, \"in\", tgt_lang, \"are\", possible_relations)\n",
    "\n",
    "        # find the word in the translation from the possible relations. if not found print the translation\n",
    "        for rel in possible_relations:\n",
    "            if rel in translations[idx]:\n",
    "                # print(\"Relation found in the translation for the word\", curr_amb_word, \"in\", tgt_lang, \"in the sentence\", translations[idx], \"at \", translations[idx].index(rel), \"\\nso sentece is\", translations[idx][translations[idx].index(rel):])\n",
    "                search_spans.append(rel)\n",
    "                break\n",
    "        else:\n",
    "            # print(\"No relation found in the translation for the word\", curr_amb_word, \"in\", tgt_lang, \"in the sentence\", translations[idx])\n",
    "            search_spans.append(translations[idx][0])\n",
    "    # print(\"Search spans are\", search_spans)\n",
    "    return root_amb_words, search_spans\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip, span_encodings):\n",
    "    translations = []\n",
    "    start_logits = []\n",
    "    root_amb_words = []\n",
    "    searched_spans = []\n",
    "    for i in tqdm(range(0, len(input_sentences), BATCH_SIZE)):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            # generated_tokens = model.generate(\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1, # TODO temp\n",
    "                output_scores=True,\n",
    "                output_logits=True,\n",
    "                return_dict_in_generate=True,\n",
    "\n",
    "            )\n",
    "            print(\"Length of outputs.logits actual\", len(outputs.logits))\n",
    "            print(\"Shape of outputs.logits actual\", outputs.logits[0].shape)\n",
    "\n",
    "            print(\"Length of outputs.beam_indices actual\", len(outputs.beam_indices))\n",
    "            print(\"Shape of outputs.beam_indices actual\", outputs.beam_indices.shape)\n",
    "            print(\"*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?**********\", outputs.beam_indices.shape[1] == len(outputs.logits))\n",
    "            \n",
    "            outputs.beam_indices = outputs.beam_indices.cpu()\n",
    "            outputs.logits = tuple(logits.cpu() for logits in outputs.logits)               \n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = outputs.sequences\n",
    "        # print(\"len generated_tokens: \", (generated_tokens[0]).shape)\n",
    "        # print(\"1st generated token: \", generated_tokens[0])\n",
    "        vector = generated_tokens.detach().cpu().tolist()\n",
    "        # print(\"length of outputs vectors: \", len(vector), len(vector[0]))\n",
    "        # print(\"vector of generated_tokens: \", vector)\n",
    "        # print(\"1st vector: \", vector[0])\n",
    "\n",
    "\n",
    "\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            decoded_op = tokenizer.batch_decode(\n",
    "                vector,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "\n",
    "        # print(\"1st decoded_op: \", decoded_op[0])\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        transl = ip.postprocess_batch(decoded_op, lang=tgt_lang)\n",
    "\n",
    "        # print(\"translations: \", transl)\n",
    "        \n",
    "\n",
    "        root_words, search_spans = get_search_spans(batch,  tgt_lang, transl)\n",
    "        searched_spans += search_spans\n",
    "        root_amb_words += root_words\n",
    "        # print(\"length search_spans: \", len(search_spans))\n",
    "        best_logits = resolve_logits_for_best_beam(outputs, num_beams=5)\n",
    "        # print(\"length best_logits: \",len(best_logits))\n",
    "        # print(\"length of best_logits: \", len(best_logits), (best_logits[0]).shape)\n",
    "\n",
    "        start_logits += get_logits_for_span(best_logits, outputs.sequences, tokenizer, search_spans, span_encodings, tgt_lang)\n",
    "        # start_logits += get_logits_for_span(best_logits, translations, tokenizer, search_spans)\n",
    "        translations += transl\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations, start_logits, root_amb_words, searched_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_script_list = [\n",
    "    'hin_Deva', \n",
    "    'guj_Gujr',\n",
    "    'mar_Deva', \n",
    "    'ory_Orya',\n",
    "     'ben_Beng', \n",
    "    'tam_Taml', \n",
    "    'pan_Guru',\n",
    "     'tel_Telu',\n",
    "      'mal_Mlym', 'kan_Knda', \n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_folder = 'custom_test_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code_map = {\n",
    "    'eng_Latn': 'en',\n",
    "    'hin_Deva': 'hi',\n",
    "    'guj_Gujr': 'gu',\n",
    "    'kan_Knda': 'kn',\n",
    "    'mal_Mlym': 'ml',\n",
    "    'mar_Deva': 'mr',\n",
    "    'tam_Taml': 'ta',\n",
    "    'tel_Telu': 'te',\n",
    "    'pan_Guru': 'pa',\n",
    "    'ben_Beng': 'bn',\n",
    "    'ory_Orya': 'or'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "with open('test_sentences_eng.txt', 'r') as f:\n",
    "    sents = f.readlines()\n",
    "sents = [sent.strip() for sent in sents if sent.find('child')==-1]\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE_SIZE = 10\n",
    "SAMPLE_SIZE = len(sents)\n",
    "sents = sents[:SAMPLE_SIZE]\n",
    "# sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tel_Telu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [1774, 1476]\n",
      "for span: అమ్మమ subtokens [1774, 1476]\n",
      "seq tensor([    2,   354,  1774,  1476, 56061,  3494,   728,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [1774, 1476]\n",
      "for span: మ subtokens [1774, 1476]\n",
      "seq tensor([    2,   354, 14552,   151, 56061,  3494,   728,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [1774, 1476]\n",
      "for span: మ subtokens [1774, 1476]\n",
      "seq tensor([    2,   354, 30539, 56061,  3494,   728,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [11569, 20269]\n",
      "for span: అత్త subtokens [11569, 20269]\n",
      "seq tensor([    2,    46, 11569, 56061,  3494,   728,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 7, 7, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.2793, -1.2793,  0.6104,  ..., -1.2793, -1.2793, -1.2793],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 7\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.2793, -1.2793,  0.6104,  ..., -1.2793, -1.2793, -1.2793],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 7\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.2793, -1.2793,  0.6104,  ..., -1.2793, -1.2793, -1.2793],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.2793, -1.2793,  0.6104,  ..., -1.2793, -1.2793, -1.2793],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 12\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 10])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 10])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 12\n",
      "length od outputs 6\n",
      "length of beam_indices 10\n",
      "subtokens [14581, 471, 4645]\n",
      "for span: న subtokens [14581, 471, 4645]\n",
      "seq tensor([    2,    46, 19360, 56061,  3494,   728,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [76, 2621, 20269]\n",
      "for span: వదిన subtokens [76, 2621, 20269]\n",
      "seq tensor([    2,    46,    76,  2621, 56061,  3494,   728,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [14581, 471, 4645]\n",
      "for span: న subtokens [14581, 471, 4645]\n",
      "seq tensor([    2,    46,  2922,  3432, 56061,  3494,   728,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [14581, 471, 4645]\n",
      "for span: న subtokens [14581, 471, 4645]\n",
      "seq tensor([    2,    46, 14581,   471,  4645, 56061,  3494,   728,     4,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [8, 1, 8, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 10\n",
      "batch, token 0 8\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.9868, -0.9863,  0.6440,  ..., -0.9868, -0.9863, -0.9863],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.9868, -0.9863,  0.6440,  ..., -0.9868, -0.9863, -0.9863],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 8\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.9868, -0.9863,  0.6440,  ..., -0.9868, -0.9863, -0.9863],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.9868, -0.9863,  0.6440,  ..., -0.9868, -0.9863, -0.9863],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 11\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 10])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 10])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 11\n",
      "length od outputs 6\n",
      "length of beam_indices 10\n",
      "subtokens [14581, 307, 12563]\n",
      "for span: మేనకోడలు subtokens [14581, 307, 12563]\n",
      "seq tensor([    2,    46, 14581,   307, 12563, 56061,  3494,   728,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [1774, 1476]\n",
      "for span: అమ్మమ subtokens [1774, 1476]\n",
      "seq tensor([    2,    46,  1774,  1476, 64275, 20903,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 10\n",
      "batch, token 0 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-1.0410, -1.0410,  0.5488,  ..., -1.0410, -1.0410, -1.0410],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-1.0410, -1.0410,  0.5488,  ..., -1.0410, -1.0410, -1.0410],\n",
      "       dtype=torch.float16)\n",
      "ory_Orya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [41445, 241, 30]\n",
      "for span: ଜେଜେମା subtokens [41445, 241, 30]\n",
      "seq tensor([    2,   644, 41445,   241,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [41445, 1007, 1714]\n",
      "for span: ଜେଜେବାପା subtokens [41445, 1007, 1714]\n",
      "seq tensor([    2,   644, 41445,  1007,  1714,  4725, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [9971, 19212, 6]\n",
      "for span: ମାମୁଁ subtokens [9971, 19212, 6]\n",
      "seq tensor([    2,   644,  9971, 19212,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [30261, 694, 6]\n",
      "for span: ମାଉସୀ subtokens [30261, 694, 6]\n",
      "seq tensor([    2,   644, 30261,   694,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7988, -0.7988,  0.3975,  ..., -0.7988, -0.7988, -0.7988],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7988, -0.7988,  0.3975,  ..., -0.7988, -0.7988, -0.7988],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7988, -0.7988,  0.3975,  ..., -0.7988, -0.7988, -0.7988],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7988, -0.7988,  0.3975,  ..., -0.7988, -0.7988, -0.7988],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [5442, 1754, 89]\n",
      "for span: ଭିଣୋଇ subtokens [5442, 1754, 89]\n",
      "seq tensor([    2,   644,  5442,  1754,    89,  4725, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [4569, 25547]\n",
      "for span: ଭାଉଜ subtokens [4569, 25547]\n",
      "seq tensor([    2,   644,  4569, 25547,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [60824, 3991, 6]\n",
      "for span: ଭାଇ subtokens [60824, 3991, 6]\n",
      "seq tensor([    2,  4433, 60824,  3991,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [4300, 5686]\n",
      "for span: ପୁତୁରା subtokens [4300, 5686]\n",
      "seq tensor([    2,   644,  4300,  5686,  4725, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6348, -0.6348,  0.9517,  ..., -0.6348, -0.6348, -0.6348],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6348, -0.6348,  0.9517,  ..., -0.6348, -0.6348, -0.6348],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6348, -0.6348,  0.9517,  ..., -0.6348, -0.6348, -0.6348],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6348, -0.6348,  0.9517,  ..., -0.6348, -0.6348, -0.6348],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 9])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [980, 9742, 795]\n",
      "for span: ଭାଣିଜୀ subtokens [980, 9742, 795]\n",
      "seq tensor([    2,  4433,   980,  9742,   795,  4725, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [41445, 241, 30]\n",
      "for span: ଜେଜେମା subtokens [41445, 241, 30]\n",
      "seq tensor([    2,   644, 41445,   241,  4725, 65121,  2383,     6,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6582, -0.6582,  0.9565,  ..., -0.6587, -0.6587, -0.6587],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6582, -0.6582,  0.9565,  ..., -0.6587, -0.6587, -0.6587],\n",
      "       dtype=torch.float16)\n",
      "pan_Guru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 12\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 11])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 11])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 12\n",
      "length od outputs 6\n",
      "length of beam_indices 11\n",
      "subtokens [29498, 640]\n",
      "for span: ਦਾਦੀ subtokens [29498, 640]\n",
      "seq tensor([    2,  1653, 29498,    88,    19,    75, 61699, 10002,     8,     6,\n",
      "            2], device='cuda:0')\n",
      "subtokens [15588, 613]\n",
      "for span: ਦਾਦਾ subtokens [15588, 613]\n",
      "seq tensor([    2,   790, 15588,    88,    19,    75, 61699, 10002,   180,     6,\n",
      "            2], device='cuda:0')\n",
      "subtokens [34059]\n",
      "for span: ਚਾਚਾ subtokens [34059]\n",
      "seq tensor([    2,   790, 34059,    88,    19,    75, 61699, 10002,   180,     6,\n",
      "            2], device='cuda:0')\n",
      "subtokens [65770, 613, 6]\n",
      "for span: ਮਾਸੀ subtokens [65770, 613, 6]\n",
      "seq tensor([    2,  1653, 65770,    88,    19,    75, 61699, 10002,     8,     6,\n",
      "            2], device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 11\n",
      "batch, token 0 1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5806, -0.5806,  1.0674,  ..., -0.5806, -0.5806, -0.5806],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5806, -0.5806,  1.0674,  ..., -0.5806, -0.5806, -0.5806],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5806, -0.5806,  1.0674,  ..., -0.5806, -0.5806, -0.5806],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5806, -0.5806,  1.0674,  ..., -0.5806, -0.5806, -0.5806],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 13\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 13])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 13])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 13\n",
      "length od outputs 6\n",
      "length of beam_indices 13\n",
      "subtokens [613, 2935]\n",
      "for span: ਜੀਜਾ subtokens [613, 2935]\n",
      "seq tensor([    2,  2243,   613,  2935,    88,    19,    75, 61699, 10002,     8,\n",
      "            6,     2,     1], device='cuda:0')\n",
      "subtokens [29498, 640]\n",
      "for span: ਮ subtokens [29498, 640]\n",
      "seq tensor([    2,  1653,  1144, 40842,    88,    19,    75, 61699, 10002,     8,\n",
      "            6,     2,     1], device='cuda:0')\n",
      "subtokens [29498, 640]\n",
      "for span: ਮ subtokens [29498, 640]\n",
      "seq tensor([    2,  2243, 49615,  2656,  8327,    88,    19,    75, 61699, 10002,\n",
      "            8,     6,     2], device='cuda:0')\n",
      "subtokens [69840]\n",
      "for span: ਭਤੀਜਾ subtokens [69840]\n",
      "seq tensor([    2,  2243, 69840,    88,    19,    75, 61699, 10002,     8,     6,\n",
      "            2,     1,     1], device='cuda:0')\n",
      "logit_pos [1, 11, 11, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 13\n",
      "batch, token 0 1\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3296, -0.3293,  0.9829,  ..., -0.3296, -0.3296, -0.3296],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 11\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3296, -0.3293,  0.9829,  ..., -0.3296, -0.3296, -0.3296],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 11\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3296, -0.3293,  0.9829,  ..., -0.3296, -0.3296, -0.3296],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3296, -0.3293,  0.9829,  ..., -0.3296, -0.3296, -0.3296],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 13\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 12])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 12])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 13\n",
      "length od outputs 6\n",
      "length of beam_indices 12\n",
      "subtokens [39136, 795]\n",
      "for span: ਭਤੀਜੀ subtokens [39136, 795]\n",
      "seq tensor([    2,  1653, 39136,   795,    88,    19,    75, 61699, 10002,     8,\n",
      "            6,     2], device='cuda:0')\n",
      "subtokens [29498, 640]\n",
      "for span: ਦਾਦੀ subtokens [29498, 640]\n",
      "seq tensor([    2,  1653, 29498,    88,    19,    75,  1052,    19,  1304,     8,\n",
      "            6,     2], device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 12\n",
      "batch, token 0 1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  0.9741,  ..., -0.4463, -0.4460, -0.4460],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  0.9741,  ..., -0.4463, -0.4460, -0.4460],\n",
      "       dtype=torch.float16)\n",
      "ben_Beng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 8\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 8])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 8])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 8\n",
      "length od outputs 6\n",
      "length of beam_indices 8\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181, 58599,   241,  1279, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [409, 8599]\n",
      "for span: দাদু subtokens [409, 8599]\n",
      "seq tensor([    2,   181,   409,  8599,  1279, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181, 41565,  1279, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181, 57511,  1279, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [3, 1, 2, 2]\n",
      "Dimensions of logits torch.Size([4, 122672]) 8\n",
      "batch, token 0 3\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8799, -0.8799,  1.4287,  ..., -0.8799, -0.8799, -0.8799],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8799, -0.8799,  1.4287,  ..., -0.8799, -0.8799, -0.8799],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 2\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8799, -0.8799,  1.4287,  ..., -0.8799, -0.8799, -0.8799],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 2\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8799, -0.8799,  1.4287,  ..., -0.8799, -0.8799, -0.8799],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181,   649,  4692,    75,  1279, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181,   649,  4692,  1525,  1279, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [35407, 359, 3991, 6]\n",
      "for span: ভাই subtokens [35407, 359, 3991, 6]\n",
      "seq tensor([    2,   181, 35407,   359,  3991,  1279, 28125,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181,   291, 27065,  1279, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [4, 4, 1, 3]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 4\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5894, -0.5894,  1.8457,  ..., -0.5894, -0.5894, -0.5894],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 4\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5894, -0.5894,  1.8457,  ..., -0.5894, -0.5894, -0.5894],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5894, -0.5894,  1.8457,  ..., -0.5894, -0.5894, -0.5894],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 3\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5894, -0.5894,  1.8457,  ..., -0.5894, -0.5894, -0.5894],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 9])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181,   291, 17389,  1279, 28125,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [5745, 102, 6]\n",
      "for span: আ subtokens [5745, 102, 6]\n",
      "seq tensor([    2,   181, 58599,   241,  1279, 65121,  2383,     6,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [3, 4]\n",
      "Dimensions of logits torch.Size([2, 122672]) 9\n",
      "batch, token 0 3\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6128, -0.6123,  1.7666,  ..., -0.6128, -0.6123, -0.6123],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 4\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6128, -0.6123,  1.7666,  ..., -0.6128, -0.6123, -0.6123],\n",
      "       dtype=torch.float16)\n",
      "mal_Mlym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 12\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 12])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 12])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 12\n",
      "length od outputs 6\n",
      "length of beam_indices 12\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28, 14392, 18823,  2914,  2826,    50, 28125,  1844,\n",
      "            4,     2], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,  1216, 18823,  5136,    28,    50, 28125,  2963,     4,     2,\n",
      "            1,     1], device='cuda:0')\n",
      "subtokens [1774, 529, 28]\n",
      "for span: അമ്മാവൻ subtokens [1774, 529, 28]\n",
      "seq tensor([    2,  1216,  1774,   529,    28,    50, 28125,  2963,     4,     2,\n",
      "            1,     1], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28, 14392, 16343,    50, 28125,  1844,     4,     2,\n",
      "            1,     1], device='cuda:0')\n",
      "logit_pos [-1, -1, 1, -1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 12\n",
      "batch, token 0 -1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.0332, -1.0332,  1.0518,  ..., -1.0332, -1.0332, -1.0332],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 -1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.0332, -1.0332,  1.0518,  ..., -1.0332, -1.0332, -1.0332],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.0332, -1.0332,  1.0518,  ..., -1.0332, -1.0332, -1.0332],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 -1\n",
      "len(logits) 12\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.0332, -1.0332,  1.0518,  ..., -1.0332, -1.0332, -1.0332],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 14\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 14])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 14])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 14\n",
      "length od outputs 6\n",
      "length of beam_indices 14\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28, 14392,  3954,  4109,  3426,   877,    28,    50,\n",
      "        28125,  2963,     4,     2], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28, 14392,  3954,  4109,  3426, 50084,    50, 28125,\n",
      "         1844,     4,     2,     1], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28,  1017, 43494,    28,    50, 28125,  2963,     4,\n",
      "            2,     1,     1,     1], device='cuda:0')\n",
      "subtokens [1326, 13315, 128, 28]\n",
      "for span: അനന്തരവൻ subtokens [1326, 13315, 128, 28]\n",
      "seq tensor([    2,   223,    28, 14392,  1326, 13315,   128,    28,    50, 28125,\n",
      "         2963,     4,     2,     1], device='cuda:0')\n",
      "logit_pos [-1, -1, -1, 3]\n",
      "Dimensions of logits torch.Size([4, 122672]) 14\n",
      "batch, token 0 -1\n",
      "len(logits) 14\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7437, -0.7437,  0.8301,  ..., -0.7437, -0.7437, -0.7437],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 -1\n",
      "len(logits) 14\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7437, -0.7437,  0.8301,  ..., -0.7437, -0.7437, -0.7437],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 -1\n",
      "len(logits) 14\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7437, -0.7437,  0.8301,  ..., -0.7437, -0.7437, -0.7437],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 3\n",
      "len(logits) 14\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.7437, -0.7437,  0.8301,  ..., -0.7437, -0.7437, -0.7437],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 13\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 13])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 13])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 13\n",
      "length od outputs 6\n",
      "length of beam_indices 13\n",
      "subtokens [1326, 13315, 128, 27]\n",
      "for span: അനന്തരവൾ subtokens [1326, 13315, 128, 27]\n",
      "seq tensor([    2,   223,    28, 14392,  1326, 13315,   128,    27,    50, 28125,\n",
      "         1844,     4,     2], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: എ subtokens [2]\n",
      "seq tensor([    2,   223,    28,  1017, 18823,  2914,  2826,    50, 64275,  1844,\n",
      "            4,     2,     1], device='cuda:0')\n",
      "logit_pos [3, -1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 13\n",
      "batch, token 0 3\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6714, -0.6714,  1.3340,  ..., -0.6714, -0.6714, -0.6714],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 -1\n",
      "len(logits) 13\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.6714, -0.6714,  1.3340,  ..., -0.6714, -0.6714, -0.6714],\n",
      "       dtype=torch.float16)\n",
      "mar_Deva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 8])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 8])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 8\n",
      "subtokens [32967]\n",
      "for span: आजी subtokens [32967]\n",
      "seq tensor([    2,  6457, 32967, 28125,    38,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [56799, 4]\n",
      "for span: आजोबा subtokens [56799, 4]\n",
      "seq tensor([    2,  2953, 56799, 28125,   233,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [41565, 4]\n",
      "for span: काका subtokens [41565, 4]\n",
      "seq tensor([    2,  2953, 41565, 28125,   233,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [11701, 987, 4]\n",
      "for span: मावशी subtokens [11701, 987, 4]\n",
      "seq tensor([    2,  6457, 11701,   987, 28125,    38,     4,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 8\n",
      "batch, token 0 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6226, -0.6226,  1.1797,  ..., -0.6226, -0.6226, -0.6221],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6226, -0.6226,  1.1797,  ..., -0.6226, -0.6226, -0.6221],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6226, -0.6226,  1.1797,  ..., -0.6226, -0.6226, -0.6221],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.6226, -0.6226,  1.1797,  ..., -0.6226, -0.6226, -0.6221],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 11\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 11\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [530, 7131, 1067]\n",
      "for span: मेहुणा subtokens [530, 7131, 1067]\n",
      "seq tensor([    2,  6010,   530,  7131,  1067, 28125,    38,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [530, 7131, 1730]\n",
      "for span: मेहुणी subtokens [530, 7131, 1730]\n",
      "seq tensor([    2,  6457,   530,  7131,  1730, 28125,    38,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [6702, 119, 22699]\n",
      "for span: चुलत भाऊ subtokens [6702, 119, 22699]\n",
      "seq tensor([    2,  6010,  6702,   119, 22699, 28125,    38,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [11701, 987, 4]\n",
      "for span: म subtokens [11701, 987, 4]\n",
      "seq tensor([    2,  6010,  4300, 12291, 28125,    38,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 3]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  1.3809,  ..., -0.4460, -0.4460, -0.4458],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  1.3809,  ..., -0.4460, -0.4460, -0.4458],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  1.3809,  ..., -0.4460, -0.4460, -0.4458],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 3\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.4460, -0.4458,  1.3809,  ..., -0.4460, -0.4460, -0.4458],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 8])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 8])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 8\n",
      "subtokens [4569, 362]\n",
      "for span: भाची subtokens [4569, 362]\n",
      "seq tensor([    2,  6457,  4569,   362, 28125,    38,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [32967]\n",
      "for span: आजी subtokens [32967]\n",
      "seq tensor([    2,  6457, 32967, 64275,    38,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 8\n",
      "batch, token 0 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4478, -0.4480,  1.1982,  ..., -0.4480, -0.4480, -0.4478],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 8\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4478, -0.4480,  1.1982,  ..., -0.4480, -0.4480, -0.4478],\n",
      "       dtype=torch.float16)\n",
      "tam_Taml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 10])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 10])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 10\n",
      "subtokens [511, 956]\n",
      "for span: பாட்டி subtokens [511, 956]\n",
      "seq tensor([    2,  1214,   511,   956,    50,  1862, 25942,   131,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [14552, 3286, 4]\n",
      "for span: தாத்தா subtokens [14552, 3286, 4]\n",
      "seq tensor([    2,  1214, 14552,  3286,    50,  1862, 25942,   131,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [24501]\n",
      "for span: மாமா subtokens [24501]\n",
      "seq tensor([    2,  1214, 24501,    50,  1862, 25942,   131,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [213, 681]\n",
      "for span: அத்தை subtokens [213, 681]\n",
      "seq tensor([    2,  1214,   213,   681,    50,  1862, 25942,   131,     4,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 10\n",
      "batch, token 0 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5010, -0.5005,  1.2656,  ..., -0.5010, -0.5005, -0.5005],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5010, -0.5005,  1.2656,  ..., -0.5010, -0.5005, -0.5005],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5010, -0.5005,  1.2656,  ..., -0.5010, -0.5005, -0.5005],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5010, -0.5005,  1.2656,  ..., -0.5010, -0.5005, -0.5005],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 11\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 11])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 11])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 11\n",
      "length od outputs 6\n",
      "length of beam_indices 11\n",
      "subtokens [1364, 864, 1488]\n",
      "for span: மைத்துனர் subtokens [1364, 864, 1488]\n",
      "seq tensor([    2,  1214,  1364,   864,  1488,    50,  1862, 25942,   131,     4,\n",
      "            2], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: எ subtokens [2]\n",
      "seq tensor([    2,  1214,  1364,   864,  1488,    50,  1862, 25942,   131,     4,\n",
      "            2], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: எ subtokens [2]\n",
      "seq tensor([    2,  4476,  2901, 47743,    50,  1862, 25942,   131,     4,     2,\n",
      "            1], device='cuda:0')\n",
      "subtokens [2]\n",
      "for span: எ subtokens [2]\n",
      "seq tensor([    2,  4476, 45894,   319,    50,  1862, 25942,   131,     4,     2,\n",
      "            1], device='cuda:0')\n",
      "logit_pos [1, -1, -1, -1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 11\n",
      "batch, token 0 1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3687, -0.3687,  0.6182,  ..., -0.3687, -0.3684, -0.3687],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 -1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3687, -0.3687,  0.6182,  ..., -0.3687, -0.3684, -0.3687],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 -1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3687, -0.3687,  0.6182,  ..., -0.3687, -0.3684, -0.3687],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 -1\n",
      "len(logits) 11\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3687, -0.3687,  0.6182,  ..., -0.3687, -0.3684, -0.3687],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 10])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 10])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 10\n",
      "subtokens [2]\n",
      "for span: எ subtokens [2]\n",
      "seq tensor([    2,  1214, 45894,  1022,    50,  1862, 25942,   131,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [511, 956]\n",
      "for span: பாட்டி subtokens [511, 956]\n",
      "seq tensor([   2, 1214,  511,  956,   50, 5117, 6963, 4987,    4,    2],\n",
      "       device='cuda:0')\n",
      "logit_pos [-1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 10\n",
      "batch, token 0 -1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4431, -0.4431,  0.8281,  ..., -0.4431, -0.4431, -0.4431],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4431, -0.4431,  0.8281,  ..., -0.4431, -0.4431, -0.4431],\n",
      "       dtype=torch.float16)\n",
      "guj_Gujr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 8\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 7])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 7])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 8\n",
      "length od outputs 6\n",
      "length of beam_indices 7\n",
      "subtokens [29498]\n",
      "for span: દાદી subtokens [29498]\n",
      "seq tensor([    2,  2562, 29498, 28125,    15,     4,     2], device='cuda:0')\n",
      "subtokens [15588]\n",
      "for span: દાદા subtokens [15588]\n",
      "seq tensor([    2,  1551, 15588, 28125,    15,     4,     2], device='cuda:0')\n",
      "subtokens [41565]\n",
      "for span: કાકા subtokens [41565]\n",
      "seq tensor([    2,  1551, 41565, 28125,    15,     4,     2], device='cuda:0')\n",
      "subtokens [64851]\n",
      "for span: કાકી subtokens [64851]\n",
      "seq tensor([    2,  2562, 64851, 28125,    15,     4,     2], device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 7\n",
      "batch, token 0 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5635, -0.5630,  1.1406,  ..., -0.5635, -0.5635, -0.5630],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5635, -0.5630,  1.1406,  ..., -0.5635, -0.5635, -0.5630],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5635, -0.5630,  1.1406,  ..., -0.5635, -0.5635, -0.5630],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5635, -0.5630,  1.1406,  ..., -0.5635, -0.5635, -0.5630],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [1872, 2466]\n",
      "for span: સાળો subtokens [1872, 2466]\n",
      "seq tensor([    2, 11788,  1872,  2466, 28125,    15,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [1872, 2651]\n",
      "for span: સાળી subtokens [1872, 2651]\n",
      "seq tensor([    2,  2562,  1872,  2651, 28125,    15,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [24501]\n",
      "for span: મ subtokens [24501]\n",
      "seq tensor([    2, 11788,  6042, 18974,  3991, 28125,    15,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [980, 14910, 3204]\n",
      "for span: ભત્રીજો subtokens [980, 14910, 3204]\n",
      "seq tensor([    2, 11788,   980, 14910,  3204, 28125,    15,     4,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 7, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5444, -0.5439,  1.1855,  ..., -0.5444, -0.5444, -0.5439],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5444, -0.5439,  1.1855,  ..., -0.5444, -0.5444, -0.5439],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 7\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5444, -0.5439,  1.1855,  ..., -0.5444, -0.5444, -0.5439],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.5444, -0.5439,  1.1855,  ..., -0.5444, -0.5444, -0.5439],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 11\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 9])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 11\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [980, 14910, 795]\n",
      "for span: ભત્રીજી subtokens [980, 14910, 795]\n",
      "seq tensor([    2,  2562,   980, 14910,   795, 28125,    15,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [29498]\n",
      "for span: દાદી subtokens [29498]\n",
      "seq tensor([    2,  2562, 29498, 64275,    15,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4136, -0.4136,  1.0811,  ..., -0.4136, -0.4136, -0.4133],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.4136, -0.4136,  1.0811,  ..., -0.4136, -0.4136, -0.4133],\n",
      "       dtype=torch.float16)\n",
      "hin_Deva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 7])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 7])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 7\n",
      "subtokens [29498, 12075]\n",
      "for span: दादी subtokens [29498, 12075]\n",
      "seq tensor([    2,  1653, 29498, 28125,    33,     6,     2], device='cuda:0')\n",
      "subtokens [15588, 613, 6]\n",
      "for span: दादा subtokens [15588, 613, 6]\n",
      "seq tensor([    2,   790, 15588, 28125,    33,     6,     2], device='cuda:0')\n",
      "subtokens [34059]\n",
      "for span: चाचा subtokens [34059]\n",
      "seq tensor([    2,   790, 34059, 28125,    33,     6,     2], device='cuda:0')\n",
      "subtokens [60684]\n",
      "for span: चाची subtokens [60684]\n",
      "seq tensor([    2,  1653, 60684, 28125,    33,     6,     2], device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 7\n",
      "batch, token 0 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3286, -0.3289,  1.3486,  ..., -0.3289, -0.3289, -0.3289],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3286, -0.3289,  1.3486,  ..., -0.3289, -0.3289, -0.3289],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3286, -0.3289,  1.3486,  ..., -0.3289, -0.3289, -0.3289],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 7\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.3286, -0.3289,  1.3486,  ..., -0.3289, -0.3289, -0.3289],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [27985]\n",
      "for span: साला subtokens [27985]\n",
      "seq tensor([    2,  2243, 27985, 28125,     8,     6,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [18477]\n",
      "for span: साली subtokens [18477]\n",
      "seq tensor([    2,  1653, 18477,    24, 28125,     8,     6,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [49615, 2656, 3057]\n",
      "for span: भाई subtokens [49615, 2656, 3057]\n",
      "seq tensor([    2,  2243, 49615,  2656,  3057, 28125,     8,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [69840]\n",
      "for span: भतीजा subtokens [69840]\n",
      "seq tensor([    2,  2243, 69840, 28125,     8,     6,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.1837, -0.1837,  1.9131,  ..., -0.1838, -0.1837, -0.1837],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.1837, -0.1837,  1.9131,  ..., -0.1838, -0.1837, -0.1837],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.1837, -0.1837,  1.9131,  ..., -0.1838, -0.1837, -0.1837],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.1837, -0.1837,  1.9131,  ..., -0.1838, -0.1837, -0.1837],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 9])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [39136, 795]\n",
      "for span: भतीजी subtokens [39136, 795]\n",
      "seq tensor([    2,  1653, 39136,   795,    24, 28125,     8,     6,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [29498, 12075]\n",
      "for span: दादी subtokens [29498, 12075]\n",
      "seq tensor([    2,  1653, 29498, 64275,    33,     6,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.2267, -0.2268,  1.9307,  ..., -0.2269, -0.2268, -0.2268],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.2267, -0.2268,  1.9307,  ..., -0.2269, -0.2268, -0.2268],\n",
      "       dtype=torch.float16)\n",
      "kan_Knda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 9\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** True\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 9])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 9\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [4565, 35330]\n",
      "for span: ಅಜ್ಜಿ subtokens [4565, 35330]\n",
      "seq tensor([    2,  1586,  4565, 35330, 28125,   194,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [4565, 35330]\n",
      "for span: ಅಜ್ಜ subtokens [4565, 35330]\n",
      "seq tensor([    2,  1586, 44928,  3564, 28125,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [2950, 378]\n",
      "for span: ಚಿಕ್ಕಪ್ಪ subtokens [2950, 378]\n",
      "seq tensor([    2,  1586,  2950,   378,  3564, 28125,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [2950, 1476, 4]\n",
      "for span: ಚಿಕ್ಕಮ್ಮ subtokens [2950, 1476, 4]\n",
      "seq tensor([    2,  1586,  2950,  1476,  3564, 28125,   104,     4,     2],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 7, 1, 1]\n",
      "Dimensions of logits torch.Size([4, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.1006, -1.1006,  1.1094,  ..., -1.1006, -1.1006, -1.1006],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 7\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.1006, -1.1006,  1.1094,  ..., -1.1006, -1.1006, -1.1006],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.1006, -1.1006,  1.1094,  ..., -1.1006, -1.1006, -1.1006],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-1.1006, -1.1006,  1.1094,  ..., -1.1006, -1.1006, -1.1006],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 12\n",
      "Shape of outputs.logits actual torch.Size([20, 122672])\n",
      "Length of outputs.beam_indices actual 4\n",
      "Shape of outputs.beam_indices actual torch.Size([4, 10])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 4\n",
      "shape of beam_indices torch.Size([4, 10])\n",
      "shape of logits torch.Size([20, 122672])\n",
      "length of logits 12\n",
      "length od outputs 6\n",
      "length of beam_indices 10\n",
      "subtokens [1364, 58831]\n",
      "for span: ನ subtokens [1364, 58831]\n",
      "seq tensor([    2,  1586,  3373,   158,  3564, 28125,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [213, 24430]\n",
      "for span: ಅತ್ತಿಗೆ subtokens [213, 24430]\n",
      "seq tensor([    2,  1586,   213, 24430, 28125,  1384,     4,     2,     1,     1],\n",
      "       device='cuda:0')\n",
      "subtokens [1364, 58831]\n",
      "for span: ನ subtokens [1364, 58831]\n",
      "seq tensor([    2,  1586, 34385,  2182, 15841,  2603,  3564, 28125,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [1364, 58831]\n",
      "for span: ನ subtokens [1364, 58831]\n",
      "seq tensor([    2,  1586, 34385,  5999, 28125,  6842, 10189,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [8, 1, 8, 8]\n",
      "Dimensions of logits torch.Size([4, 122672]) 10\n",
      "batch, token 0 8\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8062, -0.8057,  1.4746,  ..., -0.8062, -0.8057, -0.8057],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8062, -0.8057,  1.4746,  ..., -0.8062, -0.8057, -0.8057],\n",
      "       dtype=torch.float16)\n",
      "batch, token 2 8\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8062, -0.8057,  1.4746,  ..., -0.8062, -0.8057, -0.8057],\n",
      "       dtype=torch.float16)\n",
      "batch, token 3 8\n",
      "len(logits) 10\n",
      "Shape of logits torch.Size([4, 122672])\n",
      "logits 1st item 1st row tensor([-0.8062, -0.8057,  1.4746,  ..., -0.8062, -0.8057, -0.8057],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of outputs.logits actual 10\n",
      "Shape of outputs.logits actual torch.Size([10, 122672])\n",
      "Length of outputs.beam_indices actual 2\n",
      "Shape of outputs.beam_indices actual torch.Size([2, 9])\n",
      "*********IS LENGTH OF BEAM INDICES'S COL SIZE SAME AS LENGTH OF LOGITS?********** False\n",
      "length of output beam 2\n",
      "shape of beam_indices torch.Size([2, 9])\n",
      "shape of logits torch.Size([10, 122672])\n",
      "length of logits 10\n",
      "length od outputs 6\n",
      "length of beam_indices 9\n",
      "subtokens [34385, 6324, 3658]\n",
      "for span: ಸೋದರ ಸೊಸೆ subtokens [34385, 6324, 3658]\n",
      "seq tensor([    2,  1586, 34385,  6324,  3658, 28125,  1384,     4,     2],\n",
      "       device='cuda:0')\n",
      "subtokens [4565, 35330]\n",
      "for span: ಅಜ್ಜಿ subtokens [4565, 35330]\n",
      "seq tensor([    2,  1586,  4565, 35330,  3564, 64275,     4,     2,     1],\n",
      "       device='cuda:0')\n",
      "logit_pos [1, 1]\n",
      "Dimensions of logits torch.Size([2, 122672]) 9\n",
      "batch, token 0 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.8945, -0.8940,  1.0840,  ..., -0.8940, -0.8940, -0.8940],\n",
      "       dtype=torch.float16)\n",
      "batch, token 1 1\n",
      "len(logits) 9\n",
      "Shape of logits torch.Size([2, 122672])\n",
      "logits 1st item 1st row tensor([-0.8945, -0.8940,  1.0840,  ..., -0.8940, -0.8940, -0.8940],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "src_lang = \"eng_Latn\"\n",
    "output_trnsl={}\n",
    "output_logits={}\n",
    "\n",
    "for lang in lang_script_list:\n",
    "    tgt_lang = lang\n",
    "    print(lang)\n",
    "    # if tgt_lang != 'ory_Orya':\n",
    "    #     continue\n",
    "    translations, logits, root_amb_words, searched_spans = batch_translate(sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip_en_ind, span_encodings)\n",
    "    output_trnsl[lang] = translations\n",
    "    output_logits[lang] = logits\n",
    "\n",
    "    # # save hindi translations to a file test_translations_hin.txt\n",
    "    # with open('test_translations/indic_trans2/test_transl_it2_'+lang+'.txt', 'w') as f:\n",
    "    #     for sent in translations:\n",
    "    #         f.write(sent + '\\n')\n",
    "\n",
    "    # save the logits to a file \n",
    "    # with open('test_trasnlations/indic_trans2/test_transl_it2_'+lang+'_logits.txt', 'w') as f:\n",
    "    #     for logit in logits:\n",
    "    #         f.write(str(logit) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>root_ambiguous_words</th>\n",
       "      <th>searched_spans_tel_Telu</th>\n",
       "      <th>transl_te</th>\n",
       "      <th>logits_te</th>\n",
       "      <th>searched_spans_ory_Orya</th>\n",
       "      <th>transl_or</th>\n",
       "      <th>logits_or</th>\n",
       "      <th>searched_spans_pan_Guru</th>\n",
       "      <th>transl_pa</th>\n",
       "      <th>...</th>\n",
       "      <th>logits_ta</th>\n",
       "      <th>searched_spans_guj_Gujr</th>\n",
       "      <th>transl_gu</th>\n",
       "      <th>logits_gu</th>\n",
       "      <th>searched_spans_hin_Deva</th>\n",
       "      <th>transl_hi</th>\n",
       "      <th>logits_hi</th>\n",
       "      <th>searched_spans_kan_Knda</th>\n",
       "      <th>transl_kn</th>\n",
       "      <th>logits_kn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My grandmother is a Brahmin.</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>మా అమ్మమ్మ బ్రాహ్మణుడు.</td>\n",
       "      <td>[tensor(-1.6807, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>ମୋ ଜେଜେମା ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5381, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>ਮੇਰੀ ਦਾਦੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>...</td>\n",
       "      <td>[tensor(-0.7446, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>મારી દાદી બ્રાહ્મણ છે.</td>\n",
       "      <td>[tensor(-0.7539, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>मेरी दादी ब्राह्मण हैं।</td>\n",
       "      <td>[tensor(-0.7910, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜಿ</td>\n",
       "      <td>ನನ್ನ ಅಜ್ಜಿ ಬ್ರಾಹ್ಮಣರು.</td>\n",
       "      <td>[tensor(-1.0566, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My grandfather is a Brahmin.</td>\n",
       "      <td>grandfather</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>మా తాత ఒక బ్రాహ్మణుడు.</td>\n",
       "      <td>[tensor(0.0009, dtype=torch.float16), tensor(0...</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>ମୋ ଜେଜେବାପା ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.3369, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>ਮੇਰੇ ਦਾਦਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।</td>\n",
       "      <td>...</td>\n",
       "      <td>[tensor(-0.5171, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>મારા દાદા બ્રાહ્મણ છે.</td>\n",
       "      <td>[tensor(-0.5103, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>मेरे दादा ब्राह्मण हैं।</td>\n",
       "      <td>[tensor(-0.5205, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಅಜ್ಜ</td>\n",
       "      <td>ನನ್ನ ಅಜ್ಜ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.</td>\n",
       "      <td>[tensor(-1.4062, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My uncle is a Brahmin.</td>\n",
       "      <td>uncle</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>మా నాన్న బ్రాహ్మణుడు.</td>\n",
       "      <td>[tensor(-0.7363, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>ମୋ ମାମୁଁ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5029, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>ਮੇਰੇ ਚਾਚਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।</td>\n",
       "      <td>...</td>\n",
       "      <td>[tensor(-0.9399, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>મારા કાકા બ્રાહ્મણ છે.</td>\n",
       "      <td>[tensor(-0.9272, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>मेरे चाचा ब्राह्मण हैं।</td>\n",
       "      <td>[tensor(-0.8447, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಪ್ಪ</td>\n",
       "      <td>ನನ್ನ ಚಿಕ್ಕಪ್ಪ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.</td>\n",
       "      <td>[tensor(-1.1094, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My aunt is a Brahmin.</td>\n",
       "      <td>aunt</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>నా అత్త బ్రాహ్మణుడు.</td>\n",
       "      <td>[tensor(-1.6035, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>ମୋ ମାଉସୀ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.9922, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>ਮੇਰੀ ਮਾਸੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>...</td>\n",
       "      <td>[tensor(-1.0879, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>મારી કાકી બ્રાહ્મણ છે.</td>\n",
       "      <td>[tensor(-1.6504, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>मेरी चाची ब्राह्मण हैं।</td>\n",
       "      <td>[tensor(-1.4668, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ಚಿಕ್ಕಮ್ಮ</td>\n",
       "      <td>ನನ್ನ ಚಿಕ್ಕಮ್ಮ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣೆ.</td>\n",
       "      <td>[tensor(-1.3389, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My brother-in-law is a Brahmin.</td>\n",
       "      <td>brother-in-law</td>\n",
       "      <td>ನ</td>\n",
       "      <td>నా బావ బ్రాహ్మణుడు.</td>\n",
       "      <td>[tensor(-0.2654, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ನ</td>\n",
       "      <td>ମୋ ଭିଣୋଇ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5986, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ನ</td>\n",
       "      <td>ਮੇਰਾ ਜੀਜਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>...</td>\n",
       "      <td>[tensor(-0.9644, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ನ</td>\n",
       "      <td>મારો સાળો બ્રાહ્મણ છે.</td>\n",
       "      <td>[tensor(-1.3604, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ನ</td>\n",
       "      <td>मेरा साला ब्राह्मण है।</td>\n",
       "      <td>[tensor(-0.8120, dtype=torch.float16), tensor(...</td>\n",
       "      <td>ನ</td>\n",
       "      <td>ನನ್ನ ಅಳಿಯ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.</td>\n",
       "      <td>[tensor(0.0098, dtype=torch.float16), tensor(0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentences root_ambiguous_words  \\\n",
       "0     My grandmother is a Brahmin.          grandmother   \n",
       "1     My grandfather is a Brahmin.          grandfather   \n",
       "2           My uncle is a Brahmin.                uncle   \n",
       "3            My aunt is a Brahmin.                 aunt   \n",
       "4  My brother-in-law is a Brahmin.       brother-in-law   \n",
       "\n",
       "  searched_spans_tel_Telu                 transl_te  \\\n",
       "0                   ಅಜ್ಜಿ  మా అమ్మమ్మ బ్రాహ్మణుడు.    \n",
       "1                    ಅಜ್ಜ   మా తాత ఒక బ్రాహ్మణుడు.    \n",
       "2                ಚಿಕ್ಕಪ್ಪ    మా నాన్న బ్రాహ్మణుడు.    \n",
       "3                ಚಿಕ್ಕಮ್ಮ     నా అత్త బ్రాహ్మణుడు.    \n",
       "4                       ನ      నా బావ బ్రాహ్మణుడు.    \n",
       "\n",
       "                                           logits_te searched_spans_ory_Orya  \\\n",
       "0  [tensor(-1.6807, dtype=torch.float16), tensor(...                   ಅಜ್ಜಿ   \n",
       "1  [tensor(0.0009, dtype=torch.float16), tensor(0...                    ಅಜ್ಜ   \n",
       "2  [tensor(-0.7363, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಪ್ಪ   \n",
       "3  [tensor(-1.6035, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಮ್ಮ   \n",
       "4  [tensor(-0.2654, dtype=torch.float16), tensor(...                       ನ   \n",
       "\n",
       "                    transl_or  \\\n",
       "0    ମୋ ଜେଜେମା ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "1  ମୋ ଜେଜେବାପା ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "2     ମୋ ମାମୁଁ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "3     ମୋ ମାଉସୀ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "4     ମୋ ଭିଣୋଇ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "\n",
       "                                           logits_or searched_spans_pan_Guru  \\\n",
       "0  [tensor(-1.5381, dtype=torch.float16), tensor(...                   ಅಜ್ಜಿ   \n",
       "1  [tensor(-1.3369, dtype=torch.float16), tensor(...                    ಅಜ್ಜ   \n",
       "2  [tensor(-1.5029, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಪ್ಪ   \n",
       "3  [tensor(-1.9922, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಮ್ಮ   \n",
       "4  [tensor(-1.5986, dtype=torch.float16), tensor(...                       ನ   \n",
       "\n",
       "                    transl_pa  ...  \\\n",
       "0  ਮੇਰੀ ਦਾਦੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।   ...   \n",
       "1  ਮੇਰੇ ਦਾਦਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।   ...   \n",
       "2  ਮੇਰੇ ਚਾਚਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।   ...   \n",
       "3  ਮੇਰੀ ਮਾਸੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।   ...   \n",
       "4  ਮੇਰਾ ਜੀਜਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।   ...   \n",
       "\n",
       "                                           logits_ta searched_spans_guj_Gujr  \\\n",
       "0  [tensor(-0.7446, dtype=torch.float16), tensor(...                   ಅಜ್ಜಿ   \n",
       "1  [tensor(-0.5171, dtype=torch.float16), tensor(...                    ಅಜ್ಜ   \n",
       "2  [tensor(-0.9399, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಪ್ಪ   \n",
       "3  [tensor(-1.0879, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಮ್ಮ   \n",
       "4  [tensor(-0.9644, dtype=torch.float16), tensor(...                       ನ   \n",
       "\n",
       "                 transl_gu                                          logits_gu  \\\n",
       "0  મારી દાદી બ્રાહ્મણ છે.   [tensor(-0.7539, dtype=torch.float16), tensor(...   \n",
       "1  મારા દાદા બ્રાહ્મણ છે.   [tensor(-0.5103, dtype=torch.float16), tensor(...   \n",
       "2  મારા કાકા બ્રાહ્મણ છે.   [tensor(-0.9272, dtype=torch.float16), tensor(...   \n",
       "3  મારી કાકી બ્રાહ્મણ છે.   [tensor(-1.6504, dtype=torch.float16), tensor(...   \n",
       "4  મારો સાળો બ્રાહ્મણ છે.   [tensor(-1.3604, dtype=torch.float16), tensor(...   \n",
       "\n",
       "  searched_spans_hin_Deva                 transl_hi  \\\n",
       "0                   ಅಜ್ಜಿ  मेरी दादी ब्राह्मण हैं।    \n",
       "1                    ಅಜ್ಜ  मेरे दादा ब्राह्मण हैं।    \n",
       "2                ಚಿಕ್ಕಪ್ಪ  मेरे चाचा ब्राह्मण हैं।    \n",
       "3                ಚಿಕ್ಕಮ್ಮ  मेरी चाची ब्राह्मण हैं।    \n",
       "4                       ನ   मेरा साला ब्राह्मण है।    \n",
       "\n",
       "                                           logits_hi searched_spans_kan_Knda  \\\n",
       "0  [tensor(-0.7910, dtype=torch.float16), tensor(...                   ಅಜ್ಜಿ   \n",
       "1  [tensor(-0.5205, dtype=torch.float16), tensor(...                    ಅಜ್ಜ   \n",
       "2  [tensor(-0.8447, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಪ್ಪ   \n",
       "3  [tensor(-1.4668, dtype=torch.float16), tensor(...                ಚಿಕ್ಕಮ್ಮ   \n",
       "4  [tensor(-0.8120, dtype=torch.float16), tensor(...                       ನ   \n",
       "\n",
       "                        transl_kn  \\\n",
       "0         ನನ್ನ ಅಜ್ಜಿ ಬ್ರಾಹ್ಮಣರು.    \n",
       "1       ನನ್ನ ಅಜ್ಜ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.    \n",
       "2   ನನ್ನ ಚಿಕ್ಕಪ್ಪ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.    \n",
       "3  ನನ್ನ ಚಿಕ್ಕಮ್ಮ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣೆ.    \n",
       "4       ನನ್ನ ಅಳಿಯ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ.    \n",
       "\n",
       "                                           logits_kn  \n",
       "0  [tensor(-1.0566, dtype=torch.float16), tensor(...  \n",
       "1  [tensor(-1.4062, dtype=torch.float16), tensor(...  \n",
       "2  [tensor(-1.1094, dtype=torch.float16), tensor(...  \n",
       "3  [tensor(-1.3389, dtype=torch.float16), tensor(...  \n",
       "4  [tensor(0.0098, dtype=torch.float16), tensor(0...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe from the translations, logits and the root ambiguous words, searched spans\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['sentences'] = sents\n",
    "df['root_ambiguous_words'] = root_amb_words\n",
    "for lang in lang_script_list:\n",
    "    # if lang != 'ory_Orya':\n",
    "    #     continue\n",
    "    # following 2 can be commented out to reduce the size of the dataframe\n",
    "    df['searched_spans_'+lang] = searched_spans\n",
    "    df['transl_'+lang_code_map[lang]] = output_trnsl[lang]\n",
    "    df['logits_'+lang_code_map[lang]] = output_logits[lang]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all sentences:\n",
    "#    for all langs:\n",
    "#     for the given root ambiguous word, get the possible relations in the target language\n",
    "#      group the possible relations into matriarchal and patriarchal\n",
    "#       <*>find the logits for the words in matrirachi and patriachal relations\n",
    "#       find the sum over respective sets and take difference of both sums\n",
    "#       if difference is positive, then the wordXlang is matriarchal, else patriarchal\n",
    "#     Report the difference for each wordXlang as a matrix. Rows are words and columns are langs. Store it as final_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Possible relations:  ['నాన్నమ్మ', 'అమ్మమ', 'నాన్నమ', 'చిన్న నాన్నమ', 'పెద్ద  నాన్నమ', 'చిన్న అమ్మమ', 'పెద్ద అమ్మమ']\n",
      "for reln: అమ్మమ span_encodings: [1774, 143]\n",
      "for reln: చిన్న అమ్మమ span_encodings: [2195, 1774, 143]\n",
      "for reln: పెద్ద అమ్మమ span_encodings: [2224, 1774, 143]\n",
      "for reln: నాన్నమ్మ span_encodings: [30539, 1476]\n",
      "for reln: నాన్నమ span_encodings: [30539, 143]\n",
      "for reln: చిన్న నాన్నమ span_encodings: [2195, 30539, 143]\n",
      "for reln: పెద్ద  నాన్నమ span_encodings: [2224, 30539, 143]\n",
      "For word:  grandmother in lang:  tel_Telu Difference:  0.6171875\n",
      "###Possible relations:  ['ଜେଜେମା', 'ଆଈ']\n",
      "for reln: ଆଈ span_encodings: [740]\n",
      "for reln: ଜେଜେମା span_encodings: [41445, 241]\n",
      "For word:  grandmother in lang:  ory_Orya Difference:  -0.9638671875\n",
      "###Possible relations:  ['ਦਾਦੀ', 'ਨਾਨੀ']\n",
      "for reln: ਨਾਨੀ span_encodings: [8911]\n",
      "for reln: ਦਾਦੀ span_encodings: [29498]\n",
      "For word:  grandmother in lang:  pan_Guru Difference:  0.77734375\n",
      "###Possible relations:  ['ঠাকুরমা', 'দিদি মা']\n",
      "for reln: দিদি মা span_encodings: [48446, 354]\n",
      "for reln: ঠাকুরমা span_encodings: [9402, 241]\n",
      "For word:  grandmother in lang:  ben_Beng Difference:  0.126220703125\n",
      "###Possible relations:  ['അമ്മൂമ്മ']\n",
      "for reln: അമ്മൂമ്മ span_encodings: [1774, 208, 1476]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  mal_Mlym\n",
      "###Possible relations:  ['आजी', 'मावस आजी']\n",
      "for reln: आजी span_encodings: [32967]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: मावस आजी span_encodings: [11701, 115, 32967]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  mar_Deva\n",
      "###Possible relations:  ['அப்பத்தா', 'அம்மத்தா', 'சின்ன பாட்டி', 'பெரிய பாட்டி', 'பாட்டி']\n",
      "for reln: அம்மத்தா span_encodings: [1774, 2154]\n",
      "for reln: அப்பத்தா span_encodings: [2763, 2154]\n",
      "for reln: சின்ன பாட்டி span_encodings: [13735, 511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.9961, dtype=torch.float16)] Patriarchal sets:  [tensor(1.3682, dtype=torch.float16)]\n",
      "for reln: பெரிய பாட்டி span_encodings: [2765, 511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.9961, dtype=torch.float16)] Patriarchal sets:  [tensor(1.3682, dtype=torch.float16)]\n",
      "for reln: பாட்டி span_encodings: [511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.9961, dtype=torch.float16)] Patriarchal sets:  [tensor(1.3682, dtype=torch.float16)]\n",
      "For word:  grandmother in lang:  tam_Taml Difference:  0.671875\n",
      "###Possible relations:  ['દાદી', 'નાની']\n",
      "for reln: નાની span_encodings: [8911]\n",
      "for reln: દાદી span_encodings: [29498]\n",
      "For word:  grandmother in lang:  guj_Gujr Difference:  -0.9755859375\n",
      "###Possible relations:  ['दादी', 'नानी', 'पितामही']\n",
      "for reln: नानी span_encodings: [8911]\n",
      "for reln: पितामही span_encodings: [30502, 412]\n",
      "for reln: दादी span_encodings: [29498]\n",
      "For word:  grandmother in lang:  hin_Deva Difference:  0.7568359375\n",
      "###Possible relations:  ['ಅಜ್ಜಿ']\n",
      "for reln: ಅಜ್ಜಿ span_encodings: [4565, 35330]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  kan_Knda\n",
      "###Possible relations:  ['తాతయ్యగారు', 'తాతయ్య', 'చిన్న తాతయ్య', 'పెద్ద తాతయ్య']\n",
      "for reln: తాతయ్యగారు span_encodings: [14552, 4559, 20269]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: తాతయ్య span_encodings: [14552, 4559]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: చిన్న తాతయ్య span_encodings: [2195, 14552, 4559]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: పెద్ద తాతయ్య span_encodings: [2224, 14552, 4559]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandfather in lang:  tel_Telu\n",
      "###Possible relations:  ['ଜେଜେବାପା', 'ଅଜା']\n",
      "for reln: ଅଜା span_encodings: [62200]\n",
      "for reln: ଜେଜେବାପା span_encodings: [41445, 1007, 1714]\n",
      "For word:  grandfather in lang:  ory_Orya Difference:  -0.2451171875\n",
      "###Possible relations:  ['ਦਾਦਾ', 'ਨਾਨਾ']\n",
      "for reln: ਨਾਨਾ span_encodings: [2820]\n",
      "for reln: ਦਾਦਾ span_encodings: [15588]\n",
      "For word:  grandfather in lang:  pan_Guru Difference:  -0.6181640625\n",
      "###Possible relations:  ['ঠাকুরদা', 'দাদু']\n",
      "for reln: দাদু span_encodings: [409, 8599]\n",
      "for reln: ঠাকুরদা span_encodings: [9402, 450]\n",
      "For word:  grandfather in lang:  ben_Beng Difference:  0.5224609375\n",
      "###Possible relations:  ['അപ്പൂപ്പൻ']\n",
      "for reln: അപ്പൂപ്പൻ span_encodings: [2763, 208, 378, 28]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandfather in lang:  mal_Mlym\n",
      "###Possible relations:  ['आजोबा', 'चुलत आजोबा']\n",
      "for reln: आजोबा span_encodings: [56799]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: चुलत आजोबा span_encodings: [6702, 119, 56799]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandfather in lang:  mar_Deva\n",
      "###Possible relations:  ['தாத்தா', 'சின்ன தாத்தா', 'பெரிய தாத்தா']\n",
      "for reln: தாத்தா span_encodings: [14552, 3286]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: சின்ன தாத்தா span_encodings: [13735, 14552, 3286]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: பெரிய தாத்தா span_encodings: [2765, 14552, 3286]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandfather in lang:  tam_Taml\n",
      "###Possible relations:  ['દાદા', 'નાના']\n",
      "for reln: નાના span_encodings: [2820]\n",
      "for reln: દાદા span_encodings: [15588]\n",
      "For word:  grandfather in lang:  guj_Gujr Difference:  -0.9990234375\n",
      "###Possible relations:  ['दादा', 'नाना', 'पितामह']\n",
      "for reln: नाना span_encodings: [2820]\n",
      "for reln: दादा span_encodings: [15588]\n",
      "for reln: पितामह span_encodings: [53208]\n",
      "For word:  grandfather in lang:  hin_Deva Difference:  0.9833984375\n",
      "###Possible relations:  ['ಅಜ್ಜ']\n",
      "for reln: ಅಜ್ಜ span_encodings: [44928]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandfather in lang:  kan_Knda\n",
      "###Possible relations:  ['పెద్ద నాన్న', 'ఆయగారు', 'మామయ్య', 'మామయ్యగారు', 'చిన్న నాన్న']\n",
      "for reln: పెద్ద నాన్న span_encodings: [2224, 30539]\n",
      "for reln: మామయ్య span_encodings: [9971, 4559]\n",
      "for reln: చిన్న నాన్న span_encodings: [2195, 30539]\n",
      "for reln: ఆయగారు span_encodings: [1012, 20269]\n",
      "for reln: మామయ్యగారు span_encodings: [9971, 4559, 20269]\n",
      "For word:  uncle in lang:  tel_Telu Difference:  0.529296875\n",
      "###Possible relations:  ['ବଡ଼ବାପା', 'ଦାଦା', 'ମାମୁଁ', 'ପିଉସା', 'ମଉସା']\n",
      "for reln: ମାମୁଁ span_encodings: [9971, 19212]\n",
      "for reln: ମଉସା span_encodings: [63293, 964]\n",
      "for reln: ବଡ଼ବାପା span_encodings: [1111, 1007, 1714]\n",
      "for reln: ଦାଦା span_encodings: [15588]\n",
      "for reln: ପିଉସା span_encodings: [52157, 964]\n",
      "For word:  uncle in lang:  ory_Orya Difference:  -0.86328125\n",
      "###Possible relations:  ['ਤਾਇਆ', 'ਚਾਚਾ', 'ਮਾਮਾ', 'ਫੁੱਫੜ', 'ਮਾਸੜ']\n",
      "for reln: ਮਾਮਾ span_encodings: [24501]\n",
      "for reln: ਮਾਸੜ span_encodings: [1992, 1643]\n",
      "for reln: ਤਾਇਆ span_encodings: [302, 6438]\n",
      "for reln: ਚਾਚਾ span_encodings: [34059]\n",
      "for reln: ਫੁੱਫੜ span_encodings: [7355, 19, 495, 1643]\n",
      "For word:  uncle in lang:  pan_Guru Difference:  -0.9541015625\n",
      "###Possible relations:  ['জেঠা মশাই', 'কাকু', 'মামা', 'পিশে মশাই', 'মেশো মশাই']\n",
      "for reln: মামা span_encodings: [24501]\n",
      "for reln: মেশো মশাই span_encodings: [530, 2663, 15575, 635]\n",
      "for reln: জেঠা মশাই span_encodings: [169, 9965, 15575, 635]\n",
      "for reln: কাকু span_encodings: [63220]\n",
      "for reln: পিশে মশাই span_encodings: [449, 1272, 15575, 635]\n",
      "For word:  uncle in lang:  ben_Beng Difference:  -0.01318359375\n",
      "###Possible relations:  ['അമ്മാവൻ', 'മൂത്ത അച്ഛൻ', 'ചിറ്റപ്പൻ', 'മൂത്തമാമൻ', 'ഇളയമാമൻ', 'മാമൻ', 'വല്ല്യച്ചൻ', 'ചാച്ചൻ']\n",
      "for reln: മൂത്തമാമൻ span_encodings: [1398, 11549, 462, 28]\n",
      "for reln: ഇളയമാമൻ span_encodings: [3487, 18892, 462, 28]\n",
      "for reln: മാമൻ span_encodings: [9971, 28]\n",
      "for reln: വല്ല്യച്ചൻ span_encodings: [2958, 537, 356, 28]\n",
      "for reln: ചാച്ചൻ span_encodings: [1657, 356, 28]\n",
      "for reln: മൂത്ത അച്ഛൻ span_encodings: [16674, 7673, 28]\n",
      "for reln: ചിറ്റപ്പൻ span_encodings: [60069, 378, 28]\n",
      "for reln: അമ്മാവൻ span_encodings: [1774, 529, 28]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(1.6621, dtype=torch.float16), tensor(1.9111, dtype=torch.float16), tensor(1.6621, dtype=torch.float16), tensor(0.8320, dtype=torch.float16), tensor(2.2402, dtype=torch.float16)] Patriarchal sets:  [tensor(4.2266, dtype=torch.float16), tensor(2.1289, dtype=torch.float16)]\n",
      "For word:  uncle in lang:  mal_Mlym Difference:  -0.45263671875\n",
      "###Possible relations:  ['काका', 'मामा', 'मावसा']\n",
      "for reln: मामा span_encodings: [24501]\n",
      "for reln: मावसा span_encodings: [11701, 964]\n",
      "for reln: काका span_encodings: [41565]\n",
      "For word:  uncle in lang:  mar_Deva Difference:  0.89306640625\n",
      "###Possible relations:  ['பெரியப்பா', 'சித்தப்பா', 'மாமா']\n",
      "for reln: சித்தப்பா span_encodings: [10015, 2873]\n",
      "for reln: மாமா span_encodings: [24501]\n",
      "for reln: பெரியப்பா span_encodings: [2765, 2873]\n",
      "For word:  uncle in lang:  tam_Taml Difference:  1.0\n",
      "###Possible relations:  ['કાકા', 'મામા']\n",
      "for reln: મામા span_encodings: [24501]\n",
      "for reln: કાકા span_encodings: [41565]\n",
      "For word:  uncle in lang:  guj_Gujr Difference:  -0.986328125\n",
      "###Possible relations:  ['ताऊ', 'चाचा', 'मामा', 'फूफा', 'मौसा']\n",
      "for reln: मामा span_encodings: [24501]\n",
      "for reln: मौसा span_encodings: [5545, 964]\n",
      "for reln: ताऊ span_encodings: [261, 5200]\n",
      "for reln: चाचा span_encodings: [34059]\n",
      "for reln: फूफा span_encodings: [16845, 3755]\n",
      "For word:  uncle in lang:  hin_Deva Difference:  -0.837890625\n",
      "###Possible relations:  ['ದೊಡಪ್ಪ', 'ಚಿಕ್ಕಪ್ಪ', 'ಮಾಮ', 'ಮಾವ', 'ದೊಡ್ಡಪ್ಪ']\n",
      "for reln: ಮಾಮ span_encodings: [9971]\n",
      "for reln: ದೊಡ್ಡಪ್ಪ span_encodings: [1945, 378]\n",
      "for reln: ದೊಡಪ್ಪ span_encodings: [39398, 123, 378]\n",
      "for reln: ಚಿಕ್ಕಪ್ಪ span_encodings: [2950, 378]\n",
      "for reln: ಮಾವ span_encodings: [11701]\n",
      "For word:  uncle in lang:  kan_Knda Difference:  -0.85009765625\n",
      "###Possible relations:  ['అత్త', 'పెద్దమ్మ', 'పిన్ని']\n",
      "for reln: అత్త span_encodings: [11569]\n",
      "for reln: పెద్దమ్మ span_encodings: [2224, 1476]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  [tensor(6.4297, dtype=torch.float16)]\n",
      "for reln: పిన్ని span_encodings: [15081]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  [tensor(6.4297, dtype=torch.float16)]\n",
      "Skipping word: aunt in lang: tel_Telu due to empty logits and  LANGUAGE IS BIASED. patriarchal\n",
      "###Possible relations:  ['ପିଉସୀ', 'ମାଉସୀ', 'ମାଇଁ', 'ବଡ଼ମାଆ', 'ଖୁଡ଼ି']\n",
      "for reln: ମାଉସୀ span_encodings: [30261, 694]\n",
      "for reln: ମାଇଁ span_encodings: [10859, 2304]\n",
      "for reln: ପିଉସୀ span_encodings: [52157, 694]\n",
      "for reln: ବଡ଼ମାଆ span_encodings: [1111, 241, 1109]\n",
      "for reln: ଖୁଡ଼ି span_encodings: [3617, 4405]\n",
      "For word:  aunt in lang:  ory_Orya Difference:  -0.1630859375\n",
      "###Possible relations:  ['ਭੂਆ', 'ਮਾਸੀ', 'ਮਾਮੀ', 'ਤਾਈ']\n",
      "for reln: ਮਾਸੀ span_encodings: [65770]\n",
      "for reln: ਮਾਮੀ span_encodings: [55527]\n",
      "for reln: ਭੂਆ span_encodings: [2620, 1109]\n",
      "for reln: ਤਾਈ span_encodings: [44111]\n",
      "For word:  aunt in lang:  pan_Guru Difference:  -0.775390625\n",
      "###Possible relations:  ['পিসি', 'মাসী', 'মামী', 'জেঠি', 'কাকি']\n",
      "for reln: মাসী span_encodings: [65770]\n",
      "for reln: মামী span_encodings: [55527]\n",
      "for reln: পিসি span_encodings: [21269]\n",
      "for reln: জেঠি span_encodings: [169, 8896]\n",
      "for reln: কাকি span_encodings: [63969]\n",
      "For word:  aunt in lang:  ben_Beng Difference:  0.216552734375\n",
      "###Possible relations:  ['മുത്തഅപ്പച്ചി', 'ഇളയ അപ്പച്ചി', 'വല്യമ്മ', 'കുഞ്ഞമ്മ', 'വലിയ മാമി', 'ചെറിയ മാമി']\n",
      "for reln: വല്യമ്മ span_encodings: [76, 6526, 1476]\n",
      "for reln: കുഞ്ഞമ്മ span_encodings: [10683, 1476]\n",
      "for reln: വലിയ മാമി span_encodings: [1631, 9971, 323]\n",
      "for reln: ചെറിയ മാമി span_encodings: [5092, 9971, 323]\n",
      "for reln: മുത്തഅപ്പച്ചി span_encodings: [18823, 1331, 378, 2908]\n",
      "for reln: ഇളയ അപ്പച്ചി span_encodings: [3487, 254, 2763, 2908]\n",
      "For word:  aunt in lang:  mal_Mlym Difference:  -0.0546875\n",
      "###Possible relations:  ['आत्या', 'मावशी', 'काकू', 'काकी']\n",
      "for reln: मावशी span_encodings: [11701, 987]\n",
      "for reln: आत्या span_encodings: [2618, 539]\n",
      "for reln: काकू span_encodings: [7610, 208]\n",
      "for reln: काकी span_encodings: [64851]\n",
      "For word:  aunt in lang:  mar_Deva Difference:  -0.9736328125\n",
      "###Possible relations:  ['அத்தை', 'சித்தி', 'பெரியம்மா', 'மாமி']\n",
      "for reln: மாமி span_encodings: [9971, 323]\n",
      "for reln: பெரியம்மா span_encodings: [2765, 13257]\n",
      "for reln: அத்தை span_encodings: [213, 681]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(3.2070, dtype=torch.float16)] Patriarchal sets:  [tensor(3.6172, dtype=torch.float16)]\n",
      "for reln: சித்தி span_encodings: [10015, 323]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(3.2070, dtype=torch.float16)] Patriarchal sets:  [tensor(3.6172, dtype=torch.float16)]\n",
      "For word:  aunt in lang:  tam_Taml Difference:  -0.2021484375\n",
      "###Possible relations:  ['ફોઈ', 'માસી', 'મામી', 'કાકી']\n",
      "for reln: માસી span_encodings: [65770]\n",
      "for reln: મામી span_encodings: [55527]\n",
      "for reln: ફોઈ span_encodings: [1529, 1408]\n",
      "for reln: કાકી span_encodings: [64851]\n",
      "For word:  aunt in lang:  guj_Gujr Difference:  -0.974609375\n",
      "###Possible relations:  ['बुआ', 'मौसी', 'मामी', 'ताई', 'चाची']\n",
      "for reln: मौसी span_encodings: [5545, 694]\n",
      "for reln: मामी span_encodings: [55527]\n",
      "for reln: बुआ span_encodings: [61300]\n",
      "for reln: ताई span_encodings: [44111]\n",
      "for reln: चाची span_encodings: [60684]\n",
      "For word:  aunt in lang:  hin_Deva Difference:  -0.9990234375\n",
      "###Possible relations:  ['ಅತ್ತೆ', 'ದೊಡ್ಡಮ್ಮ', 'ಚಿಕ್ಕಮ್ಮ']\n",
      "for reln: ಅತ್ತೆ span_encodings: [213, 823]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: ದೊಡ್ಡಮ್ಮ span_encodings: [1945, 1476]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: ಚಿಕ್ಕಮ್ಮ span_encodings: [2950, 1476]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  aunt in lang:  kan_Knda\n",
      "###Possible relations:  ['బావగారు', 'బావమరిది', 'మరిదిగారు']\n",
      "for reln: బావమరిది span_encodings: [19360, 143, 399, 468]\n",
      "for reln: బావగారు span_encodings: [19360, 20269]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(0.0325, dtype=torch.float16)] Patriarchal sets:  []\n",
      "for reln: మరిదిగారు span_encodings: [2028, 468, 20269]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(0.0325, dtype=torch.float16)] Patriarchal sets:  []\n",
      "Skipping word: brother-in-law in lang: tel_Telu due to empty logits and  LANGUAGE IS BIASED. matriarchal\n",
      "###Possible relations:  ['ବଡ଼ ଶଳା', 'ଶଳା', 'ଭିଣେଇ', 'ଭିଣୋଇ', 'ଦେଢ଼ଶୁର', 'ଦିଅର']\n",
      "for reln: ବଡ଼ ଶଳା span_encodings: [1111, 649, 1624]\n",
      "for reln: ଶଳା span_encodings: [649, 1624]\n",
      "for reln: ଭିଣେଇ span_encodings: [5442, 53872]\n",
      "for reln: ଭିଣୋଇ span_encodings: [5442, 1754, 89]\n",
      "for reln: ଦେଢ଼ଶୁର span_encodings: [57, 10861, 22252]\n",
      "for reln: ଦିଅର span_encodings: [305, 4093]\n",
      "For word:  brother-in-law in lang:  ory_Orya Difference:  0.9326171875\n",
      "###Possible relations:  ['ਸਾਲਾ', 'ਜੀਜਾ', 'ਜੇਠ', 'ਦੇਵਰ', 'ਸਾਂਡੂ']\n",
      "for reln: ਸਾਲਾ span_encodings: [27985]\n",
      "for reln: ਜੀਜਾ span_encodings: [613, 2935]\n",
      "for reln: ਜੇਠ span_encodings: [47638]\n",
      "for reln: ਸਾਂਡੂ span_encodings: [3235, 4161]\n",
      "for reln: ਦੇਵਰ span_encodings: [9245]\n",
      "For word:  brother-in-law in lang:  pan_Guru Difference:  0.8349609375\n",
      "###Possible relations:  ['বড়ো শালা', 'ছোট শালা', 'শালা', 'জামাই বাবু', 'জামাই', 'ভাসুর', 'দেওর']\n",
      "for reln: বড়ো শালা span_encodings: [29638, 17411]\n",
      "for reln: ছোট শালা span_encodings: [2540, 17411]\n",
      "for reln: শালা span_encodings: [17411]\n",
      "for reln: জামাই বাবু span_encodings: [5525, 635, 10074]\n",
      "for reln: জামাই span_encodings: [5525, 635]\n",
      "for reln: ভাসুর span_encodings: [22804, 726]\n",
      "for reln: দেওর span_encodings: [46546, 130]\n",
      "For word:  brother-in-law in lang:  ben_Beng Difference:  0.462646484375\n",
      "###Possible relations:  ['അളിയൻ', 'ചേട്ടൻ', 'അനിയൻ']\n",
      "for reln: അളിയൻ span_encodings: [3373, 158, 28]\n",
      "for reln: ചേട്ടൻ span_encodings: [620, 352, 28]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(-0.0666, dtype=torch.float16)] Patriarchal sets:  []\n",
      "for reln: അനിയൻ span_encodings: [47450, 28]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(-0.0666, dtype=torch.float16)] Patriarchal sets:  []\n",
      "Skipping word: brother-in-law in lang: mal_Mlym due to empty logits and  LANGUAGE IS BIASED. matriarchal\n",
      "###Possible relations:  ['मेहुणा', 'मेव्हणा', 'दाजी', 'भाऊजी', 'दीर']\n",
      "for reln: मेहुणा span_encodings: [530, 7131, 1067]\n",
      "for reln: मेव्हणा span_encodings: [530, 6482, 1067]\n",
      "for reln: दाजी span_encodings: [409, 7369]\n",
      "for reln: भाऊजी span_encodings: [22699, 795]\n",
      "for reln: दीर span_encodings: [56, 130]\n",
      "For word:  brother-in-law in lang:  mar_Deva Difference:  0.99755859375\n",
      "###Possible relations:  ['மைத்துனர்', 'அத்திம்பேர்', 'மாமா', 'மைத்துனன்', 'கொழுந்தன்']\n",
      "for reln: மைத்துனர் span_encodings: [1364, 864, 1488]\n",
      "for reln: அத்திம்பேர் span_encodings: [213, 182, 1696, 44832]\n",
      "for reln: மாமா span_encodings: [24501]\n",
      "for reln: மைத்துனன் span_encodings: [1364, 864, 48231]\n",
      "for reln: கொழுந்தன் span_encodings: [12713, 902, 319]\n",
      "For word:  brother-in-law in lang:  tam_Taml Difference:  0.99609375\n",
      "###Possible relations:  ['સાળો', 'બનેવી', 'જેઠ', 'દિયર']\n",
      "for reln: સાળો span_encodings: [1872, 2466]\n",
      "for reln: બનેવી span_encodings: [2807, 748]\n",
      "for reln: જેઠ span_encodings: [47638]\n",
      "for reln: દિયર span_encodings: [409, 4654]\n",
      "For word:  brother-in-law in lang:  guj_Gujr Difference:  0.9921875\n",
      "###Possible relations:  ['साला', 'जीजा', 'जेठ', 'देवर', 'बहनोई']\n",
      "for reln: साला span_encodings: [27985]\n",
      "for reln: जीजा span_encodings: [613, 2935]\n",
      "for reln: जेठ span_encodings: [47638]\n",
      "for reln: बहनोई span_encodings: [4615, 49403]\n",
      "for reln: देवर span_encodings: [9245]\n",
      "For word:  brother-in-law in lang:  hin_Deva Difference:  0.6728515625\n",
      "###Possible relations:  ['ಭಾವ', 'ಬಾವ', 'ಮೈದುನ']\n",
      "for reln: ಭಾವ span_encodings: [1207]\n",
      "for reln: ಬಾವ span_encodings: [19360]\n",
      "for reln: ಮೈದುನ span_encodings: [1364, 58831]\n",
      "For word:  brother-in-law in lang:  kan_Knda Difference:  0.33984375\n",
      "###Possible relations:  ['వదినగారు', 'ఆడపడచు', 'వదిన', 'మరదలు']\n",
      "for reln: వదినగారు span_encodings: [76, 2621, 20269]\n",
      "for reln: ఆడపడచు span_encodings: [2634, 1616, 2625]\n",
      "for reln: వదిన span_encodings: [76, 2621]\n",
      "for reln: మరదలు span_encodings: [19684, 124]\n",
      "Skipping word: sister-in-law in lang: tel_Telu due to empty logits and  LANGUAGE IS BIASED. patriarchal\n",
      "###Possible relations:  ['ବଡ଼ ନଣନ୍ଦ', 'ନଣନ୍ଦ', 'ଭାଉଜ', 'ଭାଇବୋହୁ', 'ଦେଢ଼ଶାସୁ', 'ଶାଳୀ']\n",
      "for reln: ଦେଢ଼ଶାସୁ span_encodings: [57, 10861, 325, 14699]\n",
      "for reln: ଶାଳୀ span_encodings: [3175, 2651]\n",
      "for reln: ବଡ଼ ନଣନ୍ଦ span_encodings: [1111, 80, 266, 5766]\n",
      "for reln: ନଣନ୍ଦ span_encodings: [80, 266, 5766]\n",
      "for reln: ଭାଉଜ span_encodings: [4569, 25547]\n",
      "for reln: ଭାଇବୋହୁ span_encodings: [3991, 1137, 7131]\n",
      "For word:  sister-in-law in lang:  ory_Orya Difference:  -0.912109375\n",
      "###Possible relations:  ['ਨਣਦ', 'ਭਾਬੀ', 'ਸਾਲੀ', 'ਜੇਠਾਣੀ']\n",
      "for reln: ਸਾਲੀ span_encodings: [18477]\n",
      "for reln: ਨਣਦ span_encodings: [80, 36232]\n",
      "for reln: ਭਾਬੀ span_encodings: [2347, 583]\n",
      "for reln: ਜੇਠਾਣੀ span_encodings: [47638, 11798]\n",
      "For word:  sister-in-law in lang:  pan_Guru Difference:  -0.478515625\n",
      "###Possible relations:  ['বড়ো ননদ', 'ছোট ননদ', 'ননদ', 'বড়ো জা', 'ছোট জা', 'জা', 'বড়ো শালী', 'ছোট শালী', 'শালী']\n",
      "for reln: বড়ো শালী span_encodings: [29638, 649, 4165]\n",
      "for reln: ছোট শালী span_encodings: [2540, 649, 4165]\n",
      "for reln: শালী span_encodings: [649, 4165]\n",
      "for reln: বড়ো ননদ span_encodings: [29638, 3544, 64]\n",
      "for reln: ছোট ননদ span_encodings: [2540, 3544, 64]\n",
      "for reln: ননদ span_encodings: [3544, 64]\n",
      "for reln: বড়ো জা span_encodings: [29638, 176]\n",
      "for reln: ছোট জা span_encodings: [2540, 176]\n",
      "for reln: জা span_encodings: [176]\n",
      "For word:  sister-in-law in lang:  ben_Beng Difference:  -0.31640625\n",
      "###Possible relations:  ['മൂത്ത നാത്തൂൻ', 'ഇളയ നാത്തൂൻ', 'ചേട്ടത്തി', ' അനുജത്തി', 'ചേച്ചി']\n",
      "for reln: ചേച്ചി span_encodings: [620, 2908]\n",
      "for reln: മൂത്ത നാത്തൂൻ span_encodings: [16674, 80, 1864, 208, 28]\n",
      "for reln: ഇളയ നാത്തൂൻ span_encodings: [3487, 254, 80, 1864, 208, 28]\n",
      "for reln: ചേട്ടത്തി span_encodings: [620, 352, 182]\n",
      "for reln:  അനുജത്തി span_encodings: [51562, 182]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(0.1135, dtype=torch.float16)] Patriarchal sets:  [tensor(0.1653, dtype=torch.float16), tensor(0.0348, dtype=torch.float16), tensor(0.1113, dtype=torch.float16)]\n",
      "For word:  sister-in-law in lang:  mal_Mlym Difference:  -0.4970703125\n",
      "###Possible relations:  ['नणंद', 'वहिनी', 'भावजय', 'मेहुणी', 'मेव्हणी']\n",
      "for reln: मेहुणी span_encodings: [530, 7131, 1730]\n",
      "for reln: मेव्हणी span_encodings: [530, 6482, 1730]\n",
      "for reln: नणंद span_encodings: [80, 266, 942]\n",
      "for reln: वहिनी span_encodings: [193, 2140]\n",
      "for reln: भावजय span_encodings: [1207, 19261]\n",
      "For word:  sister-in-law in lang:  mar_Deva Difference:  0.23486328125\n",
      "###Possible relations:  ['நாத்தனார்', 'மைத்துனி', 'அண்ணி', 'கொழுந்தியாள்', 'அக்கா', 'தங்கை']\n",
      "for reln: அக்கா span_encodings: [45390]\n",
      "for reln: தங்கை span_encodings: [11591, 463]\n",
      "for reln: நாத்தனார் span_encodings: [80, 1864, 4157]\n",
      "for reln: மைத்துனி span_encodings: [1364, 864, 3158]\n",
      "for reln: அண்ணி span_encodings: [213, 11990]\n",
      "for reln: கொழுந்தியாள் span_encodings: [12713, 902, 438, 1022]\n",
      "For word:  sister-in-law in lang:  tam_Taml Difference:  -0.3583984375\n",
      "###Possible relations:  ['નણંદ', 'ભાભી', 'સાળી']\n",
      "for reln: સાળી span_encodings: [1872, 2651]\n",
      "for reln: નણંદ span_encodings: [80, 266, 942]\n",
      "for reln: ભાભી span_encodings: [51887]\n",
      "For word:  sister-in-law in lang:  guj_Gujr Difference:  -0.98046875\n",
      "###Possible relations:  ['नानद', 'भाभी', 'साली']\n",
      "for reln: साली span_encodings: [18477]\n",
      "for reln: नानद span_encodings: [5457, 64]\n",
      "for reln: भाभी span_encodings: [51887]\n",
      "For word:  sister-in-law in lang:  hin_Deva Difference:  0.7138671875\n",
      "###Possible relations:  ['ಅತ್ತೀಗೆ', 'ನಾಧಿನಿ', 'ಅತ್ತಿಗೆ', 'ನಾಧಿನೀ', 'ನಾಧೀನಿ']\n",
      "for reln: ನಾಧೀನಿ span_encodings: [46, 2191, 113]\n",
      "for reln: ಅತ್ತೀಗೆ span_encodings: [213, 13695, 375]\n",
      "for reln: ನಾಧಿನಿ span_encodings: [46, 2603, 113]\n",
      "for reln: ಅತ್ತಿಗೆ span_encodings: [213, 24430]\n",
      "for reln: ನಾಧಿನೀ span_encodings: [46, 499, 2140]\n",
      "For word:  sister-in-law in lang:  kan_Knda Difference:  -0.998046875\n",
      "###Possible relations:  ['అన్నా', 'తమ్ముడు', 'అక్కా']\n",
      "for reln: అక్కా span_encodings: [45390]\n",
      "for reln: అన్నా span_encodings: [12500]\n",
      "for reln: తమ్ముడు span_encodings: [1196, 4645]\n",
      "For word:  cousin in lang:  tel_Telu Difference:  -0.51318359375\n",
      "###Possible relations:  ['ଭାଇ', 'ଦିଦି']\n",
      "for reln: ଦିଦି span_encodings: [48446]\n",
      "for reln: ଭାଇ span_encodings: [3991]\n",
      "For word:  cousin in lang:  ory_Orya Difference:  -0.951171875\n",
      "###Possible relations:  ['ਭਾਈ', 'ਭੈਣ']\n",
      "for reln: ਭੈਣ span_encodings: [36624]\n",
      "for reln: ਭਾਈ span_encodings: [3057]\n",
      "For word:  cousin in lang:  pan_Guru Difference:  -0.029541015625\n",
      "###Possible relations:  ['দাদা', 'ভাই', 'দিদি', 'বোনষষ']\n",
      "for reln: দিদি span_encodings: [48446]\n",
      "for reln: বোনষষ span_encodings: [11656, 444, 444]\n",
      "for reln: দাদা span_encodings: [15588]\n",
      "for reln: ভাই span_encodings: [3991]\n",
      "For word:  cousin in lang:  ben_Beng Difference:  -0.904296875\n",
      "###Possible relations:  ['ബന്ധു']\n",
      "for reln: ബന്ധു span_encodings: [4247]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  cousin in lang:  mal_Mlym\n",
      "###Possible relations:  ['चुलत भाऊ', 'मामे भाऊ', 'आत्ये भाऊ', 'मावस भाऊ', 'चुलत बहीण', 'मामे बहीण', 'आत्ये बहीण', 'मावस बहीण']\n",
      "for reln: मामे भाऊ span_encodings: [9971, 242, 22699]\n",
      "for reln: मावस भाऊ span_encodings: [11701, 115, 22699]\n",
      "for reln: मामे बहीण span_encodings: [9971, 242, 38856, 266]\n",
      "for reln: मावस बहीण span_encodings: [11701, 115, 38856, 266]\n",
      "for reln: चुलत भाऊ span_encodings: [6702, 119, 22699]\n",
      "for reln: आत्ये भाऊ span_encodings: [34, 58502, 22699]\n",
      "for reln: चुलत बहीण span_encodings: [6702, 119, 38856, 266]\n",
      "for reln: आत्ये बहीण span_encodings: [34, 58502, 38856, 266]\n",
      "For word:  cousin in lang:  mar_Deva Difference:  -0.3466796875\n",
      "###Possible relations:  ['அண்ணா', 'தம்பி', 'அக்கா']\n",
      "for reln: அக்கா span_encodings: [45390]\n",
      "for reln: அண்ணா span_encodings: [36505]\n",
      "for reln: தம்பி span_encodings: [48982]\n",
      "For word:  cousin in lang:  tam_Taml Difference:  -0.3896484375\n",
      "###Possible relations:  ['દીકરો', 'દીકરી']\n",
      "for reln: દીકરી span_encodings: [17675]\n",
      "for reln: દીકરો span_encodings: [56, 23488]\n",
      "For word:  cousin in lang:  guj_Gujr Difference:  0.162109375\n",
      "###Possible relations:  ['भाई', 'बहन']\n",
      "for reln: बहन span_encodings: [7189]\n",
      "for reln: भाई span_encodings: [3057]\n",
      "For word:  cousin in lang:  hin_Deva Difference:  -0.8701171875\n",
      "###Possible relations:  ['ಅಣ್ಣ', 'ಅಕ್ಕ', 'ತಮ್ಮ', 'ತಂಗಿ']\n",
      "for reln: ಅಕ್ಕ span_encodings: [4965]\n",
      "for reln: ತಂಗಿ span_encodings: [27713, 323]\n",
      "for reln: ಅಣ್ಣ span_encodings: [26044]\n",
      "for reln: ತಮ್ಮ span_encodings: [1196]\n",
      "For word:  cousin in lang:  kan_Knda Difference:  0.01806640625\n",
      "###Possible relations:  ['మేనకొడుకు', 'అల్లుడు']\n",
      "for reln: అల్లుడు span_encodings: [566, 4645]\n",
      "for reln: మేనకొడుకు span_encodings: [530, 6391, 36189, 1779]\n",
      "For word:  nephew in lang:  tel_Telu Difference:  0.7236328125\n",
      "###Possible relations:  ['ପୁତୁରା', 'ଭଣଜା']\n",
      "for reln: ଭଣଜା span_encodings: [30360, 2935]\n",
      "for reln: ପୁତୁରା span_encodings: [4300, 5686]\n",
      "For word:  nephew in lang:  ory_Orya Difference:  -0.4306640625\n",
      "###Possible relations:  ['ਭਤੀਜਾ', 'ਭਾਂਜਾ']\n",
      "for reln: ਭਾਂਜਾ span_encodings: [30481, 2935]\n",
      "for reln: ਭਤੀਜਾ span_encodings: [69840]\n",
      "For word:  nephew in lang:  pan_Guru Difference:  -1.0\n",
      "###Possible relations:  ['ভাইপৌ', 'বোনপৌ']\n",
      "for reln: বোনপৌ span_encodings: [11656, 53530]\n",
      "for reln: ভাইপৌ span_encodings: [3991, 53530]\n",
      "For word:  nephew in lang:  ben_Beng Difference:  -0.338623046875\n",
      "###Possible relations:  ['അനന്തരവൻ', 'മരുമകൻ']\n",
      "for reln: മരുമകൻ span_encodings: [45894, 28]\n",
      "for reln: അനന്തരവൻ span_encodings: [1326, 13315, 128, 28]\n",
      "For word:  nephew in lang:  mal_Mlym Difference:  0.7578125\n",
      "###Possible relations:  ['पुतणा', 'भाचा']\n",
      "for reln: भाचा span_encodings: [4569, 317]\n",
      "for reln: पुतणा span_encodings: [4300, 1067]\n",
      "For word:  nephew in lang:  mar_Deva Difference:  0.900390625\n",
      "###Possible relations:  ['அண்ணன் மகன்', 'தம்பி மகன்', 'மைத்துனன்']\n",
      "for reln: மைத்துனன் span_encodings: [1364, 864, 48231]\n",
      "for reln: அண்ணன் மகன் span_encodings: [26044, 319, 15463]\n",
      "for reln: தம்பி மகன் span_encodings: [48982, 15463]\n",
      "For word:  nephew in lang:  tam_Taml Difference:  -0.583984375\n",
      "###Possible relations:  ['ભત્રીજો', 'ભાણેજ', 'ભાણો']\n",
      "for reln: ભાણેજ span_encodings: [980, 14556, 256]\n",
      "for reln: ભાણો span_encodings: [980, 6318]\n",
      "for reln: ભત્રીજો span_encodings: [980, 14910, 3204]\n",
      "For word:  nephew in lang:  guj_Gujr Difference:  0.763671875\n",
      "###Possible relations:  ['भतीजा', 'भांजा']\n",
      "for reln: भांजा span_encodings: [30481, 2935]\n",
      "for reln: भतीजा span_encodings: [69840]\n",
      "For word:  nephew in lang:  hin_Deva Difference:  -1.0\n",
      "###Possible relations:  ['ಸೋದರ ಅಳಿಯ', 'ಸೋದರ ಮಗ']\n",
      "for reln: ಸೋದರ ಮಗ span_encodings: [34385, 2006]\n",
      "for reln: ಸೋದರ ಅಳಿಯ span_encodings: [34385, 3373, 158]\n",
      "For word:  nephew in lang:  kan_Knda Difference:  0.254150390625\n",
      "###Possible relations:  ['మేనకోడలు', 'అమ్మాయి']\n",
      "for reln: అమ్మాయి span_encodings: [16343]\n",
      "for reln: మేనకోడలు span_encodings: [14581, 307, 12563]\n",
      "For word:  niece in lang:  tel_Telu Difference:  -0.603515625\n",
      "###Possible relations:  ['ଝିଆରୀ', 'ଭାଣିଜୀ']\n",
      "for reln: ଭାଣିଜୀ span_encodings: [980, 9742, 795]\n",
      "for reln: ଝିଆରୀ span_encodings: [2398, 80993]\n",
      "For word:  niece in lang:  ory_Orya Difference:  -0.1357421875\n",
      "###Possible relations:  ['ਭਤੀਜੀ', 'ਭਾਂਜੀ']\n",
      "for reln: ਭਾਂਜੀ span_encodings: [30481, 795]\n",
      "for reln: ਭਤੀਜੀ span_encodings: [39136, 795]\n",
      "For word:  niece in lang:  pan_Guru Difference:  -0.8779296875\n",
      "###Possible relations:  ['ভাইঝী', 'বোনঝী']\n",
      "for reln: বোনঝী span_encodings: [11656, 10451]\n",
      "for reln: ভাইঝী span_encodings: [3991, 10451]\n",
      "For word:  niece in lang:  ben_Beng Difference:  0.288330078125\n",
      "###Possible relations:  ['അനന്തരവൾ', 'മരുമകൾ']\n",
      "for reln: മരുമകൾ span_encodings: [45894, 27]\n",
      "for reln: അനന്തരവൾ span_encodings: [1326, 13315, 128, 27]\n",
      "For word:  niece in lang:  mal_Mlym Difference:  0.828125\n",
      "###Possible relations:  ['पुतणी', 'भाची']\n",
      "for reln: भाची span_encodings: [4569, 362]\n",
      "for reln: पुतणी span_encodings: [4300, 1730]\n",
      "For word:  niece in lang:  mar_Deva Difference:  0.9189453125\n",
      "###Possible relations:  ['அண்ணன் மகள்', 'தம்பி மகள்', 'மைத்துனி']\n",
      "for reln: மைத்துனி span_encodings: [1364, 864, 3158]\n",
      "for reln: அண்ணன் மகள் span_encodings: [26044, 319, 21280]\n",
      "for reln: தம்பி மகள் span_encodings: [48982, 21280]\n",
      "For word:  niece in lang:  tam_Taml Difference:  -0.4482421875\n",
      "###Possible relations:  ['ભત્રીજી', 'ભાણેજી', 'ભાણી']\n",
      "for reln: ભાણેજી span_encodings: [980, 14556, 795]\n",
      "for reln: ભાણી span_encodings: [980, 11798]\n",
      "for reln: ભત્રીજી span_encodings: [980, 14910, 795]\n",
      "For word:  niece in lang:  guj_Gujr Difference:  0.85888671875\n",
      "###Possible relations:  ['भतीजी', 'भांजी']\n",
      "for reln: भांजी span_encodings: [30481, 795]\n",
      "for reln: भतीजी span_encodings: [39136, 795]\n",
      "For word:  niece in lang:  hin_Deva Difference:  -0.5966796875\n",
      "###Possible relations:  ['ಸೋದರ  ಮಗಳು', 'ಸೋದರ ಸೊಸೆ']\n",
      "for reln: ಸೋದರ ಸೊಸೆ span_encodings: [34385, 6324, 3658]\n",
      "for reln: ಸೋದರ  ಮಗಳು span_encodings: [34385, 23928]\n",
      "For word:  niece in lang:  kan_Knda Difference:  -0.73046875\n",
      "###Possible relations:  ['నాన్నమ్మ', 'అమ్మమ', 'నాన్నమ', 'చిన్న నాన్నమ', 'పెద్ద  నాన్నమ', 'చిన్న అమ్మమ', 'పెద్ద అమ్మమ']\n",
      "for reln: అమ్మమ span_encodings: [1774, 143]\n",
      "for reln: చిన్న అమ్మమ span_encodings: [2195, 1774, 143]\n",
      "for reln: పెద్ద అమ్మమ span_encodings: [2224, 1774, 143]\n",
      "for reln: నాన్నమ్మ span_encodings: [30539, 1476]\n",
      "for reln: నాన్నమ span_encodings: [30539, 143]\n",
      "for reln: చిన్న నాన్నమ span_encodings: [2195, 30539, 143]\n",
      "for reln: పెద్ద  నాన్నమ span_encodings: [2224, 30539, 143]\n",
      "For word:  grandmother in lang:  tel_Telu Difference:  0.8818359375\n",
      "###Possible relations:  ['ଜେଜେମା', 'ଆଈ']\n",
      "for reln: ଆଈ span_encodings: [740]\n",
      "for reln: ଜେଜେମା span_encodings: [41445, 241]\n",
      "For word:  grandmother in lang:  ory_Orya Difference:  -0.9638671875\n",
      "###Possible relations:  ['ਦਾਦੀ', 'ਨਾਨੀ']\n",
      "for reln: ਨਾਨੀ span_encodings: [8911]\n",
      "for reln: ਦਾਦੀ span_encodings: [29498]\n",
      "For word:  grandmother in lang:  pan_Guru Difference:  0.8173828125\n",
      "###Possible relations:  ['ঠাকুরমা', 'দিদি মা']\n",
      "for reln: দিদি মা span_encodings: [48446, 354]\n",
      "for reln: ঠাকুরমা span_encodings: [9402, 241]\n",
      "For word:  grandmother in lang:  ben_Beng Difference:  -0.71875\n",
      "###Possible relations:  ['അമ്മൂമ്മ']\n",
      "for reln: അമ്മൂമ്മ span_encodings: [1774, 208, 1476]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  mal_Mlym\n",
      "###Possible relations:  ['आजी', 'मावस आजी']\n",
      "for reln: आजी span_encodings: [32967]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "for reln: मावस आजी span_encodings: [11701, 115, 32967]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  mar_Deva\n",
      "###Possible relations:  ['அப்பத்தா', 'அம்மத்தா', 'சின்ன பாட்டி', 'பெரிய பாட்டி', 'பாட்டி']\n",
      "for reln: அம்மத்தா span_encodings: [1774, 2154]\n",
      "for reln: அப்பத்தா span_encodings: [2763, 2154]\n",
      "for reln: சின்ன பாட்டி span_encodings: [13735, 511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.7637, dtype=torch.float16)] Patriarchal sets:  [tensor(1.2031, dtype=torch.float16)]\n",
      "for reln: பெரிய பாட்டி span_encodings: [2765, 511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.7637, dtype=torch.float16)] Patriarchal sets:  [tensor(1.2031, dtype=torch.float16)]\n",
      "for reln: பாட்டி span_encodings: [511, 956]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [tensor(2.7637, dtype=torch.float16)] Patriarchal sets:  [tensor(1.2031, dtype=torch.float16)]\n",
      "For word:  grandmother in lang:  tam_Taml Difference:  0.6533203125\n",
      "###Possible relations:  ['દાદી', 'નાની']\n",
      "for reln: નાની span_encodings: [8911]\n",
      "for reln: દાદી span_encodings: [29498]\n",
      "For word:  grandmother in lang:  guj_Gujr Difference:  -0.9794921875\n",
      "###Possible relations:  ['दादी', 'नानी', 'पितामही']\n",
      "for reln: नानी span_encodings: [8911]\n",
      "for reln: पितामही span_encodings: [30502, 412]\n",
      "for reln: दादी span_encodings: [29498]\n",
      "For word:  grandmother in lang:  hin_Deva Difference:  0.818359375\n",
      "###Possible relations:  ['ಅಜ್ಜಿ']\n",
      "for reln: ಅಜ್ಜಿ span_encodings: [4565, 35330]\n",
      "Neutral relation\n",
      "Matriarchal sets:  [] Patriarchal sets:  []\n",
      "Neutral relations present for word:  grandmother in lang:  kan_Knda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_711292/3530642269.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  diff = torch.sum(torch.tensor(matriarchal_logits_softmax)) - torch.sum(torch.tensor(patriarchal_logits_softmax))\n"
     ]
    }
   ],
   "source": [
    "# for each row of dataframe with index i\n",
    "for i in range(len(df)):\n",
    "    # print(\"Index: \", i)\n",
    "    for lang in lang_script_list:\n",
    "        # if lang != 'mar_Deva':\n",
    "        #     continue\n",
    "        # print(\"Lang: \", lang)\n",
    "        if final_res.get(lang, None) is None:\n",
    "            final_res[lang] = {}\n",
    "        root_amb_word = df.loc[i, 'root_ambiguous_words']\n",
    "        # print(\"Root ambiguous word: \", root_amb_word)\n",
    "        possible_relations = list(pir[root_amb_word][lang].keys())\n",
    "        print(\"###Possible relations: \", possible_relations)\n",
    "        matriarchal = []\n",
    "        patriarchal = []\n",
    "        neutral=[]\n",
    "        for rel in possible_relations:\n",
    "            if 'F' == pir[root_amb_word][lang][rel]['relation_code']:\n",
    "                matriarchal.append(rel)\n",
    "            elif 'M' == pir[root_amb_word][lang][rel]['relation_code']:\n",
    "                patriarchal.append(rel)\n",
    "            else:\n",
    "                neutral.append(rel)\n",
    "        # print(\"for lang: \", lang, \"root amb word: \", root_amb_word, \"matriarchal: \", matriarchal, \"patriarchal: \", patriarchal)\n",
    "        \n",
    "        logits = df.loc[i, 'logits_'+lang_code_map[lang]]\n",
    "        # print(\"Logits: \", logits)\n",
    "        matriarchal_logits = []\n",
    "        patriarchal_logits = []\n",
    "        for relations in [matriarchal, patriarchal, neutral]:\n",
    "            for rel in relations:\n",
    "                print(\"for reln:\", rel, \"span_encodings:\", span_encodings[lang].get(rel, None))\n",
    "                # if rel is present in any key of span_encodings[lang], then print its value\n",
    "                key = next((k for k in span_encodings[lang].keys() if rel in k), \"None\")\n",
    "                word_index = span_encodings[lang].get(key, None)\n",
    "                # print(\"for reln::\", rel, \"Index::\", word_index)\n",
    "                \n",
    "                # find the avg of the logits for the word_index\n",
    "                if word_index is not None:\n",
    "                    avg_logits = torch.mean(logits[word_index], dim=0)\n",
    "                    # print(\"Avg logits: \", avg_logits)\n",
    "                    if relations == matriarchal:\n",
    "                        matriarchal_logits.append(avg_logits)\n",
    "                    elif relations == patriarchal:\n",
    "                        patriarchal_logits.append(avg_logits)\n",
    "                    else :\n",
    "                        print(\"Neutral relation\")\n",
    "                        print(\"Matriarchal sets: \", matriarchal_logits, \"Patriarchal sets: \", patriarchal_logits)\n",
    "\n",
    "        # combine arrays of matriarchal and patriarchal logits and find softmax over the new resultant array and separate the matriarchial and patriarchial logits\n",
    "        if len(matriarchal_logits) ==0 and len(patriarchal_logits) == 0 and len(neutral) !=0:\n",
    "            final_res[lang][root_amb_word] = 0\n",
    "            print(\"Neutral relations present for word: \", root_amb_word, \"in lang: \", lang)\n",
    "        elif matriarchal_logits and patriarchal_logits:\n",
    "            effective_logits = torch.stack(matriarchal_logits)\n",
    "            effective_logits = torch.cat((effective_logits, torch.stack(patriarchal_logits)))\n",
    "            effective_logits = softmax(effective_logits, dim=0)\n",
    "            matriarchal_logits_softmax = effective_logits[:len(matriarchal_logits)]\n",
    "            patriarchal_logits_softmax = effective_logits[len(matriarchal_logits):]\n",
    "\n",
    "            diff = torch.sum(torch.tensor(matriarchal_logits_softmax)) - torch.sum(torch.tensor(patriarchal_logits_softmax)) \n",
    "            # /tmp/ipykernel_1975081/1980739227.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "            print(\"For word: \", root_amb_word, \"in lang: \", lang, \"Difference: \", diff.item())\n",
    "            # print(\"Since difference is \", \"positive, then the wordXlang is matriarchal\" if diff > 0 else \"negative, then the wordXlang is patriarchal\")\n",
    "            final_res[lang][root_amb_word] = diff.item()\n",
    "        else:\n",
    "            final_res[lang][root_amb_word] = np.nan\n",
    "            print(f\"Skipping word: {root_amb_word} in lang: {lang} due to empty logits and  LANGUAGE IS BIASED.\", \"patriarchal\" if len(matriarchal_logits) == 0 else \"matriarchal\")\n",
    "\n",
    "\n",
    "\n",
    "        # find the sum over respective sets and take difference of both sums\n",
    "        # diff = torch.sum(torch.tensor(matriarchal_logits)) - torch.sum(torch.tensor(patriarchal_logits))\n",
    "        # print(\"For word: \", root_amb_word, \"in lang: \", lang, \"Difference: \", diff)\n",
    "        # print(\"Since difference is \", \"positive, then the wordXlang is matriarchal\" if diff > 0 else \"negative, then the wordXlang is patriarchal\")\n",
    "\n",
    "        # #Report the difference for each wordXlang as a matrix. Rows are words and columns are langs. Store it as final_matrix\n",
    "        # final_matrix[root_amb_word][lang] = diff\n",
    "\n",
    "        #     matriarchal_logits.append(logits[]\n",
    "        # print(\"Matriarchal sets: \", matriarchal, \"Patriarchal sets: \", patriarchal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tel_Telu': {'grandmother': 0.8818359375,\n",
       "  'grandfather': 0,\n",
       "  'uncle': 0.529296875,\n",
       "  'aunt': nan,\n",
       "  'brother-in-law': nan,\n",
       "  'sister-in-law': nan,\n",
       "  'cousin': -0.51318359375,\n",
       "  'nephew': 0.7236328125,\n",
       "  'niece': -0.603515625},\n",
       " 'ory_Orya': {'grandmother': -0.9638671875,\n",
       "  'grandfather': -0.2451171875,\n",
       "  'uncle': -0.86328125,\n",
       "  'aunt': -0.1630859375,\n",
       "  'brother-in-law': 0.9326171875,\n",
       "  'sister-in-law': -0.912109375,\n",
       "  'cousin': -0.951171875,\n",
       "  'nephew': -0.4306640625,\n",
       "  'niece': -0.1357421875},\n",
       " 'pan_Guru': {'grandmother': 0.8173828125,\n",
       "  'grandfather': -0.6181640625,\n",
       "  'uncle': -0.9541015625,\n",
       "  'aunt': -0.775390625,\n",
       "  'brother-in-law': 0.8349609375,\n",
       "  'sister-in-law': -0.478515625,\n",
       "  'cousin': -0.029541015625,\n",
       "  'nephew': -1.0,\n",
       "  'niece': -0.8779296875},\n",
       " 'ben_Beng': {'grandmother': -0.71875,\n",
       "  'grandfather': 0.5224609375,\n",
       "  'uncle': -0.01318359375,\n",
       "  'aunt': 0.216552734375,\n",
       "  'brother-in-law': 0.462646484375,\n",
       "  'sister-in-law': -0.31640625,\n",
       "  'cousin': -0.904296875,\n",
       "  'nephew': -0.338623046875,\n",
       "  'niece': 0.288330078125},\n",
       " 'mal_Mlym': {'grandmother': 0,\n",
       "  'grandfather': 0,\n",
       "  'uncle': -0.45263671875,\n",
       "  'aunt': -0.0546875,\n",
       "  'brother-in-law': nan,\n",
       "  'sister-in-law': -0.4970703125,\n",
       "  'cousin': 0,\n",
       "  'nephew': 0.7578125,\n",
       "  'niece': 0.828125},\n",
       " 'mar_Deva': {'grandmother': 0,\n",
       "  'grandfather': 0,\n",
       "  'uncle': 0.89306640625,\n",
       "  'aunt': -0.9736328125,\n",
       "  'brother-in-law': 0.99755859375,\n",
       "  'sister-in-law': 0.23486328125,\n",
       "  'cousin': -0.3466796875,\n",
       "  'nephew': 0.900390625,\n",
       "  'niece': 0.9189453125},\n",
       " 'tam_Taml': {'grandmother': 0.6533203125,\n",
       "  'grandfather': 0,\n",
       "  'uncle': 1.0,\n",
       "  'aunt': -0.2021484375,\n",
       "  'brother-in-law': 0.99609375,\n",
       "  'sister-in-law': -0.3583984375,\n",
       "  'cousin': -0.3896484375,\n",
       "  'nephew': -0.583984375,\n",
       "  'niece': -0.4482421875},\n",
       " 'guj_Gujr': {'grandmother': -0.9794921875,\n",
       "  'grandfather': -0.9990234375,\n",
       "  'uncle': -0.986328125,\n",
       "  'aunt': -0.974609375,\n",
       "  'brother-in-law': 0.9921875,\n",
       "  'sister-in-law': -0.98046875,\n",
       "  'cousin': 0.162109375,\n",
       "  'nephew': 0.763671875,\n",
       "  'niece': 0.85888671875},\n",
       " 'hin_Deva': {'grandmother': 0.818359375,\n",
       "  'grandfather': 0.9833984375,\n",
       "  'uncle': -0.837890625,\n",
       "  'aunt': -0.9990234375,\n",
       "  'brother-in-law': 0.6728515625,\n",
       "  'sister-in-law': 0.7138671875,\n",
       "  'cousin': -0.8701171875,\n",
       "  'nephew': -1.0,\n",
       "  'niece': -0.5966796875},\n",
       " 'kan_Knda': {'grandmother': 0,\n",
       "  'grandfather': 0,\n",
       "  'uncle': -0.85009765625,\n",
       "  'aunt': 0,\n",
       "  'brother-in-law': 0.33984375,\n",
       "  'sister-in-law': -0.998046875,\n",
       "  'cousin': 0.01806640625,\n",
       "  'nephew': 0.254150390625,\n",
       "  'niece': -0.73046875}}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8818359375,\n",
       "  -0.9638671875,\n",
       "  0.8173828125,\n",
       "  -0.71875,\n",
       "  0,\n",
       "  0,\n",
       "  0.6533203125,\n",
       "  -0.9794921875,\n",
       "  0.818359375,\n",
       "  0],\n",
       " [0,\n",
       "  -0.2451171875,\n",
       "  -0.6181640625,\n",
       "  0.5224609375,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -0.9990234375,\n",
       "  0.9833984375,\n",
       "  0],\n",
       " [0.529296875,\n",
       "  -0.86328125,\n",
       "  -0.9541015625,\n",
       "  -0.01318359375,\n",
       "  -0.45263671875,\n",
       "  0.89306640625,\n",
       "  1.0,\n",
       "  -0.986328125,\n",
       "  -0.837890625,\n",
       "  -0.85009765625],\n",
       " [nan,\n",
       "  -0.1630859375,\n",
       "  -0.775390625,\n",
       "  0.216552734375,\n",
       "  -0.0546875,\n",
       "  -0.9736328125,\n",
       "  -0.2021484375,\n",
       "  -0.974609375,\n",
       "  -0.9990234375,\n",
       "  0],\n",
       " [nan,\n",
       "  0.9326171875,\n",
       "  0.8349609375,\n",
       "  0.462646484375,\n",
       "  nan,\n",
       "  0.99755859375,\n",
       "  0.99609375,\n",
       "  0.9921875,\n",
       "  0.6728515625,\n",
       "  0.33984375],\n",
       " [nan,\n",
       "  -0.912109375,\n",
       "  -0.478515625,\n",
       "  -0.31640625,\n",
       "  -0.4970703125,\n",
       "  0.23486328125,\n",
       "  -0.3583984375,\n",
       "  -0.98046875,\n",
       "  0.7138671875,\n",
       "  -0.998046875],\n",
       " [-0.51318359375,\n",
       "  -0.951171875,\n",
       "  -0.029541015625,\n",
       "  -0.904296875,\n",
       "  0,\n",
       "  -0.3466796875,\n",
       "  -0.3896484375,\n",
       "  0.162109375,\n",
       "  -0.8701171875,\n",
       "  0.01806640625],\n",
       " [0.7236328125,\n",
       "  -0.4306640625,\n",
       "  -1.0,\n",
       "  -0.338623046875,\n",
       "  0.7578125,\n",
       "  0.900390625,\n",
       "  -0.583984375,\n",
       "  0.763671875,\n",
       "  -1.0,\n",
       "  0.254150390625],\n",
       " [-0.603515625,\n",
       "  -0.1357421875,\n",
       "  -0.8779296875,\n",
       "  0.288330078125,\n",
       "  0.828125,\n",
       "  0.9189453125,\n",
       "  -0.4482421875,\n",
       "  0.85888671875,\n",
       "  -0.5966796875,\n",
       "  -0.73046875]]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a 2D array of the final_res.. not dataframe but 2D array\n",
    "confusion_mat =[[final_res[lang][word] for lang in (lang_script_list)] for word in (ambiguos_words) if word!='child' ]\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file named \"logits_confusion_matrix.txt\", put heading as the languages used. next line all ambiguos words, next lines the confusion matrix\n",
    "with open('logits_confusion_matrix.txt', 'a') as f:\n",
    "    f.write(\"Sample size: \"+str(SAMPLE_SIZE))\n",
    "    f.write('\\n')\n",
    "    f.write(','.join(lang_script_list))\n",
    "    f.write('\\n')\n",
    "    f.write(','.join(ambiguos_words))\n",
    "    f.write('\\n')\n",
    "    for row in confusion_mat:\n",
    "        f.write(','.join([str(elem) for elem in row]))\n",
    "        f.write('\\n')\n",
    "    f.write('\\n\\n')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_711292/3520349198.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + list(final_res['ory_Orya'].keys()))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a confusion matrix plot from matplotlib of the final_res. rows are langs, columns are words and values are differences ranging from -1 to 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.bwr  # Base colormap: Blue-White-Red\n",
    "cmap.set_bad(color='black')  # Map NaN values to black\n",
    "# give colour custommed as max value as Pink and min value as blue and 0 as white\n",
    "cax = ax.matshow(confusion_mat, cmap=cmap)\n",
    "# fig.colorbar(cax)\n",
    "# Create the plot\n",
    "cax = ax.matshow(confusion_mat, cmap=cmap,)# norm=Normalize(vmin=-1, vmax=1))\n",
    "\n",
    "# Annotate values in the matrix\n",
    "# rows, cols = confusion_mat.shape\n",
    "rows = len(confusion_mat)\n",
    "cols = len(confusion_mat[0])\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        value = confusion_mat[i][j]\n",
    "        if not np.isnan(value):  # Skip NaN values\n",
    "            ax.text(j, i, f'{value:.2f}'.lstrip('0'), ha='center', va='center', fontsize=8, color = 'black')\n",
    "\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax)\n",
    "\n",
    "# Customize colorbar tick labels\n",
    "cbar.set_ticks([-1, 0, 1])  # Set ticks at min, mid, and max\n",
    "# cbar.set_ticklabels([\"Patriarchy\", \"Neutral\", \"Matriarchy\"]) \n",
    "cbar.ax.text(-0.03, -0.03, \"Patriarchy\", ha=\"center\", va=\"center\", fontsize=10,   transform=cbar.ax.transAxes)\n",
    "cbar.ax.text(0.06, 1.03, \"Matriarchy\", ha=\"center\", va=\"center\", fontsize=10,   transform=cbar.ax.transAxes)\n",
    " \n",
    "ax.set_xticks(range(len(final_res.keys()))) \n",
    "ax.set_xticklabels( list(lang_code_map[lang] for lang in final_res.keys()),  ha=\"center\")\n",
    "ax.set_yticklabels([''] + list(final_res['ory_Orya'].keys()))\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Words')\n",
    "plt.title('Difference in Logits for Matriarchal and Patriarchal relations')\n",
    "# save the image to a file\n",
    "# Add a small black box legend below the plot\n",
    "black_patch = mpatches.Patch(color='black', label='Language exhibits single-gender bias.')\n",
    "plt.legend(handles=[black_patch], loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=1, fontsize=10, frameon=False)\n",
    "\n",
    "fig.savefig('results/logit_prob_diff_'+str(SAMPLE_SIZE)+'num.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a confusion matrix plot from matplotlib of the final_res. rows are langs, columns are words and values are differences ranging from -1 to 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cmap = plt.cm.bwr  # Base colormap: Blue-White-Red\n",
    "cmap.set_bad(color='black')  # Map NaN values to black\n",
    "# give colour custommed as max value as Pink and min value as blue and 0 as white\n",
    "cax = ax.matshow(confusion_mat, cmap=cmap)\n",
    "# fig.colorbar(cax)\n",
    "# Create the plot\n",
    "# cax = ax.matshow(confusion_mat, cmap=cmap,)# norm=Normalize(vmin=-1, vmax=1))\n",
    "\n",
    "# Add colorbar\n",
    "cbar = fig.colorbar(cax)\n",
    "\n",
    "# Customize colorbar tick labels\n",
    "cbar.set_ticks([-1, 0, 1])  # Set ticks at min, mid, and max\n",
    "# cbar.set_ticklabels([\"Patriarchy\", \"Neutral\", \"Matriarchy\"]) \n",
    "cbar.ax.text(-0.03, -0.03, \"Patriarchy\", ha=\"center\", va=\"center\", fontsize=10,   transform=cbar.ax.transAxes)\n",
    "cbar.ax.text(0.06, 1.03, \"Matriarchy\", ha=\"center\", va=\"center\", fontsize=10,   transform=cbar.ax.transAxes)\n",
    " \n",
    "ax.set_xticks(range(len(final_res.keys()))) \n",
    "ax.set_xticklabels( list(lang_code_map[lang] for lang in final_res.keys()),  ha=\"center\")\n",
    "ax.set_yticklabels([''] + list(final_res['ory_Orya'].keys()))\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Words')\n",
    "plt.title('Difference in Logits for Matriarchal and Patriarchal relations')\n",
    "# save the image to a file\n",
    "# Add a small black box legend below the plot\n",
    "black_patch = mpatches.Patch(color='black', label='Language exhibits single-gender bias.')\n",
    "plt.legend(handles=[black_patch], loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=1, fontsize=10, frameon=False)\n",
    "\n",
    "fig.savefig('results/logit_prob_diff_'+str(SAMPLE_SIZE)+'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of ['ମାମୁଁ', 'ମଉସା'] in vocab of en_indic_tokenizer\n",
    "# print(en_indic_tokenizer.convert_tokens_to_ids(['ମାମୁଁ', 'ମଉସା'])) #[3, 3] - wrong\n",
    "\n",
    "# print(en_indic_tokenizer.vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the test_sentences_eng.txt file data as sents\n",
    "\n",
    "# # sents = ['The river is blue.', 'My uncle wearing blue coat.', 'My maternal aunt went to the river bank.', \"The doctor went to bank for money.\"]\n",
    "# sents=['My maternal aunt went to the river bank.', 'My maternal aunt loves me.', \n",
    "#        'My maternal aunt loves her grandchildren.', \"My maternal aunt loves her children.\", \n",
    "#        \"My maternal aunt loves her family.\",\n",
    "#        ]   \n",
    "# src_lang = \"eng_Latn\"\n",
    "\n",
    "# tgt_lang = 'hin_Deva'\n",
    "# # print(lang)\n",
    "# translations, logits = batch_translate(sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip_en_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ನನ್ನ ಅಜ್ಜಿ ಬ್ರಾಹ್ಮಣರು. ', 'ನನ್ನ ಅಜ್ಜ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ. ', 'ನನ್ನ ಚಿಕ್ಕಪ್ಪ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ. ', 'ನನ್ನ ಚಿಕ್ಕಮ್ಮ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣೆ. ', 'ನನ್ನ ಅಳಿಯ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ. ', 'ನನ್ನ ಅತ್ತಿಗೆ ಬ್ರಾಹ್ಮಣಳು. ', 'ನನ್ನ ಸೋದರಸಂಬಂಧಿ ಒಬ್ಬ ಬ್ರಾಹ್ಮಣ. ', 'ನನ್ನ ಸೋದರಳಿಯ ಬ್ರಾಹ್ಮಣನಾಗಿದ್ದಾನೆ. ', 'ನನ್ನ ಸೋದರ ಸೊಸೆ ಬ್ರಾಹ್ಮಣಳು. ', 'ನನ್ನ ಅಜ್ಜಿ ಒಬ್ಬ ಕ್ಷತ್ರಿಯ. ']\n"
     ]
    }
   ],
   "source": [
    "# print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8970, -0.8960, -1.3037,  ..., -0.8960, -0.8965, -0.8965],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify for Odia that logits at correct positions have been extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3.5763e-07, 3.5763e-07, 5.9605e-08,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16), tensor([4.1723e-07, 4.1723e-07, 1.1921e-07,  ..., 4.1723e-07, 4.1723e-07,\n",
      "        4.1723e-07], dtype=torch.float16), tensor([9.5367e-07, 9.5367e-07, 6.5565e-07,  ..., 9.5367e-07, 9.5367e-07,\n",
      "        9.5367e-07], dtype=torch.float16), tensor([1.0133e-06, 1.0133e-06, 4.1723e-07,  ..., 1.0133e-06, 1.0133e-06,\n",
      "        1.0133e-06], dtype=torch.float16), tensor([5.3644e-07, 5.3644e-07, 1.1921e-07,  ..., 5.3644e-07, 5.3644e-07,\n",
      "        5.3644e-07], dtype=torch.float16), tensor([7.1526e-07, 7.1526e-07, 2.3842e-07,  ..., 7.1526e-07, 7.1526e-07,\n",
      "        7.1526e-07], dtype=torch.float16), tensor([1.0133e-06, 1.0133e-06, 2.9802e-07,  ..., 1.0133e-06, 1.0133e-06,\n",
      "        1.0133e-06], dtype=torch.float16), tensor([3.5763e-07, 3.5763e-07, 1.7881e-07,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16), tensor([9.5367e-07, 9.5367e-07, 2.3842e-07,  ..., 9.5367e-07, 9.5367e-07,\n",
      "        9.5367e-07], dtype=torch.float16), tensor([3.5763e-07, 3.5763e-07, 5.9605e-08,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16)]\n",
      "10\n",
      "torch.Size([122672])\n"
     ]
    }
   ],
   "source": [
    "# for each logit in logits, convert it to prob using softmax\n",
    "for lang in lang_script_list:\n",
    "    if lang != 'ory_Orya':\n",
    "        continue\n",
    "    logits = output_logits[lang]\n",
    "    softmax_logits = [softmax(logit, dim=-1) for logit in logits]\n",
    "    print(softmax_logits)\n",
    "    print(len(softmax_logits) ) # for each sentence translated)\n",
    "    print(softmax_logits[0].shape) # for each word in the sentence; vocab size\n",
    "\n",
    "# for each sentence, amongs all vocab logits, find the difference of [sum of matrirach words] - [sum of patriarch words]\n",
    "# find the root word in english and as per lang, find the other Matriarch or Patriarch words based on relation code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(41445), tensor(41445), tensor(9971), tensor(30261), tensor(5442), tensor(4569), tensor(60824), tensor(4300), tensor(980), tensor(41445)]\n"
     ]
    }
   ],
   "source": [
    "# get the index of max prob for each logit\n",
    "max_prob_index = [torch.argmax(softmax_logit, dim=-1) for softmax_logit in softmax_logits]\n",
    "print(max_prob_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.return_types.topk(\n",
      "values=tensor([0.8823, 0.0048, 0.0035, 0.0031, 0.0028, 0.0021, 0.0021, 0.0016, 0.0016,\n",
      "        0.0014], dtype=torch.float16),\n",
      "indices=tensor([41445,    80,    30,  8911, 51174, 29498, 33622, 48446, 30261, 30502])), torch.return_types.topk(\n",
      "values=tensor([0.8306, 0.0312, 0.0203, 0.0101, 0.0087, 0.0076, 0.0056, 0.0024, 0.0017,\n",
      "        0.0010], dtype=torch.float16),\n",
      "indices=tensor([41445, 53208, 15588, 20077, 30502,    30,   409,  1111, 55513, 51174])), torch.return_types.topk(\n",
      "values=tensor([0.5093, 0.1919, 0.0316, 0.0116, 0.0104, 0.0051, 0.0042, 0.0039, 0.0035,\n",
      "        0.0035], dtype=torch.float16),\n",
      "indices=tensor([ 9971, 41565, 24501,    30, 41445,  7610, 20077,  3991,  3617, 15588])), torch.return_types.topk(\n",
      "values=tensor([0.6060, 0.0270, 0.0156, 0.0095, 0.0076, 0.0057, 0.0052, 0.0051, 0.0051,\n",
      "        0.0049], dtype=torch.float16),\n",
      "indices=tensor([30261, 41445,  9971,    30,  3617,   213, 54203,   336, 58401,  1390])), torch.return_types.topk(\n",
      "values=tensor([0.6250, 0.0746, 0.0439, 0.0277, 0.0132, 0.0132, 0.0124, 0.0089, 0.0055,\n",
      "        0.0045], dtype=torch.float16),\n",
      "indices=tensor([ 5442, 21405,  4569, 45883,   980,   649,  1390,  1872,  3991, 47727])), torch.return_types.topk(\n",
      "values=tensor([0.2969, 0.2172, 0.0637, 0.0562, 0.0255, 0.0233, 0.0202, 0.0194, 0.0112,\n",
      "        0.0105], dtype=torch.float16),\n",
      "indices=tensor([ 4569,  5442, 21405,  1390, 38982,  2398, 45883,   649,   980,  3175])), torch.return_types.topk(\n",
      "values=tensor([0.5723, 0.0255, 0.0235, 0.0147, 0.0088, 0.0082, 0.0079, 0.0065, 0.0049,\n",
      "        0.0049], dtype=torch.float16),\n",
      "indices=tensor([60824,  3991,  9971, 56796,  6091, 38982,  4725,  1111, 21058,   110])), torch.return_types.topk(\n",
      "values=tensor([0.6226, 0.2020, 0.0210, 0.0135, 0.0099, 0.0072, 0.0047, 0.0047, 0.0032,\n",
      "        0.0029], dtype=torch.float16),\n",
      "indices=tensor([ 4300, 30360,   980,  3991,    30,  1013, 21058,  4569,  9919, 60824])), torch.return_types.topk(\n",
      "values=tensor([0.4546, 0.1158, 0.0446, 0.0203, 0.0179, 0.0153, 0.0098, 0.0091, 0.0066,\n",
      "        0.0056], dtype=torch.float16),\n",
      "indices=tensor([  980, 30360,  4300,  2398,  4569, 38982, 13818,  3991,  1390,  4725])), torch.return_types.topk(\n",
      "values=tensor([0.8975, 0.0045, 0.0034, 0.0028, 0.0023, 0.0020, 0.0015, 0.0014, 0.0014,\n",
      "        0.0013], dtype=torch.float16),\n",
      "indices=tensor([41445,    80,  8911,    30, 29498, 51174, 48446, 33622,  1828,  2214]))]\n"
     ]
    }
   ],
   "source": [
    "# from the softmax_logits, get the indices of top 10 max prob \n",
    "top_10_indices = [torch.topk(softmax_logit, k=10, dim=-1) for softmax_logit in softmax_logits]\n",
    "print(top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['जेजे ', 'न ', \"' \", 'नानी ', 'नाति ', 'दादी ', 'माआ ', 'दिदि ', 'माउ ', 'पिताम '], ['जेजे ', 'पितामह ', 'दादा ', 'बापा ', 'पिताम ', \"' \", 'द ', 'बड़ ', 'बापाङ्क ', 'नाति '], ['माम ', 'काका ', 'मामा ', \"' \", 'जेजे ', 'काक ', 'बापा ', 'भाइ ', 'खु ', 'दादा '], ['माउ ', 'जेजे ', 'माम ', \"' \", 'खु ', 'अ ', 'माङ्क ', 'ब ', 'कुनि ', 'बो '], ['भि ', 'श् ', 'भा ', 'ज् ', 'भ ', 'श ', 'बो ', 'सा ', 'भाइ ', 'भाइर '], ['भा ', 'भि ', 'श् ', 'बो ', 'भउणी ', 'झ ', 'ज् ', 'श ', 'भ ', 'शा '], ['सम्पर्कीय़ ', 'भाइ ', 'माम ', 'भ्रातृ ', 'सम्प ', 'भउणी ', 'जणे ', 'बड़ ', 'भ्र ', 'क '], ['पुत ', 'भण ', 'भ ', 'भाइ ', \"' \", 'पु ', 'भ्र ', 'भा ', 'सान ', 'सम्पर्कीय़ '], ['भ ', 'भण ', 'पुत ', 'झ ', 'भा ', 'भउणी ', 'भग ', 'भाइ ', 'बो ', 'जणे '], ['जेजे ', 'न ', 'नानी ', \"' \", 'दादी ', 'नाति ', 'दिदि ', 'माआ ', 'आइ ', 'मात ']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sofia/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from the top_10_indices, get the words in Hindi vocab using tokenizer.target_tokenizer\n",
    "word_list = []\n",
    "for i in top_10_indices:\n",
    "    with en_indic_tokenizer.as_target_tokenizer():\n",
    "        word_list.append(en_indic_tokenizer.batch_decode(i.indices))\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जेजे ', 'न ', \"' \", 'नानी ', 'नाति ', 'दादी ', 'माआ ', 'दिदि ', 'माउ ', 'पिताम ']\n",
      "['जेजे ', 'पितामह ', 'दादा ', 'बापा ', 'पिताम ', \"' \", 'द ', 'बड़ ', 'बापाङ्क ', 'नाति ']\n",
      "['माम ', 'काका ', 'मामा ', \"' \", 'जेजे ', 'काक ', 'बापा ', 'भाइ ', 'खु ', 'दादा ']\n",
      "['माउ ', 'जेजे ', 'माम ', \"' \", 'खु ', 'अ ', 'माङ्क ', 'ब ', 'कुनि ', 'बो ']\n",
      "['भि ', 'श् ', 'भा ', 'ज् ', 'भ ', 'श ', 'बो ', 'सा ', 'भाइ ', 'भाइर ']\n",
      "['भा ', 'भि ', 'श् ', 'बो ', 'भउणी ', 'झ ', 'ज् ', 'श ', 'भ ', 'शा ']\n",
      "['सम्पर्कीय़ ', 'भाइ ', 'माम ', 'भ्रातृ ', 'सम्प ', 'भउणी ', 'जणे ', 'बड़ ', 'भ्र ', 'क ']\n",
      "['पुत ', 'भण ', 'भ ', 'भाइ ', \"' \", 'पु ', 'भ्र ', 'भा ', 'सान ', 'सम्पर्कीय़ ']\n",
      "['भ ', 'भण ', 'पुत ', 'झ ', 'भा ', 'भउणी ', 'भग ', 'भाइ ', 'बो ', 'जणे ']\n",
      "['जेजे ', 'न ', 'नानी ', \"' \", 'दादी ', 'नाति ', 'दिदि ', 'माआ ', 'आइ ', 'मात ']\n"
     ]
    }
   ],
   "source": [
    "for _ in word_list:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "Found logits for ambiguos english words just before translating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
