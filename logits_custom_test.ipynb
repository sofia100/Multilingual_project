{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3,5,7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES= 3,5,7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/home/sofia/cache_custom'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndicTrans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4 # edited from 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization = None\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import possible_indic_relations as poss_indic_rel\n",
    "import span_encodings as sp_enc\n",
    "# Reload the module to reflect changes\n",
    "importlib.reload(poss_indic_rel)\n",
    "importlib.reload(sp_enc)\n",
    "\n",
    "pir= poss_indic_rel.possible_relations\n",
    "pir\n",
    "\n",
    "ambiguos_words = list(pir.keys())\n",
    "span_encodings = sp_enc.span_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ଜେଜେମା'\": [41445, 241, 30],\n",
       " 'ଜେଜେବାପା ': [41445, 1007, 1714],\n",
       " 'ମାମୁଁ। ': [9971, 19212, 6],\n",
       " 'ମାଉସୀ। ': [30261, 694, 6],\n",
       " 'ଶ୍ୱଶୁର-ଶ୍ୱଶୁର ': [21405, 699, 22252, 13, 21405, 699, 22252],\n",
       " 'ଶ୍ୱଶୁର। ': [21405, 699, 22252, 6],\n",
       " 'ସମ୍ପର୍କୀଯ଼ ଭାଇ। ': [60824, 3991, 6],\n",
       " 'ଶିଶୁ ': [3442],\n",
       " 'ପୁତୁରା ': [4300, 5686],\n",
       " 'ଭାଣିଜୀ ': [980, 9742, 795],\n",
       " 'None': [2],\n",
       " 'ଜେଜେମା': [41445, 241],\n",
       " 'ଆଈ': [740],\n",
       " 'ଜେଜେବାପା': [41445, 1007, 1714],\n",
       " 'ଅଜା': [62200],\n",
       " 'ବଡ଼ବାପା': [1111, 1007, 1714],\n",
       " 'ଦାଦା': [15588],\n",
       " 'ମାମୁଁ': [9971, 19212],\n",
       " 'ପିଉସା': [52157, 964],\n",
       " 'ମଉସା': [63293, 964],\n",
       " 'ପିଉସୀ': [52157, 694],\n",
       " 'ମାଉସୀ': [30261, 694],\n",
       " 'ମାଇଁ': [10859, 2304],\n",
       " 'ବଡ଼ମାଆ': [1111, 241, 1109],\n",
       " 'ଖୁଡ଼ି': [3617, 4405],\n",
       " 'ବଡ଼ ଶଳା': [1111, 649, 1624],\n",
       " 'ଶଳା': [649, 1624],\n",
       " 'ଭିଣେଇ': [5442, 53872],\n",
       " 'ଭିଣୋଇ': [5442, 1754, 89],\n",
       " 'ଦେଢ଼ଶୁର': [57, 10861, 22252],\n",
       " 'ଦିଅର': [305, 4093],\n",
       " 'ବଡ଼ ନଣନ୍ଦ': [1111, 80, 266, 5766],\n",
       " 'ନଣନ୍ଦ': [80, 266, 5766],\n",
       " 'ଭାଉଜ': [4569, 25547],\n",
       " 'ଭାଇବୋହୁ': [3991, 1137, 7131],\n",
       " 'ଦେଢ଼ଶାସୁ': [57, 10861, 325, 14699],\n",
       " 'ଶାଳୀ': [3175, 2651],\n",
       " 'ଭାଇ': [3991],\n",
       " 'ଦିଦି': [48446],\n",
       " 'ପୁଅ': [23401],\n",
       " 'ଝିଅ': [20076],\n",
       " 'ପିଲା': [23000],\n",
       " 'ପୁତୁରା': [4300, 5686],\n",
       " 'ଭଣଜା': [30360, 2935],\n",
       " 'ଝିଆରୀ': [2398, 80993],\n",
       " 'ଭାଣିଜୀ': [980, 9742, 795]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# span_encodings['ory_Orya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer(ckpt_dir, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ckpt_dir, trust_remote_code=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir,  quantization)\n",
    "\n",
    "ip_en_ind = IndicProcessor(inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def resolve_logits_for_best_beam(outputs, num_beams):\n",
    "    \"\"\" Resolve the logits from the best beam, using model output from a generate call.\n",
    "        For a shape [tokens?, batch_size*num_beams, vocab], returns [tokens?, batch_size, vocab]\n",
    "\n",
    "        Assumes num_return_sequences=1.\"\"\"\n",
    "\n",
    "    # print(\"length of output beam\", len(outputs.beam_indices))\n",
    "    # print(\"shape of beam_indices\", outputs.beam_indices.shape)\n",
    "    # print(\"shape of logits\", (outputs.logits[0].shape))\n",
    "    # print(\"length of logits\", len(outputs.logits))\n",
    "    # print(\"length od outputs\", len(outputs))\n",
    "    best_logits  = []\n",
    "    beam_indices = [ outputs.beam_indices[:,i].tolist() for i in range(len(outputs.logits)-1) ]\n",
    "    # print(\"length of beam_indices\", len(beam_indices))\n",
    "\n",
    "    for beam_index, logits in zip(beam_indices, outputs.logits):\n",
    "        beam_index = [ idx if idx != -1 else ((num_beams*(i+1))-1) for i, idx in enumerate(beam_index) ]\n",
    "        best_logits.append(logits[beam_index,:])\n",
    "\n",
    "    return best_logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_logits_for_span(logits, translations, tokenizer, search_spans, span_encodings, lang):\n",
    "    \"\"\" Given search spans, returns the logits before the span was generated.\n",
    "\n",
    "    Args:\n",
    "        logits (tuple[Tensor]): Tuple of tensors, of shape [tokens?, batch_size, vocab]\n",
    "        sequences (tuple[list[int]]): Tokenized output sequences.\n",
    "        tokenizer (PreTrainedTokenizerBase): Tokenizer for the model.\n",
    "        search_spans (list[str]): batch_size spans to search for. Must be present in the generated sequences.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Tensor of shape [batch_size, vocab] indicating the logits before the span for each batch element.\n",
    "    \"\"\"\n",
    "    if isinstance(search_spans, str):\n",
    "        search_spans = [ search_spans ] * len(translations)\n",
    "\n",
    "    # with tokenizer.as_target_tokenizer():   \n",
    "    #     detok_outputs = tokenizer.batch_decode(translations, skip_special_tokens=True)\n",
    "\n",
    "    # positions = [ output.index(span) for output, span in zip(translations, search_spans) ]\n",
    "    logit_pos = [  ]\n",
    "\n",
    "    for seq,  span,  in zip(translations,  search_spans): \n",
    "        # print(\"Span to search for:\", span, span_encodings[lang])\n",
    "        key = next((k for k in span_encodings[lang].keys() if span in k), \"None\")\n",
    "        subtokens = span_encodings[lang][key]\n",
    "        # print(\"subtokens\", subtokens)\n",
    "        # print(\"for span:\", span, \"subtokens\", subtokens)\n",
    "        # print(\"seq\", seq)\n",
    "        idx = 0\n",
    "        while idx < len(seq)-1:\n",
    "            if any(seq[idx+i] == tok for i, tok in enumerate(subtokens)): \n",
    "                # print( \"found\", idx)\n",
    "                break\n",
    "            idx += 1\n",
    "        logit_pos.append(idx-1)\n",
    "    \n",
    "    # print(\"logit_pos\", logit_pos)\n",
    "    # print(\"Dimensions of logits\", logits[0].shape, len(logits))\n",
    "\n",
    "    selected_logits = []\n",
    "    # Iterate over each batch and corresponding token position\n",
    "    for batch, token in enumerate(logit_pos):\n",
    "        # print(\"batch, token\", batch, token)\n",
    "        # print(\"len(logits)\", len(logits))\n",
    "        # print(\"Shape of logits\", logits[0].shape)\n",
    "        # # print(\"logits token\", logits[token])\n",
    "        # print(\"logits 1st item 1st row\",logits[0][0])\n",
    "        # Extract logits for the specific token position in the current batch\n",
    "        current_logit = logits[token][batch, :]\n",
    "        # current_logit = logits[token][0]\n",
    "        \n",
    "        # Append the selected logit to the list\n",
    "        selected_logits.append(current_logit)\n",
    "\n",
    "    # Stack the list of selected logits into a tensor\n",
    "    selected_logits = torch.stack(selected_logits)\n",
    "\n",
    "    return selected_logits\n",
    "        \n",
    "    # return selected_logits\n",
    "    # return torch.stack([ logits[token][batch,:] for batch, token in enumerate(logit_pos) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_spans(inp_sents, tgt_lang, translations):\n",
    "    search_spans= []\n",
    "    root_amb_words=[]\n",
    "    # print(\"inp_sents\", inp_sents)\n",
    "    for idx, inp in enumerate(inp_sents):\n",
    "        # check which word from ambiguos_Wwords in present in the input sentence\n",
    "        for word in ambiguos_words:\n",
    "            if word in inp:\n",
    "                curr_amb_word= word\n",
    "        root_amb_words.append(curr_amb_word)\n",
    "\n",
    "        # get the possible relations for the current ambiguous word\n",
    "        possible_relations= pir[curr_amb_word][tgt_lang].keys()\n",
    "        # print(\"Possible relations for the word\", curr_amb_word, \"in\", tgt_lang, \"are\", possible_relations)\n",
    "\n",
    "        # find the word in the translation from the possible relations. if not found print the translation\n",
    "        for rel in possible_relations:\n",
    "            if rel in translations[idx]:\n",
    "                # print(\"Relation found in the translation for the word\", curr_amb_word, \"in\", tgt_lang, \"in the sentence\", translations[idx], \"at \", translations[idx].index(rel), \"\\nso sentece is\", translations[idx][translations[idx].index(rel):])\n",
    "                search_spans.append(rel)\n",
    "                break\n",
    "        else:\n",
    "            # print(\"No relation found in the translation for the word\", curr_amb_word, \"in\", tgt_lang, \"in the sentence\", translations[idx])\n",
    "            search_spans.append(translations[idx][0])\n",
    "    # print(\"Search spans are\", search_spans)\n",
    "    return root_amb_words, search_spans\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip, span_encodings):\n",
    "    translations = []\n",
    "    start_logits = []\n",
    "    root_amb_words = []\n",
    "    searched_spans = []\n",
    "    for i in tqdm(range(0, len(input_sentences), BATCH_SIZE)):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            # generated_tokens = model.generate(\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1, # TODO temp\n",
    "                output_scores=True,\n",
    "                output_logits=True,\n",
    "                return_dict_in_generate=True,\n",
    "\n",
    "            )\n",
    "            # print(\"Length of outputs.logits actual\", len(outputs.logits))\n",
    "            # print(\"Shape of outputs.logits actual\", outputs.logits[0].shape)\n",
    "\n",
    "            # print(\"Length of outputs.beam_indices actual\", len(outputs.beam_indices))\n",
    "            # print(\"Shape of outputs.beam_indices actual\", outputs.beam_indices.shape)\n",
    "            \n",
    "            outputs.beam_indices = outputs.beam_indices.cpu()\n",
    "            outputs.logits = tuple(logits.cpu() for logits in outputs.logits)               \n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = outputs.sequences\n",
    "        # print(\"len generated_tokens: \", (generated_tokens[0]).shape)\n",
    "        # print(\"1st generated token: \", generated_tokens[0])\n",
    "        vector = generated_tokens.detach().cpu().tolist()\n",
    "        # print(\"length of outputs vectors: \", len(vector), len(vector[0]))\n",
    "        # print(\"vector of generated_tokens: \", vector)\n",
    "        # print(\"1st vector: \", vector[0])\n",
    "\n",
    "\n",
    "\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            decoded_op = tokenizer.batch_decode(\n",
    "                vector,\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "\n",
    "        # print(\"1st decoded_op: \", decoded_op[0])\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        transl = ip.postprocess_batch(decoded_op, lang=tgt_lang)\n",
    "\n",
    "        # print(\"translations: \", transl)\n",
    "        \n",
    "\n",
    "        root_words, search_spans = get_search_spans(batch,  tgt_lang, transl)\n",
    "        searched_spans += search_spans\n",
    "        root_amb_words += root_words\n",
    "        # print(\"length search_spans: \", len(search_spans))\n",
    "        best_logits = resolve_logits_for_best_beam(outputs, num_beams=5)\n",
    "        # print(\"length best_logits: \",len(best_logits))\n",
    "        # print(\"length of best_logits: \", len(best_logits), (best_logits[0]).shape)\n",
    "\n",
    "        start_logits += get_logits_for_span(best_logits, outputs.sequences, tokenizer, search_spans, span_encodings, tgt_lang)\n",
    "        # start_logits += get_logits_for_span(best_logits, translations, tokenizer, search_spans)\n",
    "        translations += transl\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations, start_logits, root_amb_words, searched_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_script_list = [\n",
    "                           'ory_Orya',\n",
    "                     'pan_Guru', 'ben_Beng', \n",
    "                       'mal_Mlym',\n",
    "                          #  'mar_Deva', \n",
    "                           'tam_Taml', \n",
    "                          #  'guj_Gujr', \n",
    "                          #  'tel_Telu',\n",
    "                            #  'hin_Deva', \n",
    "                          #  'kan_Knda', \n",
    "                           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_folder = 'custom_test_csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code_map = {\n",
    "    'eng_Latn': 'en',\n",
    "    'hin_Deva': 'hi',\n",
    "    'guj_Gujr': 'gu',\n",
    "    'kan_Knda': 'kn',\n",
    "    'mal_Mlym': 'ml',\n",
    "    'mar_Deva': 'mr',\n",
    "    'tam_Taml': 'ta',\n",
    "    'tel_Telu': 'te',\n",
    "    'pan_Guru': 'pa',\n",
    "    'ben_Beng': 'bn',\n",
    "    'ory_Orya': 'or'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809\n"
     ]
    }
   ],
   "source": [
    "sents = []\n",
    "with open('test_sentences_eng.txt', 'r') as f:\n",
    "    sents = f.readlines()\n",
    "sents = [sent.strip() for sent in sents if sent.find('child')==-1]\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My grandmother is a Brahmin.',\n",
       " 'My grandfather is a Brahmin.',\n",
       " 'My uncle is a Brahmin.',\n",
       " 'My aunt is a Brahmin.',\n",
       " 'My brother-in-law is a Brahmin.',\n",
       " 'My sister-in-law is a Brahmin.',\n",
       " 'My cousin is a Brahmin.',\n",
       " 'My nephew is a Brahmin.',\n",
       " 'My niece is a Brahmin.',\n",
       " 'My grandmother is a Kshatriya.']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SIZE = 10\n",
    "sents = sents[:SAMPLE_SIZE]\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ory_Orya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pan_Guru\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ben_Beng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mal_Mlym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tam_Taml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "src_lang = \"eng_Latn\"\n",
    "output_trnsl={}\n",
    "output_logits={}\n",
    "\n",
    "for lang in lang_script_list:\n",
    "    tgt_lang = lang\n",
    "    print(lang)\n",
    "    # if tgt_lang != 'ory_Orya':\n",
    "    #     continue\n",
    "    translations, logits, root_amb_words, searched_spans = batch_translate(sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip_en_ind, span_encodings)\n",
    "    output_trnsl[lang] = translations\n",
    "    output_logits[lang] = logits\n",
    "\n",
    "    # # save hindi translations to a file test_translations_hin.txt\n",
    "    # with open('test_translations/indic_trans2/test_transl_it2_'+lang+'.txt', 'w') as f:\n",
    "    #     for sent in translations:\n",
    "    #         f.write(sent + '\\n')\n",
    "\n",
    "    # save the logits to a file \n",
    "    # with open('test_trasnlations/indic_trans2/test_transl_it2_'+lang+'_logits.txt', 'w') as f:\n",
    "    #     for logit in logits:\n",
    "    #         f.write(str(logit) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>root_ambiguous_words</th>\n",
       "      <th>searched_spans_ory_Orya</th>\n",
       "      <th>transl_or</th>\n",
       "      <th>logits_or</th>\n",
       "      <th>searched_spans_pan_Guru</th>\n",
       "      <th>transl_pa</th>\n",
       "      <th>logits_pa</th>\n",
       "      <th>searched_spans_ben_Beng</th>\n",
       "      <th>transl_bn</th>\n",
       "      <th>logits_bn</th>\n",
       "      <th>searched_spans_mal_Mlym</th>\n",
       "      <th>transl_ml</th>\n",
       "      <th>logits_ml</th>\n",
       "      <th>searched_spans_tam_Taml</th>\n",
       "      <th>transl_ta</th>\n",
       "      <th>logits_ta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My grandmother is a Brahmin.</td>\n",
       "      <td>grandmother</td>\n",
       "      <td>பாட்டி</td>\n",
       "      <td>ମୋ ଜେଜେମା ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5381, dtype=torch.float16), tensor(...</td>\n",
       "      <td>பாட்டி</td>\n",
       "      <td>ਮੇਰੀ ਦਾਦੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>[tensor(-1.1885, dtype=torch.float16), tensor(...</td>\n",
       "      <td>பாட்டி</td>\n",
       "      <td>আমার ঠাকুমা একজন ব্রাহ্মণ।</td>\n",
       "      <td>[tensor(-1.1504, dtype=torch.float16), tensor(...</td>\n",
       "      <td>பாட்டி</td>\n",
       "      <td>എൻ്റെ മുത്തശ്ശി ഒരു ബ്രാഹ്മണയാണ്.</td>\n",
       "      <td>[tensor(-0.0732, dtype=torch.float16), tensor(...</td>\n",
       "      <td>பாட்டி</td>\n",
       "      <td>என் பாட்டி ஒரு பிராமணர்.</td>\n",
       "      <td>[tensor(-0.7446, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My grandfather is a Brahmin.</td>\n",
       "      <td>grandfather</td>\n",
       "      <td>தாத்தா</td>\n",
       "      <td>ମୋ ଜେଜେବାପା ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.3369, dtype=torch.float16), tensor(...</td>\n",
       "      <td>தாத்தா</td>\n",
       "      <td>ਮੇਰੇ ਦਾਦਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।</td>\n",
       "      <td>[tensor(-0.7490, dtype=torch.float16), tensor(...</td>\n",
       "      <td>தாத்தா</td>\n",
       "      <td>আমার দাদু একজন ব্রাহ্মণ।</td>\n",
       "      <td>[tensor(-1.3174, dtype=torch.float16), tensor(...</td>\n",
       "      <td>தாத்தா</td>\n",
       "      <td>എന്റെ മുത്തച്ഛൻ ഒരു ബ്രാഹ്മണനാണ്.</td>\n",
       "      <td>[tensor(-0.6470, dtype=torch.float16), tensor(...</td>\n",
       "      <td>தாத்தா</td>\n",
       "      <td>என் தாத்தா ஒரு பிராமணர்.</td>\n",
       "      <td>[tensor(-0.5171, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My uncle is a Brahmin.</td>\n",
       "      <td>uncle</td>\n",
       "      <td>மாமா</td>\n",
       "      <td>ମୋ ମାମୁଁ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5029, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மாமா</td>\n",
       "      <td>ਮੇਰੇ ਚਾਚਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।</td>\n",
       "      <td>[tensor(-1.4482, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மாமா</td>\n",
       "      <td>আমার কাকা একজন ব্রাহ্মণ।</td>\n",
       "      <td>[tensor(-1.3193, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மாமா</td>\n",
       "      <td>എന്റെ അമ്മാവൻ ഒരു ബ്രാഹ്മണനാണ്.</td>\n",
       "      <td>[tensor(-0.9233, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மாமா</td>\n",
       "      <td>என் மாமா ஒரு பிராமணர்.</td>\n",
       "      <td>[tensor(-0.9399, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My aunt is a Brahmin.</td>\n",
       "      <td>aunt</td>\n",
       "      <td>அத்தை</td>\n",
       "      <td>ମୋ ମାଉସୀ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.9922, dtype=torch.float16), tensor(...</td>\n",
       "      <td>அத்தை</td>\n",
       "      <td>ਮੇਰੀ ਮਾਸੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>[tensor(-1.9619, dtype=torch.float16), tensor(...</td>\n",
       "      <td>அத்தை</td>\n",
       "      <td>আমার মাসি একজন ব্রাহ্মণ।</td>\n",
       "      <td>[tensor(-1.2168, dtype=torch.float16), tensor(...</td>\n",
       "      <td>அத்தை</td>\n",
       "      <td>എൻ്റെ അമ്മായി ഒരു ബ്രാഹ്മണയാണ്.</td>\n",
       "      <td>[tensor(-0.4893, dtype=torch.float16), tensor(...</td>\n",
       "      <td>அத்தை</td>\n",
       "      <td>என் அத்தை ஒரு பிராமணர்.</td>\n",
       "      <td>[tensor(-1.0879, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My brother-in-law is a Brahmin.</td>\n",
       "      <td>brother-in-law</td>\n",
       "      <td>மைத்துனர்</td>\n",
       "      <td>ମୋ ଭିଣୋଇ ଜଣେ ବ୍ରାହ୍ମଣ।</td>\n",
       "      <td>[tensor(-1.5986, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மைத்துனர்</td>\n",
       "      <td>ਮੇਰਾ ਜੀਜਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।</td>\n",
       "      <td>[tensor(-1.5898, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மைத்துனர்</td>\n",
       "      <td>আমার শ্যালক একজন ব্রাহ্মণ।</td>\n",
       "      <td>[tensor(-1.1924, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மைத்துனர்</td>\n",
       "      <td>എൻ്റെ ഭാര്യാസഹോദരൻ ഒരു ബ്രാഹ്മണനാണ്.</td>\n",
       "      <td>[tensor(-0.0292, dtype=torch.float16), tensor(...</td>\n",
       "      <td>மைத்துனர்</td>\n",
       "      <td>என் மைத்துனர் ஒரு பிராமணர்.</td>\n",
       "      <td>[tensor(-0.9644, dtype=torch.float16), tensor(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentences root_ambiguous_words  \\\n",
       "0     My grandmother is a Brahmin.          grandmother   \n",
       "1     My grandfather is a Brahmin.          grandfather   \n",
       "2           My uncle is a Brahmin.                uncle   \n",
       "3            My aunt is a Brahmin.                 aunt   \n",
       "4  My brother-in-law is a Brahmin.       brother-in-law   \n",
       "\n",
       "  searched_spans_ory_Orya                   transl_or  \\\n",
       "0                  பாட்டி    ମୋ ଜେଜେମା ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "1                  தாத்தா  ମୋ ଜେଜେବାପା ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "2                    மாமா     ମୋ ମାମୁଁ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "3                   அத்தை     ମୋ ମାଉସୀ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "4               மைத்துனர்     ମୋ ଭିଣୋଇ ଜଣେ ବ୍ରାହ୍ମଣ।    \n",
       "\n",
       "                                           logits_or searched_spans_pan_Guru  \\\n",
       "0  [tensor(-1.5381, dtype=torch.float16), tensor(...                  பாட்டி   \n",
       "1  [tensor(-1.3369, dtype=torch.float16), tensor(...                  தாத்தா   \n",
       "2  [tensor(-1.5029, dtype=torch.float16), tensor(...                    மாமா   \n",
       "3  [tensor(-1.9922, dtype=torch.float16), tensor(...                   அத்தை   \n",
       "4  [tensor(-1.5986, dtype=torch.float16), tensor(...               மைத்துனர்   \n",
       "\n",
       "                    transl_pa  \\\n",
       "0  ਮੇਰੀ ਦਾਦੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।    \n",
       "1  ਮੇਰੇ ਦਾਦਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।    \n",
       "2  ਮੇਰੇ ਚਾਚਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹਨ।    \n",
       "3  ਮੇਰੀ ਮਾਸੀ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।    \n",
       "4  ਮੇਰਾ ਜੀਜਾ ਇੱਕ ਬ੍ਰਾਹਮਣ ਹੈ।    \n",
       "\n",
       "                                           logits_pa searched_spans_ben_Beng  \\\n",
       "0  [tensor(-1.1885, dtype=torch.float16), tensor(...                  பாட்டி   \n",
       "1  [tensor(-0.7490, dtype=torch.float16), tensor(...                  தாத்தா   \n",
       "2  [tensor(-1.4482, dtype=torch.float16), tensor(...                    மாமா   \n",
       "3  [tensor(-1.9619, dtype=torch.float16), tensor(...                   அத்தை   \n",
       "4  [tensor(-1.5898, dtype=torch.float16), tensor(...               மைத்துனர்   \n",
       "\n",
       "                     transl_bn  \\\n",
       "0  আমার ঠাকুমা একজন ব্রাহ্মণ।    \n",
       "1    আমার দাদু একজন ব্রাহ্মণ।    \n",
       "2    আমার কাকা একজন ব্রাহ্মণ।    \n",
       "3    আমার মাসি একজন ব্রাহ্মণ।    \n",
       "4  আমার শ্যালক একজন ব্রাহ্মণ।    \n",
       "\n",
       "                                           logits_bn searched_spans_mal_Mlym  \\\n",
       "0  [tensor(-1.1504, dtype=torch.float16), tensor(...                  பாட்டி   \n",
       "1  [tensor(-1.3174, dtype=torch.float16), tensor(...                  தாத்தா   \n",
       "2  [tensor(-1.3193, dtype=torch.float16), tensor(...                    மாமா   \n",
       "3  [tensor(-1.2168, dtype=torch.float16), tensor(...                   அத்தை   \n",
       "4  [tensor(-1.1924, dtype=torch.float16), tensor(...               மைத்துனர்   \n",
       "\n",
       "                               transl_ml  \\\n",
       "0     എൻ്റെ മുത്തശ്ശി ഒരു ബ്രാഹ്മണയാണ്.    \n",
       "1     എന്റെ മുത്തച്ഛൻ ഒരു ബ്രാഹ്മണനാണ്.    \n",
       "2       എന്റെ അമ്മാവൻ ഒരു ബ്രാഹ്മണനാണ്.    \n",
       "3       എൻ്റെ അമ്മായി ഒരു ബ്രാഹ്മണയാണ്.    \n",
       "4  എൻ്റെ ഭാര്യാസഹോദരൻ ഒരു ബ്രാഹ്മണനാണ്.    \n",
       "\n",
       "                                           logits_ml searched_spans_tam_Taml  \\\n",
       "0  [tensor(-0.0732, dtype=torch.float16), tensor(...                  பாட்டி   \n",
       "1  [tensor(-0.6470, dtype=torch.float16), tensor(...                  தாத்தா   \n",
       "2  [tensor(-0.9233, dtype=torch.float16), tensor(...                    மாமா   \n",
       "3  [tensor(-0.4893, dtype=torch.float16), tensor(...                   அத்தை   \n",
       "4  [tensor(-0.0292, dtype=torch.float16), tensor(...               மைத்துனர்   \n",
       "\n",
       "                      transl_ta  \\\n",
       "0     என் பாட்டி ஒரு பிராமணர்.    \n",
       "1     என் தாத்தா ஒரு பிராமணர்.    \n",
       "2       என் மாமா ஒரு பிராமணர்.    \n",
       "3      என் அத்தை ஒரு பிராமணர்.    \n",
       "4  என் மைத்துனர் ஒரு பிராமணர்.    \n",
       "\n",
       "                                           logits_ta  \n",
       "0  [tensor(-0.7446, dtype=torch.float16), tensor(...  \n",
       "1  [tensor(-0.5171, dtype=torch.float16), tensor(...  \n",
       "2  [tensor(-0.9399, dtype=torch.float16), tensor(...  \n",
       "3  [tensor(-1.0879, dtype=torch.float16), tensor(...  \n",
       "4  [tensor(-0.9644, dtype=torch.float16), tensor(...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe from the translations, logits and the root ambiguous words, searched spans\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['sentences'] = sents\n",
    "df['root_ambiguous_words'] = root_amb_words\n",
    "for lang in lang_script_list:\n",
    "    # if lang != 'ory_Orya':\n",
    "    #     continue\n",
    "    # following 2 can be commented out to reduce the size of the dataframe\n",
    "    df['searched_spans_'+lang] = searched_spans\n",
    "    df['transl_'+lang_code_map[lang]] = output_trnsl[lang]\n",
    "    df['logits_'+lang_code_map[lang]] = output_logits[lang]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all sentences:\n",
    "#    for all langs:\n",
    "#     for the given root ambiguous word, get the possible relations in the target language\n",
    "#      group the possible relations into matriarchal and patriarchal\n",
    "#       <*>find the logits for the words in matrirachi and patriachal relations\n",
    "#       find the sum over respective sets and take difference of both sums\n",
    "#       if difference is positive, then the wordXlang is matriarchal, else patriarchal\n",
    "#     Report the difference for each wordXlang as a matrix. Rows are words and columns are langs. Store it as final_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For word:  grandmother in lang:  ory_Orya Difference:  -0.9638671875\n",
      "For word:  grandmother in lang:  pan_Guru Difference:  0.77734375\n",
      "For word:  grandmother in lang:  ben_Beng Difference:  0.126220703125\n",
      "Skipping word: grandmother in lang: mal_Mlym due to empty logits.\n",
      "For word:  grandmother in lang:  tam_Taml Difference:  0.671875\n",
      "For word:  grandfather in lang:  ory_Orya Difference:  -0.2451171875\n",
      "For word:  grandfather in lang:  pan_Guru Difference:  -0.6181640625\n",
      "For word:  grandfather in lang:  ben_Beng Difference:  0.5224609375\n",
      "Skipping word: grandfather in lang: mal_Mlym due to empty logits.\n",
      "Skipping word: grandfather in lang: tam_Taml due to empty logits.\n",
      "For word:  uncle in lang:  ory_Orya Difference:  -0.86328125\n",
      "For word:  uncle in lang:  pan_Guru Difference:  -0.9541015625\n",
      "For word:  uncle in lang:  ben_Beng Difference:  -0.01318359375\n",
      "For word:  uncle in lang:  mal_Mlym Difference:  -0.45263671875\n",
      "For word:  uncle in lang:  tam_Taml Difference:  1.0\n",
      "For word:  aunt in lang:  ory_Orya Difference:  -0.1630859375\n",
      "For word:  aunt in lang:  pan_Guru Difference:  -0.775390625\n",
      "For word:  aunt in lang:  ben_Beng Difference:  0.216552734375\n",
      "For word:  aunt in lang:  mal_Mlym Difference:  0.463134765625\n",
      "For word:  aunt in lang:  tam_Taml Difference:  -0.2021484375\n",
      "For word:  brother-in-law in lang:  ory_Orya Difference:  0.9326171875\n",
      "For word:  brother-in-law in lang:  pan_Guru Difference:  0.8349609375\n",
      "For word:  brother-in-law in lang:  ben_Beng Difference:  0.462646484375\n",
      "Skipping word: brother-in-law in lang: mal_Mlym due to empty logits.\n",
      "For word:  brother-in-law in lang:  tam_Taml Difference:  0.99609375\n",
      "For word:  sister-in-law in lang:  ory_Orya Difference:  -0.912109375\n",
      "For word:  sister-in-law in lang:  pan_Guru Difference:  -0.478515625\n",
      "For word:  sister-in-law in lang:  ben_Beng Difference:  -0.31640625\n",
      "For word:  sister-in-law in lang:  mal_Mlym Difference:  -0.564453125\n",
      "For word:  sister-in-law in lang:  tam_Taml Difference:  -0.341796875\n",
      "For word:  cousin in lang:  ory_Orya Difference:  -0.951171875\n",
      "For word:  cousin in lang:  pan_Guru Difference:  -0.029541015625\n",
      "For word:  cousin in lang:  ben_Beng Difference:  -0.904296875\n",
      "Skipping word: cousin in lang: mal_Mlym due to empty logits.\n",
      "For word:  cousin in lang:  tam_Taml Difference:  -0.39453125\n",
      "For word:  nephew in lang:  ory_Orya Difference:  -0.4306640625\n",
      "For word:  nephew in lang:  pan_Guru Difference:  -1.0\n",
      "For word:  nephew in lang:  ben_Beng Difference:  -0.338623046875\n",
      "For word:  nephew in lang:  mal_Mlym Difference:  0.7578125\n",
      "For word:  nephew in lang:  tam_Taml Difference:  -0.59326171875\n",
      "For word:  niece in lang:  ory_Orya Difference:  -0.1357421875\n",
      "For word:  niece in lang:  pan_Guru Difference:  -0.8779296875\n",
      "For word:  niece in lang:  ben_Beng Difference:  0.288330078125\n",
      "For word:  niece in lang:  mal_Mlym Difference:  0.828125\n",
      "For word:  niece in lang:  tam_Taml Difference:  -0.4287109375\n",
      "For word:  grandmother in lang:  ory_Orya Difference:  -0.9638671875\n",
      "For word:  grandmother in lang:  pan_Guru Difference:  0.8173828125\n",
      "For word:  grandmother in lang:  ben_Beng Difference:  -0.71875\n",
      "Skipping word: grandmother in lang: mal_Mlym due to empty logits.\n",
      "For word:  grandmother in lang:  tam_Taml Difference:  0.6533203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2164147/2259655106.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  diff = torch.sum(torch.tensor(matriarchal_logits_softmax)) - torch.sum(torch.tensor(patriarchal_logits_softmax))\n"
     ]
    }
   ],
   "source": [
    "# for each row of dataframe with index i\n",
    "for i in range(len(df)):\n",
    "    # print(\"Index: \", i)\n",
    "    for lang in lang_script_list:\n",
    "        # if lang != 'ory_Orya':\n",
    "        #     continue\n",
    "        # print(\"Lang: \", lang)\n",
    "        if final_res.get(lang, None) is None:\n",
    "            final_res[lang] = {}\n",
    "        root_amb_word = df.loc[i, 'root_ambiguous_words']\n",
    "        # print(\"Root ambiguous word: \", root_amb_word)\n",
    "        possible_relations = list(pir[root_amb_word][lang].keys())\n",
    "        # print(\"Possible relations: \", possible_relations)\n",
    "        matriarchal = []\n",
    "        patriarchal = []\n",
    "        for rel in possible_relations:\n",
    "            if 'F' == pir[root_amb_word][lang][rel]['relation_code']:\n",
    "                matriarchal.append(rel)\n",
    "            if 'M' == pir[root_amb_word][lang][rel]['relation_code']:\n",
    "                patriarchal.append(rel)\n",
    "        # print(\"for lang: \", lang, \"root amb word: \", root_amb_word, \"matriarchal: \", matriarchal, \"patriarchal: \", patriarchal)\n",
    "        \n",
    "        logits = df.loc[i, 'logits_'+lang_code_map[lang]]\n",
    "        # print(\"Logits: \", logits)\n",
    "        matriarchal_logits = []\n",
    "        patriarchal_logits = []\n",
    "        for relations in [matriarchal, patriarchal]:\n",
    "            for rel in relations:\n",
    "                # print(\"for reln:\", rel, \"span_encodings:\", span_encodings[lang].get(rel, None))\n",
    "                # if rel is present in any key of span_encodings[lang], then print its value\n",
    "                key = next((k for k in span_encodings[lang].keys() if rel in k), \"None\")\n",
    "                word_index = span_encodings[lang].get(key, None)\n",
    "                # print(\"for reln::\", rel, \"Index::\", word_index)\n",
    "                \n",
    "                # find the avg of the logits for the word_index\n",
    "                if word_index is not None:\n",
    "                    avg_logits = torch.mean(logits[word_index], dim=0)\n",
    "                    # print(\"Avg logits: \", avg_logits)\n",
    "                    if relations == matriarchal:\n",
    "                        matriarchal_logits.append(avg_logits)\n",
    "                    else:\n",
    "                        patriarchal_logits.append(avg_logits)\n",
    "\n",
    "        # print(\"Matriarchal sets: \", matriarchal_logits, \"Patriarchal sets: \", patriarchal_logits)\n",
    "\n",
    "        # combine arrays of matriarchal and patriarchal logits and find softmax over the new resultant array and separate the matriarchial and patriarchial logits\n",
    "        if matriarchal_logits and patriarchal_logits:\n",
    "            effective_logits = torch.stack(matriarchal_logits)\n",
    "            effective_logits = torch.cat((effective_logits, torch.stack(patriarchal_logits)))\n",
    "            effective_logits = softmax(effective_logits, dim=0)\n",
    "            matriarchal_logits_softmax = effective_logits[:len(matriarchal_logits)]\n",
    "            patriarchal_logits_softmax = effective_logits[len(matriarchal_logits):]\n",
    "\n",
    "            diff = torch.sum(torch.tensor(matriarchal_logits_softmax)) - torch.sum(torch.tensor(patriarchal_logits_softmax)) \n",
    "            # /tmp/ipykernel_1975081/1980739227.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
    "            print(\"For word: \", root_amb_word, \"in lang: \", lang, \"Difference: \", diff.item())\n",
    "            # print(\"Since difference is \", \"positive, then the wordXlang is matriarchal\" if diff > 0 else \"negative, then the wordXlang is patriarchal\")\n",
    "            final_res[lang][root_amb_word] = diff.item()\n",
    "        else:\n",
    "            final_res[lang][root_amb_word] = 0\n",
    "            print(f\"Skipping word: {root_amb_word} in lang: {lang} due to empty logits.\")\n",
    "\n",
    "\n",
    "\n",
    "        # find the sum over respective sets and take difference of both sums\n",
    "        # diff = torch.sum(torch.tensor(matriarchal_logits)) - torch.sum(torch.tensor(patriarchal_logits))\n",
    "        # print(\"For word: \", root_amb_word, \"in lang: \", lang, \"Difference: \", diff)\n",
    "        # print(\"Since difference is \", \"positive, then the wordXlang is matriarchal\" if diff > 0 else \"negative, then the wordXlang is patriarchal\")\n",
    "\n",
    "        # #Report the difference for each wordXlang as a matrix. Rows are words and columns are langs. Store it as final_matrix\n",
    "        # final_matrix[root_amb_word][lang] = diff\n",
    "\n",
    "        #     matriarchal_logits.append(logits[]\n",
    "        # print(\"Matriarchal sets: \", matriarchal, \"Patriarchal sets: \", patriarchal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ory_Orya': {'grandmother': -0.9638671875,\n",
       "  'grandfather': -0.2451171875,\n",
       "  'uncle': -0.86328125,\n",
       "  'aunt': -0.1630859375,\n",
       "  'brother-in-law': 0.9326171875,\n",
       "  'sister-in-law': -0.912109375,\n",
       "  'cousin': -0.951171875,\n",
       "  'nephew': -0.4306640625,\n",
       "  'niece': -0.1357421875},\n",
       " 'pan_Guru': {'grandmother': 0.8173828125,\n",
       "  'grandfather': -0.6181640625,\n",
       "  'uncle': -0.9541015625,\n",
       "  'aunt': -0.775390625,\n",
       "  'brother-in-law': 0.8349609375,\n",
       "  'sister-in-law': -0.478515625,\n",
       "  'cousin': -0.029541015625,\n",
       "  'nephew': -1.0,\n",
       "  'niece': -0.8779296875},\n",
       " 'ben_Beng': {'grandmother': -0.71875,\n",
       "  'grandfather': 0.5224609375,\n",
       "  'uncle': -0.01318359375,\n",
       "  'aunt': 0.216552734375,\n",
       "  'brother-in-law': 0.462646484375,\n",
       "  'sister-in-law': -0.31640625,\n",
       "  'cousin': -0.904296875,\n",
       "  'nephew': -0.338623046875,\n",
       "  'niece': 0.288330078125},\n",
       " 'mal_Mlym': {'grandmother': 0,\n",
       "  'grandfather': 0,\n",
       "  'uncle': -0.45263671875,\n",
       "  'aunt': 0.463134765625,\n",
       "  'brother-in-law': 0,\n",
       "  'sister-in-law': -0.564453125,\n",
       "  'cousin': 0,\n",
       "  'nephew': 0.7578125,\n",
       "  'niece': 0.828125},\n",
       " 'tam_Taml': {'grandmother': 0.6533203125,\n",
       "  'grandfather': 0,\n",
       "  'uncle': 1.0,\n",
       "  'aunt': -0.2021484375,\n",
       "  'brother-in-law': 0.99609375,\n",
       "  'sister-in-law': -0.341796875,\n",
       "  'cousin': -0.39453125,\n",
       "  'nephew': -0.59326171875,\n",
       "  'niece': -0.4287109375}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.9638671875, 0.8173828125, -0.71875, 0, 0.6533203125],\n",
       " [-0.2451171875, -0.6181640625, 0.5224609375, 0, 0],\n",
       " [-0.86328125, -0.9541015625, -0.01318359375, -0.45263671875, 1.0],\n",
       " [-0.1630859375, -0.775390625, 0.216552734375, 0.463134765625, -0.2021484375],\n",
       " [0.9326171875, 0.8349609375, 0.462646484375, 0, 0.99609375],\n",
       " [-0.912109375, -0.478515625, -0.31640625, -0.564453125, -0.341796875],\n",
       " [-0.951171875, -0.029541015625, -0.904296875, 0, -0.39453125],\n",
       " [-0.4306640625, -1.0, -0.338623046875, 0.7578125, -0.59326171875],\n",
       " [-0.1357421875, -0.8779296875, 0.288330078125, 0.828125, -0.4287109375]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a 2D array of the final_res.. not dataframe but 2D array\n",
    "confusion_mat =[[final_res[lang][word] for j,lang in enumerate(lang_script_list)] for i,word in enumerate(ambiguos_words) if word!='child' ]\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2164147/3411790434.py:8: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + list(lang_code_map[lang] for lang in final_res.keys()))\n",
      "/tmp/ipykernel_2164147/3411790434.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + list(final_res['ory_Orya'].keys()))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show a confusion matrix plot from matplotlib of the final_res. rows are langs, columns are words and values are differences ranging from -1 to 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# give colour custommed as max value as Pink and min value as blue and 0 as white\n",
    "cax = ax.matshow(confusion_mat, cmap='bwr')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + list(lang_code_map[lang] for lang in final_res.keys()))\n",
    "ax.set_yticklabels([''] + list(final_res['ory_Orya'].keys()))\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Words')\n",
    "plt.title('Difference in Logits for Matriarchal and Patriarchal relations')\n",
    "# save the image to a file\n",
    "fig.savefig('results/logit_prob_diff_'+str(SAMPLE_SIZE)+'.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of ['ମାମୁଁ', 'ମଉସା'] in vocab of en_indic_tokenizer\n",
    "# print(en_indic_tokenizer.convert_tokens_to_ids(['ମାମୁଁ', 'ମଉସା'])) #[3, 3] - wrong\n",
    "\n",
    "# print(en_indic_tokenizer.vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the test_sentences_eng.txt file data as sents\n",
    "\n",
    "# # sents = ['The river is blue.', 'My uncle wearing blue coat.', 'My maternal aunt went to the river bank.', \"The doctor went to bank for money.\"]\n",
    "# sents=['My maternal aunt went to the river bank.', 'My maternal aunt loves me.', \n",
    "#        'My maternal aunt loves her grandchildren.', \"My maternal aunt loves her children.\", \n",
    "#        \"My maternal aunt loves her family.\",\n",
    "#        ]   \n",
    "# src_lang = \"eng_Latn\"\n",
    "\n",
    "# tgt_lang = 'hin_Deva'\n",
    "# # print(lang)\n",
    "# translations, logits = batch_translate(sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip_en_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ମୋ ଜେଜେମା ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ଜେଜେବାପା ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ମାମୁଁ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ମାଉସୀ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ଭିଣୋଇ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ଭାଉଜ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋର ସମ୍ପର୍କୀଯ଼ ଭାଇ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ପୁତୁରା ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋର ଭାଣିଜୀ ଜଣେ ବ୍ରାହ୍ମଣ। ', 'ମୋ ଜେଜେମା ଜଣେ କ୍ଷତ୍ରିଯ଼। ']\n"
     ]
    }
   ],
   "source": [
    "print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4980, -1.4980, -2.9004,  ..., -1.4980, -1.4980, -1.4980],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3.5763e-07, 3.5763e-07, 5.9605e-08,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16), tensor([4.1723e-07, 4.1723e-07, 1.1921e-07,  ..., 4.1723e-07, 4.1723e-07,\n",
      "        4.1723e-07], dtype=torch.float16), tensor([9.5367e-07, 9.5367e-07, 6.5565e-07,  ..., 9.5367e-07, 9.5367e-07,\n",
      "        9.5367e-07], dtype=torch.float16), tensor([1.0133e-06, 1.0133e-06, 4.1723e-07,  ..., 1.0133e-06, 1.0133e-06,\n",
      "        1.0133e-06], dtype=torch.float16), tensor([8.3447e-07, 8.3447e-07, 9.0088e-01,  ..., 8.3447e-07, 8.3447e-07,\n",
      "        8.3447e-07], dtype=torch.float16), tensor([8.3447e-07, 8.3447e-07, 4.3511e-04,  ..., 8.3447e-07, 8.3447e-07,\n",
      "        8.3447e-07], dtype=torch.float16), tensor([1.0133e-06, 1.0133e-06, 2.9802e-07,  ..., 1.0133e-06, 1.0133e-06,\n",
      "        1.0133e-06], dtype=torch.float16), tensor([3.5763e-07, 3.5763e-07, 1.7881e-07,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16), tensor([9.5367e-07, 9.5367e-07, 2.3842e-07,  ..., 9.5367e-07, 9.5367e-07,\n",
      "        9.5367e-07], dtype=torch.float16), tensor([3.5763e-07, 3.5763e-07, 5.9605e-08,  ..., 3.5763e-07, 3.5763e-07,\n",
      "        3.5763e-07], dtype=torch.float16)]\n",
      "10\n",
      "torch.Size([122672])\n"
     ]
    }
   ],
   "source": [
    "# for each logit in logits, convert it to prob using softmax\n",
    "for lang in lang_script_list:\n",
    "    if lang != 'ory_Orya':\n",
    "        continue\n",
    "    logits = output_logits[lang]\n",
    "    softmax_logits = [softmax(logit, dim=-1) for logit in logits]\n",
    "    print(softmax_logits)\n",
    "    print(len(softmax_logits) ) # for each sentence translated)\n",
    "    print(softmax_logits[0].shape) # for each word in the sentence; vocab size\n",
    "\n",
    "# for each sentence, amongs all vocab logits, find the difference of [sum of matrirach words] - [sum of patriarch words]\n",
    "# find the root word in english and as per lang, find the other Matriarch or Patriarch words based on relation code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(41445), tensor(41445), tensor(9971), tensor(30261), tensor(2), tensor(6), tensor(60824), tensor(4300), tensor(980), tensor(41445)]\n"
     ]
    }
   ],
   "source": [
    "# get the index of max prob for each logit\n",
    "max_prob_index = [torch.argmax(softmax_logit, dim=-1) for softmax_logit in softmax_logits]\n",
    "print(max_prob_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.return_types.topk(\n",
      "values=tensor([0.8823, 0.0048, 0.0035, 0.0031, 0.0028, 0.0021, 0.0021, 0.0016, 0.0016,\n",
      "        0.0014], dtype=torch.float16),\n",
      "indices=tensor([41445,    80,    30,  8911, 51174, 29498, 33622, 48446, 30261, 30502])), torch.return_types.topk(\n",
      "values=tensor([0.8306, 0.0312, 0.0203, 0.0101, 0.0087, 0.0076, 0.0056, 0.0024, 0.0017,\n",
      "        0.0010], dtype=torch.float16),\n",
      "indices=tensor([41445, 53208, 15588, 20077, 30502,    30,   409,  1111, 55513, 51174])), torch.return_types.topk(\n",
      "values=tensor([0.5093, 0.1919, 0.0316, 0.0116, 0.0104, 0.0051, 0.0042, 0.0039, 0.0035,\n",
      "        0.0035], dtype=torch.float16),\n",
      "indices=tensor([ 9971, 41565, 24501,    30, 41445,  7610, 20077,  3991,  3617, 15588])), torch.return_types.topk(\n",
      "values=tensor([0.6055, 0.0270, 0.0156, 0.0095, 0.0076, 0.0057, 0.0053, 0.0051, 0.0051,\n",
      "        0.0049], dtype=torch.float16),\n",
      "indices=tensor([30261, 41445,  9971,    30,  3617,   213, 54203,   336, 58401,  1390])), torch.return_types.topk(\n",
      "values=tensor([9.0088e-01, 1.0282e-04, 4.3392e-05, 1.4842e-05, 6.9737e-06, 6.1989e-06,\n",
      "        6.0201e-06, 4.6492e-06, 4.1723e-06, 3.3975e-06], dtype=torch.float16),\n",
      "indices=tensor([    2,     6,     4,     7,     5,    13,  9182,  2207,    70, 31428])), torch.return_types.topk(\n",
      "values=tensor([8.9160e-01, 6.4964e-03, 4.3511e-04, 2.2495e-04, 1.5342e-04, 8.3387e-05,\n",
      "        3.6299e-05, 3.5644e-05, 2.5749e-05, 2.3961e-05], dtype=torch.float16),\n",
      "indices=tensor([   6, 9182,    2,    4,    5, 2207,    7,  732, 3882,   13])), torch.return_types.topk(\n",
      "values=tensor([0.5723, 0.0255, 0.0235, 0.0147, 0.0088, 0.0082, 0.0079, 0.0065, 0.0049,\n",
      "        0.0049], dtype=torch.float16),\n",
      "indices=tensor([60824,  3991,  9971, 56796,  6091, 38982,  4725,  1111, 21058,   110])), torch.return_types.topk(\n",
      "values=tensor([0.6226, 0.2020, 0.0210, 0.0135, 0.0099, 0.0072, 0.0047, 0.0047, 0.0032,\n",
      "        0.0029], dtype=torch.float16),\n",
      "indices=tensor([ 4300, 30360,   980,  3991,    30,  1013, 21058,  4569,  9919, 60824])), torch.return_types.topk(\n",
      "values=tensor([0.4546, 0.1158, 0.0446, 0.0203, 0.0179, 0.0153, 0.0098, 0.0091, 0.0066,\n",
      "        0.0056], dtype=torch.float16),\n",
      "indices=tensor([  980, 30360,  4300,  2398,  4569, 38982, 13818,  3991,  1390,  4725])), torch.return_types.topk(\n",
      "values=tensor([0.8975, 0.0045, 0.0034, 0.0028, 0.0023, 0.0020, 0.0015, 0.0014, 0.0014,\n",
      "        0.0013], dtype=torch.float16),\n",
      "indices=tensor([41445,    80,  8911,    30, 29498, 51174, 48446, 33622,  1828,  2214]))]\n"
     ]
    }
   ],
   "source": [
    "# from the softmax_logits, get the indices of top 10 max prob \n",
    "top_10_indices = [torch.topk(softmax_logit, k=10, dim=-1) for softmax_logit in softmax_logits]\n",
    "print(top_10_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['जेजे ', 'न ', \"' \", 'नानी ', 'नाति ', 'दादी ', 'माआ ', 'दिदि ', 'माउ ', 'पिताम '], ['जेजे ', 'पितामह ', 'दादा ', 'बापा ', 'पिताम ', \"' \", 'द ', 'बड़ ', 'बापाङ्क ', 'नाति '], ['माम ', 'काका ', 'मामा ', \"' \", 'जेजे ', 'काक ', 'बापा ', 'भाइ ', 'खु ', 'दादा '], ['माउ ', 'जेजे ', 'माम ', \"' \", 'खु ', 'अ ', 'माङ्क ', 'ब ', 'कुनि ', 'बो '], ['</s> ', '। ', '. ', '\" ', ', ', '- ', '| ', 'I ', '۔ ', '᱾ '], ['। ', '| ', '</s> ', '. ', ', ', 'I ', '\" ', '_ ', 'बोलि ', '- '], ['सम्पर्कीय़ ', 'भाइ ', 'माम ', 'भ्रातृ ', 'सम्प ', 'भउणी ', 'जणे ', 'बड़ ', 'भ्र ', 'क '], ['पुत ', 'भण ', 'भ ', 'भाइ ', \"' \", 'पु ', 'भ्र ', 'भा ', 'सान ', 'सम्पर्कीय़ '], ['भ ', 'भण ', 'पुत ', 'झ ', 'भा ', 'भउणी ', 'भग ', 'भाइ ', 'बो ', 'जणे '], ['जेजे ', 'न ', 'नानी ', \"' \", 'दादी ', 'नाति ', 'दिदि ', 'माआ ', 'आइ ', 'मात ']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sofia/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from the top_10_indices, get the words in Hindi vocab using tokenizer.target_tokenizer\n",
    "word_list = []\n",
    "for i in top_10_indices:\n",
    "    with en_indic_tokenizer.as_target_tokenizer():\n",
    "        word_list.append(en_indic_tokenizer.batch_decode(i.indices))\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['जेजे ', 'न ', \"' \", 'नानी ', 'नाति ', 'दादी ', 'माआ ', 'दिदि ', 'माउ ', 'पिताम ']\n",
      "['जेजे ', 'पितामह ', 'दादा ', 'बापा ', 'पिताम ', \"' \", 'द ', 'बड़ ', 'बापाङ्क ', 'नाति ']\n",
      "['माम ', 'काका ', 'मामा ', \"' \", 'जेजे ', 'काक ', 'बापा ', 'भाइ ', 'खु ', 'दादा ']\n",
      "['माउ ', 'जेजे ', 'माम ', \"' \", 'खु ', 'अ ', 'माङ्क ', 'ब ', 'कुनि ', 'बो ']\n",
      "['</s> ', '। ', '. ', '\" ', ', ', '- ', '| ', 'I ', '۔ ', '᱾ ']\n",
      "['। ', '| ', '</s> ', '. ', ', ', 'I ', '\" ', '_ ', 'बोलि ', '- ']\n",
      "['सम्पर्कीय़ ', 'भाइ ', 'माम ', 'भ्रातृ ', 'सम्प ', 'भउणी ', 'जणे ', 'बड़ ', 'भ्र ', 'क ']\n",
      "['पुत ', 'भण ', 'भ ', 'भाइ ', \"' \", 'पु ', 'भ्र ', 'भा ', 'सान ', 'सम्पर्कीय़ ']\n",
      "['भ ', 'भण ', 'पुत ', 'झ ', 'भा ', 'भउणी ', 'भग ', 'भाइ ', 'बो ', 'जणे ']\n",
      "['जेजे ', 'न ', 'नानी ', \"' \", 'दादी ', 'नाति ', 'दिदि ', 'माआ ', 'आइ ', 'मात ']\n"
     ]
    }
   ],
   "source": [
    "for _ in word_list:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
